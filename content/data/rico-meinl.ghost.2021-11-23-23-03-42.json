{"meta":{"exported_on":1637708622161,"version":"4.22.4"},"data":{"posts":[{"id":"6085751174348916f1b0899b","uuid":"1e13a833-be02-455c-8afd-25a202ac34f0","title":"Machine Learning System Design","slug":"machine-learning-system-design","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/1_mHGcYI_L-ci7jnkKkzfBOw.png\",\"width\":1400,\"height\":783,\"caption\":\"Facebook Field Guide to Machine Learning\"}],[\"hr\",{}]],\"markups\":[[\"a\",[\"href\",\"https://becominghuman.ai/machine-learning-system-design-f2f4018f2f8\"]],[\"strong\"],[\"a\",[\"href\",\"https://blog.twitter.com/engineering/en_us/topics/insights/2017/using-deep-learning-at-scale-in-twitters-timelines.html\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://blog.twitter.com/engineering/en_us/topics/insights/2019/improving-engagement-on-digital-ads-with-delayed-feedback.html\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://instagram-engineering.com/lessons-learned-at-instagram-stories-and-feed-machine-learning-54f3aaa09e56\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://engineering.fb.com/security/fighting-abuse-scale-2019/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://ai.facebook.com/blog/community-standards-report/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://eng.uber.com/uber-eats-query-understanding/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://eng.uber.com/uber-eats-recommending-marketplace/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://eng.uber.com/uber-eats-graph-learning/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://eng.uber.com/nlp-deep-learning-uber-maps/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://eng.uber.com/forecasting-introduction/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d\"]],[\"a\",[\"href\",\"https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e\"]],[\"a\",[\"href\",\"https://medium.com/airbnb-engineering/learning-market-dynamics-for-optimal-pricing-97cffbcc53e3\"]],[\"a\",[\"href\",\"https://medium.com/airbnb-engineering/categorizing-listing-photos-at-airbnb-f9483f3ab7e3\"]],[\"a\",[\"href\",\"https://medium.com/airbnb-engineering/applying-deep-learning-to-airbnb-search-7ebd7230891f\"]],[\"a\",[\"href\",\"https://medium.com/airbnb-engineering/discovering-and-classifying-in-app-message-intent-at-airbnb-6a55f5400a0c\"]],[\"a\",[\"href\",\"https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789\"]],[\"a\",[\"href\",\"https://engineering.linkedin.com/blog/2018/10/an-introduction-to-ai-at-linkedin\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://engineering.linkedin.com/blog/2019/fairness-privacy-transparency-by-design\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://engineering.linkedin.com/blog/2019/06/building-communities-around-interests\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"http://highscalability.com/blog/2016/3/16/jeff-dean-on-large-scale-deep-learning-at-google.html\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=kY-BCNHd_dM\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://labs.spotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe\"]],[\"a\",[\"href\",\"https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking/dp/1449361323\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://gist.github.com/bluekidds/cad5c0ea2e5051b638ec39810f3c4b09\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://research.fb.com/the-facebook-field-guide-to-machine-learning-video-series/\",\"rel\",\"noopener\"]]],\"sections\":[[1,\"p\",[[0,[0],1,\"Read this post on Medium.\"]]],[10,0],[1,\"p\",[[0,[],0,\"While preparing for job interviews I found some great resources on Machine Learning System designs from Facebook, Twitter, Google, Airbnb, Uber, Instagram, Netflix, AWS and Spotify.\"]]],[1,\"p\",[[0,[],0,\"I find this to be a fascinating topic because it’s something not often covered in online courses.\"]]],[1,\"p\",[[0,[1],1,\"Twitter\"]]],[3,\"ul\",[[[0,[2],1,\"Using Deep Learning at Scale in Twitter’s Timelines\"]],[[0,[3],1,\"Improving engagement on digital ads with delayed feedback\"]],[[0,[4],1,\"Embeddings@Twitter\"]]]],[1,\"p\",[[0,[1],1,\"Instagram\"]]],[3,\"ul\",[[[0,[5],1,\"Lessons Learned at Instagram Stories and Feed Machine Learning\"]],[[0,[6],1,\"Powered by AI: Instagram’s Explore recommender system\"]]]],[1,\"p\",[[0,[1],1,\"Facebook\"]]],[3,\"ul\",[[[0,[7],1,\"Deep Entity Classification: An abusive account detection framework\"]],[[0,[8],1,\"New progress in using AI to detect harmful content\"]]]],[1,\"p\",[[0,[1],1,\"Uber Eats\"]]],[3,\"ul\",[[[0,[9],1,\"Food Discovery with Uber Eats: Building a Query Understanding Engine\"]],[[0,[10],1,\"Food Discovery with Uber Eats: Recommending for the Marketplace\"]],[[0,[11],1,\"Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations\"]]]],[1,\"p\",[[0,[1],1,\"Uber\"]]],[3,\"ul\",[[[0,[12],1,\"Applying Customer Feedback: How NLP & Deep Learning Improve Uber’s Maps\"]],[[0,[13],1,\"Forecasting at Uber: An Introduction\"]]]],[1,\"p\",[[0,[1],1,\"Airbnb\"]]],[3,\"ul\",[[[0,[14],1,\"Using Machine Learning to Predict Value of Homes On Airbnb\"]],[[0,[15],1,\"Listing Embeddings in Search Ranking\"]],[[0,[16],1,\"Learning Market Dynamics for Optimal Pricing\"]],[[0,[17],1,\"Categorizing Listing Photos at Airbnb\"]],[[0,[18],1,\"Applying Deep Learning To Airbnb Search\"]],[[0,[19],1,\"Discovering and Classifying In-app Message Intent at Airbnb\"]]]],[1,\"p\",[[0,[1],1,\"Airbnb Experiences\"]]],[3,\"ul\",[[[0,[20],1,\"Machine Learning-Powered Search Ranking of Airbnb Experiences\"]]]],[1,\"p\",[[0,[1],1,\"Linkedin\"]]],[3,\"ul\",[[[0,[21],1,\"An Introduction to AI at LinkedIn\"]],[[0,[22],1,\"Fairness, Privacy, and Transparency by Design in AI/ML Systems\"]],[[0,[23],1,\"Communities AI: Building Communities Around Interests on LinkedIn\"]],[[0,[7],1,\"Preventing abuse using unsupervised learning\"]]]],[1,\"p\",[[0,[1],1,\"Google\"]]],[3,\"ul\",[[[0,[24],1,\"Jeff Dean On Large-Scale Deep Learning At Google\"]]]],[1,\"p\",[[0,[1],1,\"Netflix\"]]],[3,\"ul\",[[[0,[25],1,\"A Multi-Armed Bandit Framework for Recommendations at Netflix\"]]]],[1,\"p\",[[0,[1],1,\"Spotify\"]]],[3,\"ul\",[[[0,[26],1,\"For Your Ears Only: Personalizing Spotify Home with Machine Learning\"]],[[0,[27],1,\"How Does Spotify Know You So Well?\"]]]],[10,1],[1,\"p\",[[0,[],0,\"In addition, here are some resources on a more general process. Starting with the book \"],[0,[28],1,\"Data Science for Business\"],[0,[],0,\" which explains the CRISP-DM (Cross Industry Standard Process for Data Mining).\"]]],[1,\"p\",[[0,[],0,\"The process involves six stages:\"]]],[3,\"ol\",[[[0,[],0,\"Business Understanding\"]],[[0,[],0,\"Data Understanding\"]],[[0,[],0,\"Data Preparation\"]],[[0,[],0,\"Modelling\"]],[[0,[],0,\"Evaluation\"]],[[0,[],0,\"Deployment\"]]]],[1,\"p\",[[0,[],0,\"Here is a more high-level breakdown on \"],[0,[29],1,\"how to apply CRISP-DM on AWS.\"]]],[1,\"p\",[[0,[],0,\"Facebook also created a video series where they go into depth in how they structure Machine Learning Projects with the \"],[0,[30],1,\"Facebook Field Guide\"],[0,[],0,\" to Machine Learning.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p><a href=\"https://becominghuman.ai/machine-learning-system-design-f2f4018f2f8\">Read this post on Medium.</a></p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2020/10/1_mHGcYI_L-ci7jnkKkzfBOw.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1400\" height=\"783\" srcset=\"__GHOST_URL__/content/images/size/w600/2020/10/1_mHGcYI_L-ci7jnkKkzfBOw.png 600w, __GHOST_URL__/content/images/size/w1000/2020/10/1_mHGcYI_L-ci7jnkKkzfBOw.png 1000w, __GHOST_URL__/content/images/2020/10/1_mHGcYI_L-ci7jnkKkzfBOw.png 1400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Facebook Field Guide to Machine Learning</figcaption></figure><p>While preparing for job interviews I found some great resources on Machine Learning System designs from Facebook, Twitter, Google, Airbnb, Uber, Instagram, Netflix, AWS and Spotify.</p><p>I find this to be a fascinating topic because it’s something not often covered in online courses.</p><p><strong>Twitter</strong></p><ul><li><a href=\"https://blog.twitter.com/engineering/en_us/topics/insights/2017/using-deep-learning-at-scale-in-twitters-timelines.html\" rel=\"noopener\">Using Deep Learning at Scale in Twitter’s Timelines</a></li><li><a href=\"https://blog.twitter.com/engineering/en_us/topics/insights/2019/improving-engagement-on-digital-ads-with-delayed-feedback.html\" rel=\"noopener\">Improving engagement on digital ads with delayed feedback</a></li><li><a href=\"https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html\" rel=\"noopener\">Embeddings@Twitter</a></li></ul><p><strong>Instagram</strong></p><ul><li><a href=\"https://instagram-engineering.com/lessons-learned-at-instagram-stories-and-feed-machine-learning-54f3aaa09e56\" rel=\"noopener\">Lessons Learned at Instagram Stories and Feed Machine Learning</a></li><li><a href=\"https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/\" rel=\"noopener\">Powered by AI: Instagram’s Explore recommender system</a></li></ul><p><strong>Facebook</strong></p><ul><li><a href=\"https://engineering.fb.com/security/fighting-abuse-scale-2019/\" rel=\"noopener\">Deep Entity Classification: An abusive account detection framework</a></li><li><a href=\"https://ai.facebook.com/blog/community-standards-report/\" rel=\"noopener\">New progress in using AI to detect harmful content</a></li></ul><p><strong>Uber Eats</strong></p><ul><li><a href=\"https://eng.uber.com/uber-eats-query-understanding/\" rel=\"noopener\">Food Discovery with Uber Eats: Building a Query Understanding Engine</a></li><li><a href=\"https://eng.uber.com/uber-eats-recommending-marketplace/\" rel=\"noopener\">Food Discovery with Uber Eats: Recommending for the Marketplace</a></li><li><a href=\"https://eng.uber.com/uber-eats-graph-learning/\" rel=\"noopener\">Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations</a></li></ul><p><strong>Uber</strong></p><ul><li><a href=\"https://eng.uber.com/nlp-deep-learning-uber-maps/\" rel=\"noopener\">Applying Customer Feedback: How NLP &amp; Deep Learning Improve Uber’s Maps</a></li><li><a href=\"https://eng.uber.com/forecasting-introduction/\" rel=\"noopener\">Forecasting at Uber: An Introduction</a></li></ul><p><strong>Airbnb</strong></p><ul><li><a href=\"https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d\">Using Machine Learning to Predict Value of Homes On Airbnb</a></li><li><a href=\"https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e\">Listing Embeddings in Search Ranking</a></li><li><a href=\"https://medium.com/airbnb-engineering/learning-market-dynamics-for-optimal-pricing-97cffbcc53e3\">Learning Market Dynamics for Optimal Pricing</a></li><li><a href=\"https://medium.com/airbnb-engineering/categorizing-listing-photos-at-airbnb-f9483f3ab7e3\">Categorizing Listing Photos at Airbnb</a></li><li><a href=\"https://medium.com/airbnb-engineering/applying-deep-learning-to-airbnb-search-7ebd7230891f\">Applying Deep Learning To Airbnb Search</a></li><li><a href=\"https://medium.com/airbnb-engineering/discovering-and-classifying-in-app-message-intent-at-airbnb-6a55f5400a0c\">Discovering and Classifying In-app Message Intent at Airbnb</a></li></ul><p><strong>Airbnb Experiences</strong></p><ul><li><a href=\"https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789\">Machine Learning-Powered Search Ranking of Airbnb Experiences</a></li></ul><p><strong>Linkedin</strong></p><ul><li><a href=\"https://engineering.linkedin.com/blog/2018/10/an-introduction-to-ai-at-linkedin\" rel=\"noopener\">An Introduction to AI at LinkedIn</a></li><li><a href=\"https://engineering.linkedin.com/blog/2019/fairness-privacy-transparency-by-design\" rel=\"noopener\">Fairness, Privacy, and Transparency by Design in AI/ML Systems</a></li><li><a href=\"https://engineering.linkedin.com/blog/2019/06/building-communities-around-interests\" rel=\"noopener\">Communities AI: Building Communities Around Interests on LinkedIn</a></li><li><a href=\"https://engineering.fb.com/security/fighting-abuse-scale-2019/\" rel=\"noopener\">Preventing abuse using unsupervised learning</a></li></ul><p><strong>Google</strong></p><ul><li><a href=\"http://highscalability.com/blog/2016/3/16/jeff-dean-on-large-scale-deep-learning-at-google.html\" rel=\"noopener\">Jeff Dean On Large-Scale Deep Learning At Google</a></li></ul><p><strong>Netflix</strong></p><ul><li><a href=\"https://www.youtube.com/watch?v=kY-BCNHd_dM\" rel=\"noopener\">A Multi-Armed Bandit Framework for Recommendations at Netflix</a></li></ul><p><strong>Spotify</strong></p><ul><li><a href=\"https://labs.spotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/\" rel=\"noopener\">For Your Ears Only: Personalizing Spotify Home with Machine Learning</a></li><li><a href=\"https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe\">How Does Spotify Know You So Well?</a></li></ul><hr><p>In addition, here are some resources on a more general process. Starting with the book <a href=\"https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking/dp/1449361323\" rel=\"noopener\">Data Science for Business</a> which explains the CRISP-DM (Cross Industry Standard Process for Data Mining).</p><p>The process involves six stages:</p><ol><li>Business Understanding</li><li>Data Understanding</li><li>Data Preparation</li><li>Modelling</li><li>Evaluation</li><li>Deployment</li></ol><p>Here is a more high-level breakdown on <a href=\"https://gist.github.com/bluekidds/cad5c0ea2e5051b638ec39810f3c4b09\" rel=\"noopener\">how to apply CRISP-DM on AWS.</a></p><p>Facebook also created a video series where they go into depth in how they structure Machine Learning Projects with the <a href=\"https://research.fb.com/the-facebook-field-guide-to-machine-learning-video-series/\" rel=\"noopener\">Facebook Field Guide</a> to Machine Learning.</p>","comment_id":"5f7a32cc3ffbdb6a6f04d689","plaintext":"Read this post on Medium.\n[https://becominghuman.ai/machine-learning-system-design-f2f4018f2f8]\n\nFacebook Field Guide to Machine LearningWhile preparing for job interviews I\nfound some great resources on Machine Learning System designs from Facebook,\nTwitter, Google, Airbnb, Uber, Instagram, Netflix, AWS and Spotify.\n\nI find this to be a fascinating topic because it’s something not often covered\nin online courses.\n\nTwitter\n\n * Using Deep Learning at Scale in Twitter’s Timelines\n   [https://blog.twitter.com/engineering/en_us/topics/insights/2017/using-deep-learning-at-scale-in-twitters-timelines.html]\n * Improving engagement on digital ads with delayed feedback\n   [https://blog.twitter.com/engineering/en_us/topics/insights/2019/improving-engagement-on-digital-ads-with-delayed-feedback.html]\n * Embeddings@Twitter\n   [https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html]\n\nInstagram\n\n * Lessons Learned at Instagram Stories and Feed Machine Learning\n   [https://instagram-engineering.com/lessons-learned-at-instagram-stories-and-feed-machine-learning-54f3aaa09e56]\n * Powered by AI: Instagram’s Explore recommender system\n   [https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/]\n\nFacebook\n\n * Deep Entity Classification: An abusive account detection framework\n   [https://engineering.fb.com/security/fighting-abuse-scale-2019/]\n * New progress in using AI to detect harmful content\n   [https://ai.facebook.com/blog/community-standards-report/]\n\nUber Eats\n\n * Food Discovery with Uber Eats: Building a Query Understanding Engine\n   [https://eng.uber.com/uber-eats-query-understanding/]\n * Food Discovery with Uber Eats: Recommending for the Marketplace\n   [https://eng.uber.com/uber-eats-recommending-marketplace/]\n * Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations\n   [https://eng.uber.com/uber-eats-graph-learning/]\n\nUber\n\n * Applying Customer Feedback: How NLP & Deep Learning Improve Uber’s Maps\n   [https://eng.uber.com/nlp-deep-learning-uber-maps/]\n * Forecasting at Uber: An Introduction\n   [https://eng.uber.com/forecasting-introduction/]\n\nAirbnb\n\n * Using Machine Learning to Predict Value of Homes On Airbnb\n   [https://medium.com/airbnb-engineering/using-machine-learning-to-predict-value-of-homes-on-airbnb-9272d3d4739d]\n * Listing Embeddings in Search Ranking\n   [https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e]\n * Learning Market Dynamics for Optimal Pricing\n   [https://medium.com/airbnb-engineering/learning-market-dynamics-for-optimal-pricing-97cffbcc53e3]\n * Categorizing Listing Photos at Airbnb\n   [https://medium.com/airbnb-engineering/categorizing-listing-photos-at-airbnb-f9483f3ab7e3]\n * Applying Deep Learning To Airbnb Search\n   [https://medium.com/airbnb-engineering/applying-deep-learning-to-airbnb-search-7ebd7230891f]\n * Discovering and Classifying In-app Message Intent at Airbnb\n   [https://medium.com/airbnb-engineering/discovering-and-classifying-in-app-message-intent-at-airbnb-6a55f5400a0c]\n\nAirbnb Experiences\n\n * Machine Learning-Powered Search Ranking of Airbnb Experiences\n   [https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789]\n\nLinkedin\n\n * An Introduction to AI at LinkedIn\n   [https://engineering.linkedin.com/blog/2018/10/an-introduction-to-ai-at-linkedin]\n * Fairness, Privacy, and Transparency by Design in AI/ML Systems\n   [https://engineering.linkedin.com/blog/2019/fairness-privacy-transparency-by-design]\n * Communities AI: Building Communities Around Interests on LinkedIn\n   [https://engineering.linkedin.com/blog/2019/06/building-communities-around-interests]\n * Preventing abuse using unsupervised learning\n   [https://engineering.fb.com/security/fighting-abuse-scale-2019/]\n\nGoogle\n\n * Jeff Dean On Large-Scale Deep Learning At Google\n   [http://highscalability.com/blog/2016/3/16/jeff-dean-on-large-scale-deep-learning-at-google.html]\n\nNetflix\n\n * A Multi-Armed Bandit Framework for Recommendations at Netflix\n   [https://www.youtube.com/watch?v=kY-BCNHd_dM]\n\nSpotify\n\n * For Your Ears Only: Personalizing Spotify Home with Machine Learning\n   [https://labs.spotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/]\n * How Does Spotify Know You So Well?\n   [https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe]\n\n\n--------------------------------------------------------------------------------\n\nIn addition, here are some resources on a more general process. Starting with\nthe book Data Science for Business\n[https://www.amazon.com/Data-Science-Business-Data-Analytic-Thinking/dp/1449361323] \nwhich explains the CRISP-DM (Cross Industry Standard Process for Data Mining).\n\nThe process involves six stages:\n\n 1. Business Understanding\n 2. Data Understanding\n 3. Data Preparation\n 4. Modelling\n 5. Evaluation\n 6. Deployment\n\nHere is a more high-level breakdown on how to apply CRISP-DM on AWS.\n[https://gist.github.com/bluekidds/cad5c0ea2e5051b638ec39810f3c4b09]\n\nFacebook also created a video series where they go into depth in how they\nstructure Machine Learning Projects with the Facebook Field Guide\n[https://research.fb.com/the-facebook-field-guide-to-machine-learning-video-series/] \nto Machine Learning.","feature_image":null,"featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2020-10-04 20:38:36","created_by":"1","updated_at":"2021-04-25 14:07:28","updated_by":"1","published_at":"2020-03-02 21:40:00","published_by":"1","custom_excerpt":"Some great resources on Machine Learning System designs from Facebook, Twitter, Google, Airbnb, Uber, Instagram, Netflix, AWS and Spotify.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"6085751174348916f1b0899c","uuid":"4daaf252-b49c-4601-8512-6ac69131daee","title":"The World Doesn't Care - Lessons From Startup Failure","slug":"the-world-doesnt-care-lessons-from-startup-failure","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"https://cdn-images-1.medium.com/max/2400/1*AsK8E3zZ78yf3iG1c1uiSA.jpeg\",\"alt\":\"\",\"title\":\"\",\"cardWidth\":\"\",\"caption\":\"Photo by <a href=\\\"https://unsplash.com/@sebastian_unrau?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\\\" data-href=\\\"https://unsplash.com/@sebastian_unrau?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\\\" class=\\\"markup--anchor markup--figure-anchor\\\" rel=\\\"noopener\\\" target=\\\"_blank\\\">Sebastian Unrau</a> on&nbsp;<a href=\\\"https://unsplash.com/s/photos/forest?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\\\" data-href=\\\"https://unsplash.com/s/photos/forest?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\\\" class=\\\"markup--anchor markup--figure-anchor\\\" rel=\\\"noopener\\\" target=\\\"_blank\\\">Unsplash</a>\"}],[\"hr\",{}],[\"hr\",{}],[\"hr\",{}]],\"markups\":[[\"a\",[\"href\",\"https://medium.com/@ricomeinl/the-world-doesnt-care-lessons-from-startup-failure-f960dfc6be8a\"]],[\"strong\"],[\"a\",[\"href\",\"https://youtu.be/pg9fRGlW-2U?t=173\",\"rel\",\"noopener\"]],[\"em\"],[\"a\",[\"href\",\"https://www.alicorn.blog\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://youtu.be/pg9fRGlW-2U?t=479\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.alicorn.blog/books/competing-against-luck-innovation-customer\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.alicorn.blog/books/hard-thing-about-hard-things-building-business\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=uFX95HahaUs\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.alicorn.blog/books/measure-what-matters-okr\",\"rel\",\"noopener\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"The other often overlooked and not-so-glamorous side of the founder’s story.\"]]],[1,\"p\",[[0,[0],1,\"Read this article on Medium.\"]]],[10,0],[1,\"p\",[[0,[],0,\"Everyone loves the good old startup story of the young college dropout who started from his dorm room, built an amazing product, assembled a team of equally smart people, worked incredibly hard and went on to change the world. In my opinion the ideology of starting your own startup has been completely overhyped in the recent years (maybe even longer but that’s as far as I can judge) and young people start companies just for the sake of being a part of this story. I thought it’d be interesting to contribute my story which often remains untold because we all shy away from admitting to failure.\"]]],[1,\"p\",[[0,[],0,\"My name is Rico, I am a 22 y/o entrepreneur and the technical co-founder of a FashionTech startup which we’ve recently put on hold. Having completed my first attempt of founding a startup I wanted to share a couple of painful lessons that I took away from this experience.\"]]],[1,\"p\",[[0,[],0,\"Before I get to my real list, let me quickly explain why I included my age in the previous sentence. This is actually the first fallacy I fell for: thinking you’re awesome because you went on a leave of absence from college to co-found a startup at age 21. \"],[1,[],0,0],[0,[1],1,\"Breaking news: the world doesn’t care.\"],[0,[],0,\" \"],[1,[],0,1],[0,[1],1,\"Investors don’t care. And most importantly, your customers don’t care.\"],[0,[],0,\" Don’t follow the hype stories of Zuckerberg, Gates and Jobs and think it gives you an advantage to start something while you’re young. It’s nice to have an idea and be able to \"],[0,[2],1,\"start something while you’re young\"],[0,[],0,\" because you usually don’t have that much to lose and no family to take care of but it shouldn’t be the reason in the first place.\"]]],[1,\"p\",[[0,[],0,\"Now, to the actual learnings. Before you start reading this, I want to point out that I made 1 attempt to start a company so far and it didn’t succeed. This article is about what I learned not to do. \"],[1,[],0,2],[0,[3],1,\"But, please take my advice with a grain of salt\"],[0,[],0,\". \"],[1,[],0,3],[0,[],0,\"If you want to learn how to do it right, \"],[0,[4],1,\"check out my blog\"],[0,[],0,\". It only contains books recommended or written by billionaire founders.\"]]],[10,1],[1,\"p\",[[0,[],0,\"As a quick background: I don’t like to go shopping and also don’t want to spend much of my time going to the mall. Still, I like to dress well. Online shopping is even worse because I have really long legs and nothing I ever ordered fit me well. My co-founder and I bonded through that problem when he had started working as a salesperson in a retail store in Hamburg to understand the customer needs in this segment. We joined forces in November 2018 and built an algorithm that allows people to measure themselves with their phone to find perfect fitting clothes. We started with only jeans to have focus and because so many people struggle to find a pair that fits well. In April 2019 we moved to Amsterdam and started working with two jeans brands and tried to sell the technology as a plugin to the online retailers (we talked with ASOS, Levi’s, Zappos, Nordstrom, AboutYou). In August 2019 we moved to Los Angeles and pivoted into B2C (all the major jeans brands are located there). Recently we put the company on hold.\"]]],[10,2],[1,\"h3\",[[0,[],0,\"#1 Start with a Problem in Your Own Life\"]]],[1,\"blockquote\",[[0,[],0,\"We were building a product that we ourselves were the customer for. — \"],[0,[5],1,\"Steve Jobs\"]]],[1,\"p\",[[0,[],0,\"This is probably the most painful but also the most valuable lesson of all. Especially because I had seen the video about Steve Jobs saying that a couple times. But there’s quite a difference between consuming information and then acting on it. We didn’t act on it. When we built the body measurement technology we decided to start with women. There were many reasons for that decision and I won’t go into depth here but what we painfully learned was that it is really hard to create a \"],[0,[1],1,\"great\"],[0,[],0,\" consumer product. To get all the tiny details right, you’ll have a much better starting point when you’re building something for yourself.\"]]],[1,\"p\",[[0,[],0,\"To frame the problem we were trying to solve we used the “Jobs Theory” framework described by Clayton Christensen in his book “\"],[0,[6],1,\"Competing Against Luck\"],[0,[],0,\"”: \"],[0,[3],1,\"What job do people hire our product for? \"],[1,[],0,4],[0,[],0,\"Though, we failed to apply this framework to our solution, aka how our product helps people accomplish the jobs they hired it for. We realized this later on when we were already in L.A. and pivoted to men and couldn’t imagine how our product would fit into our own lives.\"]]],[1,\"p\",[[0,[],0,\"The learning here is: \"],[1,[],0,5],[0,[1,3],2,\"Start with a problem in your own life and build a solution that you would use yourself.\"]]],[1,\"h3\",[[0,[],0,\"#2 Stay Relentlessly Focused on the End Results with the Highest Impact on Your Business Strategy\"]]],[1,\"p\",[[0,[],0,\"Setting measurable goals is great. Setting the right goals is hard. There is a reason why executives and company founders get paid so much. The hardest job in the world is deciding and prioritizing what to work on. And if you work on the wrong things, it doesn’t matter how hard you work. You’re probably not gonna get where you want to go.\"]]],[1,\"p\",[[0,[],0,\"We learned this the hard way, when we spent three months trying to get to +-1% measurement inaccuracy to impress the big retailers (so we thought) and convince them to work with us. Our assumption was that our product needs to work really well to succeed. \"],[1,[],0,6],[0,[],0,\"In our field that meant, being able to recommend people jeans that fit perfectly. In order for the jeans to fit perfectly, it needs to sit well at the hip, waist, upper thigh, mid thigh, calf and ankle. That’s one reason why jeans are amongst the hardest products to fit (and therefore our reasoning: if we solve this, everything else will be like a walk in the park). So, even though it is true that all the body parts I mentioned above need to be measured with +-1% inaccuracy for the jeans to fit perfectly, there’s a relative degree of importance. We later found out that the hip and waist for example have the highest impact on the end result.\"]]],[1,\"p\",[[0,[],0,\"Taking it one step further, the +-1% inaccuracy was a terrible metric to focus on when trying to start a business. The online retailers don’t care about the measurement inaccuracy. They care about products that drive conversion and reduce costs associated with returns. Customers don’t care about the measurement inaccuracy. They don’t even care about the technology in general. They care about saving time and effort and eventually if the jeans makes them look and feel good.\"]]],[1,\"p\",[[0,[],0,\"It’s so easy to feel good about yourself when you work super hard and make progress towards achieving goals but none of that matters if those goals are not aligned with your business strategy. I feel like this one is especially important for tech people (such as myself) who love to build cool things. The stuff that matters most for the business is not always the most fun.\"]]],[1,\"p\",[[0,[],0,\"The learning here is: \"],[1,[],0,7],[0,[1,3],2,\"Don’t get lost in the trenches and focus on the stuff that has the highest impact on the results you are trying to achieve as a business.\"]]],[1,\"p\",[[0,[],0,\"I’ll throw in another one here: \"],[0,[1,3],2,\"Don’t build something that doesn’t have short-term value because “we’ll definitely need it in the future”.\"],[1,[],0,8],[0,[],0,\"I once cleaned up the whole code base for our web app and automatized one of our internal processes, just because I had some time on hand and thought that automation would definitely be useful and save time in the future. I was wrong. Not long after, the process changed and now it was super hard to add to it and I ended up wasting a lot of time reverting the automation I just implemented a week ago.\"]]],[1,\"h3\",[[0,[],0,\"#3 It’s not the money. It’s the f****** money.\"]]],[1,\"p\",[[0,[],0,\"This is what Bill Campbell told Ben Horowitz when he was planning to take his company Loudcloud public (from “\"],[0,[7],1,\"The Hard Thing About Hard Things\"],[0,[],0,\"”).\"]]],[1,\"p\",[[0,[],0,\"I thought this quote accurately captures the relationship you should entertain with money when starting a company. And by that I mean, \"],[0,[1],1,\"how are you going to make money? \"],[0,[],0,\"As a tech person it’s easy to think that if you build something cool, you will somehow find a way for people to pay you for it.\"],[1,[],0,9],[0,[],0,\"But nowadays, especially in the era\"],[0,[1],1,\" \"],[0,[],0,\"of mobile it’s not as easy as “just put ads on it”.\"]]],[1,\"p\",[[0,[],0,\"We made the mistake of thinking that our product has the potential to be so useful for people (save time and effort) and the online retailers (reduce online returns, which are at 60% for jeans) that we don’t need a business model but rather investors will fund us and we’ll figure out how to make money later. Needless to say, that was a bad strategy. During YC Startup School, Marc Andreessen once said the \"],[0,[8],1,\"best way to raise money is to create a great business and then tell investors about it.\"],[0,[],0,\" Not the other way around.\"]]],[1,\"p\",[[0,[],0,\"The learning here is: \"],[1,[],0,10],[0,[1,3],2,\"You’re running a business, not a research lab. If you don’t focus on the money, your business will die.\"]]],[1,\"h3\",[[0,[],0,\"#4 Be careful with the latest research\"]]],[1,\"p\",[[0,[],0,\"I think this one heavily depends on the field you’re in and I don’t know if this is the case in general so I’m happy to hear about your experience. We started with three co-founders and my initial role was not the technology part. When we became two co-founders and I was in charge of getting to +-1% measurement inaccuracy my approach was to contact different companies that were already working on this to see if we could buy the technology. \"],[1,[],0,11],[0,[],0,\"None of them had something that was good enough so we had to move ahead and build it ourselves. \"],[1,[],0,12],[0,[],0,\"I locked myself in my room during all of November and December and basically read every research paper that was ever written in this field. That took a lot of time and effort because the barrier you need to overcome until you fully understand all these deeply technical papers is extremely steep. Not a very good idea, when you’re \"],[0,[3],1,\"jumping off of a cliff trying to assemble a plane on the way down\"],[0,[],0,\" (Reid Hoffman).\"]]],[1,\"p\",[[0,[],0,\"In addition to that almost all of the papers are not industry-ready, which means they are presented nicely but have underlying flaws in terms of performance, they only work for specific edge cases or with lab data. My advice is to always connect with the authors and ask them to help you understand the algorithms and ask about the limits of the paper beforehand. Another thing I learned is that many papers are oversold. If you think about it, it makes sense because as a researcher you have to show process in your work to keep the funding going. It’s just good to be aware of that when you are trying to assess whether any of the ideas from the papers could be used in practice. In theory it looks amazing but in practice the performance is heavily limited.\"]]],[1,\"p\",[[0,[],0,\"The learning here is: \"],[1,[],0,13],[0,[1,3],2,\"Unless you’re a PhD and know about what’s really possible in your field, be careful with trying to reimplement the latest research papers for your industry application.\"]]],[1,\"h3\",[[0,[],0,\"#5 Reach out to Experts\"]]],[1,\"p\",[[0,[],0,\"Before we started our journey, we came across the book “\"],[0,[9],1,\"Measure What Matters\"],[0,[],0,\"” by John Doerr, a heavily recommended book on OKRs (Objectives and Key Results), the management methodology from Intel which was implemented by Google back in the day and is still actively used. \"],[1,[],0,14],[0,[],0,\"Naturally we were intrigued to make this our standard methodology to set our monthly goals and how we’d get there. The book does mention the downside that it’s quite hard to implement and we struggled quite a bit with it. It just didn’t feel like it was dynamic enough because in a startup things change almost every day. \"],[1,[],0,15],[0,[],0,\"After 9 months I was tired of it and shot an email to some of the people interviewed in the book. Among them were Atticus Tysen, the CIO from Intuit and Brett Kopf, CEO of Remind. They both got back to me and their response was simple and clear: the methodology is too heavy and too much process for an early stage startup. Would’ve been good to know that before we started using it.\"]]],[1,\"p\",[[0,[],0,\"The learning here is: \"],[1,[],0,16],[0,[1,3],2,\"Always reach out to experts and ask for their advice before you start to implement something that requires as much time and effort like OKRs.\"]]],[10,3],[1,\"h3\",[[0,[],0,\"Wrapping Up\"]]],[1,\"p\",[[0,[],0,\"To sum up, here are my 5 Learnings:\"]]],[3,\"ol\",[[[0,[1,3],2,\"Start with a problem in your own life and build a solution that you would use yourself.\"]],[[0,[1,3],2,\"Don’t get lost in the trenches and focus on the stuff that has the highest impact on the results you are trying to achieve as a business.\"]],[[0,[1,3],2,\"You’re running a business, not a research lab. If you don’t focus on the money, your business will die.\"]],[[0,[1,3],2,\"Unless you’re a PhD and know about what’s really possible in your field, be careful with trying to reimplement the latest research papers for your industry application.\"]],[[0,[1,3],2,\"Always reach out to experts and ask for their advice before you start to implement something that requires as much time and effort like OKRs.\"]]]],[1,\"p\",[[0,[],0,\"Lastly, there are a lot of idealized founders’ stories out there but no one really talks about the other side:\"]]],[3,\"ul\",[[[0,[],0,\"The world doesn’t care \"],[0,[1],1,\"how old you are\"],[0,[],0,\" (see above).\"]],[[0,[],0,\"The world doesn’t care \"],[0,[1],1,\"if it’s new years or your birthday\"],[0,[],0,\". We were up until 4am in the night before my birthday, slept 2 hours and then went to a customer presentation in the morning. We worked all throughout new years eve.\"]],[[0,[],0,\"The world doesn’t care \"],[0,[1],1,\"how many hours you put in\"],[0,[],0,\". 8.30am — 2.00am, 6 days a week.\"]],[[0,[],0,\"The world doesn’t care\"],[0,[1],1,\" where and how much you sleep\"],[0,[],0,\". When we were sleeping in an office in LA we had to sleep on the floor because mattresses would’ve raised too much attention and in order to not get caught we had a sleeping window between 2am and 7am which was when the cleaning people left and the first people came to work. In Amsterdam we slept in a hostel room together with 30 other people.\"]]]],[1,\"p\",[[0,[],0,\"I didn’t include this so you feel sorry for us. There are people in this world who live in much worse conditions. I included this to point out that when people are thinking about starting companies because they celebrate the stories where Elon Musk slept in his office instead of getting an apartment or when he talks about putting in 120h weeks during crazy periods at Tesla, that they forget there is another side to this coin. \"],[1,[],0,17],[0,[1],1,\"Just because you do this doesn’t mean you will be successful and if you’re not, the world doesn’t care about it.\"]]],[1,\"p\",[[0,[],0,\"Do the one thing the world does care about: \"],[1,[],0,18],[0,[],0,\"Build great products that solve a real need in people’s lives, make the world a better place and make sure to become profitable with doing that so you can build a sustainable business for the long-term.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>The other often overlooked and not-so-glamorous side of the founder’s story.</p><p><a href=\"https://medium.com/@ricomeinl/the-world-doesnt-care-lessons-from-startup-failure-f960dfc6be8a\">Read this article on Medium.</a></p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://cdn-images-1.medium.com/max/2400/1*AsK8E3zZ78yf3iG1c1uiSA.jpeg\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Photo by <a href=\"https://unsplash.com/@sebastian_unrau?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\" data-href=\"https://unsplash.com/@sebastian_unrau?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\" class=\"markup--anchor markup--figure-anchor\" rel=\"noopener\" target=\"_blank\">Sebastian Unrau</a> on&nbsp;<a href=\"https://unsplash.com/s/photos/forest?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\" data-href=\"https://unsplash.com/s/photos/forest?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\" class=\"markup--anchor markup--figure-anchor\" rel=\"noopener\" target=\"_blank\">Unsplash</a></figcaption></figure><p>Everyone loves the good old startup story of the young college dropout who started from his dorm room, built an amazing product, assembled a team of equally smart people, worked incredibly hard and went on to change the world. In my opinion the ideology of starting your own startup has been completely overhyped in the recent years (maybe even longer but that’s as far as I can judge) and young people start companies just for the sake of being a part of this story. I thought it’d be interesting to contribute my story which often remains untold because we all shy away from admitting to failure.</p><p>My name is Rico, I am a 22 y/o entrepreneur and the technical co-founder of a FashionTech startup which we’ve recently put on hold. Having completed my first attempt of founding a startup I wanted to share a couple of painful lessons that I took away from this experience.</p><p>Before I get to my real list, let me quickly explain why I included my age in the previous sentence. This is actually the first fallacy I fell for: thinking you’re awesome because you went on a leave of absence from college to co-found a startup at age 21. <br><strong>Breaking news: the world doesn’t care.</strong> <br><strong>Investors don’t care. And most importantly, your customers don’t care.</strong> Don’t follow the hype stories of Zuckerberg, Gates and Jobs and think it gives you an advantage to start something while you’re young. It’s nice to have an idea and be able to <a href=\"https://youtu.be/pg9fRGlW-2U?t=173\" rel=\"noopener\">start something while you’re young</a> because you usually don’t have that much to lose and no family to take care of but it shouldn’t be the reason in the first place.</p><p>Now, to the actual learnings. Before you start reading this, I want to point out that I made 1 attempt to start a company so far and it didn’t succeed. This article is about what I learned not to do. <br><em>But, please take my advice with a grain of salt</em>. <br>If you want to learn how to do it right, <a href=\"https://www.alicorn.blog\" rel=\"noopener\">check out my blog</a>. It only contains books recommended or written by billionaire founders.</p><hr><p>As a quick background: I don’t like to go shopping and also don’t want to spend much of my time going to the mall. Still, I like to dress well. Online shopping is even worse because I have really long legs and nothing I ever ordered fit me well. My co-founder and I bonded through that problem when he had started working as a salesperson in a retail store in Hamburg to understand the customer needs in this segment. We joined forces in November 2018 and built an algorithm that allows people to measure themselves with their phone to find perfect fitting clothes. We started with only jeans to have focus and because so many people struggle to find a pair that fits well. In April 2019 we moved to Amsterdam and started working with two jeans brands and tried to sell the technology as a plugin to the online retailers (we talked with ASOS, Levi’s, Zappos, Nordstrom, AboutYou). In August 2019 we moved to Los Angeles and pivoted into B2C (all the major jeans brands are located there). Recently we put the company on hold.</p><hr><h3 id=\"-1-start-with-a-problem-in-your-own-life\">#1 Start with a Problem in Your Own Life</h3><blockquote>We were building a product that we ourselves were the customer for. — <a href=\"https://youtu.be/pg9fRGlW-2U?t=479\" rel=\"noopener\">Steve Jobs</a></blockquote><p>This is probably the most painful but also the most valuable lesson of all. Especially because I had seen the video about Steve Jobs saying that a couple times. But there’s quite a difference between consuming information and then acting on it. We didn’t act on it. When we built the body measurement technology we decided to start with women. There were many reasons for that decision and I won’t go into depth here but what we painfully learned was that it is really hard to create a <strong>great</strong> consumer product. To get all the tiny details right, you’ll have a much better starting point when you’re building something for yourself.</p><p>To frame the problem we were trying to solve we used the “Jobs Theory” framework described by Clayton Christensen in his book “<a href=\"https://www.alicorn.blog/books/competing-against-luck-innovation-customer\" rel=\"noopener\">Competing Against Luck</a>”: <em>What job do people hire our product for? </em><br>Though, we failed to apply this framework to our solution, aka how our product helps people accomplish the jobs they hired it for. We realized this later on when we were already in L.A. and pivoted to men and couldn’t imagine how our product would fit into our own lives.</p><p>The learning here is: <br><strong><em>Start with a problem in your own life and build a solution that you would use yourself.</em></strong></p><h3 id=\"-2-stay-relentlessly-focused-on-the-end-results-with-the-highest-impact-on-your-business-strategy\">#2 Stay Relentlessly Focused on the End Results with the Highest Impact on Your Business Strategy</h3><p>Setting measurable goals is great. Setting the right goals is hard. There is a reason why executives and company founders get paid so much. The hardest job in the world is deciding and prioritizing what to work on. And if you work on the wrong things, it doesn’t matter how hard you work. You’re probably not gonna get where you want to go.</p><p>We learned this the hard way, when we spent three months trying to get to +-1% measurement inaccuracy to impress the big retailers (so we thought) and convince them to work with us. Our assumption was that our product needs to work really well to succeed. <br>In our field that meant, being able to recommend people jeans that fit perfectly. In order for the jeans to fit perfectly, it needs to sit well at the hip, waist, upper thigh, mid thigh, calf and ankle. That’s one reason why jeans are amongst the hardest products to fit (and therefore our reasoning: if we solve this, everything else will be like a walk in the park). So, even though it is true that all the body parts I mentioned above need to be measured with +-1% inaccuracy for the jeans to fit perfectly, there’s a relative degree of importance. We later found out that the hip and waist for example have the highest impact on the end result.</p><p>Taking it one step further, the +-1% inaccuracy was a terrible metric to focus on when trying to start a business. The online retailers don’t care about the measurement inaccuracy. They care about products that drive conversion and reduce costs associated with returns. Customers don’t care about the measurement inaccuracy. They don’t even care about the technology in general. They care about saving time and effort and eventually if the jeans makes them look and feel good.</p><p>It’s so easy to feel good about yourself when you work super hard and make progress towards achieving goals but none of that matters if those goals are not aligned with your business strategy. I feel like this one is especially important for tech people (such as myself) who love to build cool things. The stuff that matters most for the business is not always the most fun.</p><p>The learning here is: <br><strong><em>Don’t get lost in the trenches and focus on the stuff that has the highest impact on the results you are trying to achieve as a business.</em></strong></p><p>I’ll throw in another one here: <strong><em>Don’t build something that doesn’t have short-term value because “we’ll definitely need it in the future”.</em></strong><br>I once cleaned up the whole code base for our web app and automatized one of our internal processes, just because I had some time on hand and thought that automation would definitely be useful and save time in the future. I was wrong. Not long after, the process changed and now it was super hard to add to it and I ended up wasting a lot of time reverting the automation I just implemented a week ago.</p><h3 id=\"-3-it-s-not-the-money-it-s-the-f-money-\">#3 It’s not the money. It’s the f****** money.</h3><p>This is what Bill Campbell told Ben Horowitz when he was planning to take his company Loudcloud public (from “<a href=\"https://www.alicorn.blog/books/hard-thing-about-hard-things-building-business\" rel=\"noopener\">The Hard Thing About Hard Things</a>”).</p><p>I thought this quote accurately captures the relationship you should entertain with money when starting a company. And by that I mean, <strong>how are you going to make money? </strong>As a tech person it’s easy to think that if you build something cool, you will somehow find a way for people to pay you for it.<br>But nowadays, especially in the era<strong> </strong>of mobile it’s not as easy as “just put ads on it”.</p><p>We made the mistake of thinking that our product has the potential to be so useful for people (save time and effort) and the online retailers (reduce online returns, which are at 60% for jeans) that we don’t need a business model but rather investors will fund us and we’ll figure out how to make money later. Needless to say, that was a bad strategy. During YC Startup School, Marc Andreessen once said the <a href=\"https://www.youtube.com/watch?v=uFX95HahaUs\" rel=\"noopener\">best way to raise money is to create a great business and then tell investors about it.</a> Not the other way around.</p><p>The learning here is: <br><strong><em>You’re running a business, not a research lab. If you don’t focus on the money, your business will die.</em></strong></p><h3 id=\"-4-be-careful-with-the-latest-research\">#4 Be careful with the latest research</h3><p>I think this one heavily depends on the field you’re in and I don’t know if this is the case in general so I’m happy to hear about your experience. We started with three co-founders and my initial role was not the technology part. When we became two co-founders and I was in charge of getting to +-1% measurement inaccuracy my approach was to contact different companies that were already working on this to see if we could buy the technology. <br>None of them had something that was good enough so we had to move ahead and build it ourselves. <br>I locked myself in my room during all of November and December and basically read every research paper that was ever written in this field. That took a lot of time and effort because the barrier you need to overcome until you fully understand all these deeply technical papers is extremely steep. Not a very good idea, when you’re <em>jumping off of a cliff trying to assemble a plane on the way down</em> (Reid Hoffman).</p><p>In addition to that almost all of the papers are not industry-ready, which means they are presented nicely but have underlying flaws in terms of performance, they only work for specific edge cases or with lab data. My advice is to always connect with the authors and ask them to help you understand the algorithms and ask about the limits of the paper beforehand. Another thing I learned is that many papers are oversold. If you think about it, it makes sense because as a researcher you have to show process in your work to keep the funding going. It’s just good to be aware of that when you are trying to assess whether any of the ideas from the papers could be used in practice. In theory it looks amazing but in practice the performance is heavily limited.</p><p>The learning here is: <br><strong><em>Unless you’re a PhD and know about what’s really possible in your field, be careful with trying to reimplement the latest research papers for your industry application.</em></strong></p><h3 id=\"-5-reach-out-to-experts\">#5 Reach out to Experts</h3><p>Before we started our journey, we came across the book “<a href=\"https://www.alicorn.blog/books/measure-what-matters-okr\" rel=\"noopener\">Measure What Matters</a>” by John Doerr, a heavily recommended book on OKRs (Objectives and Key Results), the management methodology from Intel which was implemented by Google back in the day and is still actively used. <br>Naturally we were intrigued to make this our standard methodology to set our monthly goals and how we’d get there. The book does mention the downside that it’s quite hard to implement and we struggled quite a bit with it. It just didn’t feel like it was dynamic enough because in a startup things change almost every day. <br>After 9 months I was tired of it and shot an email to some of the people interviewed in the book. Among them were Atticus Tysen, the CIO from Intuit and Brett Kopf, CEO of Remind. They both got back to me and their response was simple and clear: the methodology is too heavy and too much process for an early stage startup. Would’ve been good to know that before we started using it.</p><p>The learning here is: <br><strong><em>Always reach out to experts and ask for their advice before you start to implement something that requires as much time and effort like OKRs.</em></strong></p><hr><h3 id=\"wrapping-up\">Wrapping Up</h3><p>To sum up, here are my 5 Learnings:</p><ol><li><strong><em>Start with a problem in your own life and build a solution that you would use yourself.</em></strong></li><li><strong><em>Don’t get lost in the trenches and focus on the stuff that has the highest impact on the results you are trying to achieve as a business.</em></strong></li><li><strong><em>You’re running a business, not a research lab. If you don’t focus on the money, your business will die.</em></strong></li><li><strong><em>Unless you’re a PhD and know about what’s really possible in your field, be careful with trying to reimplement the latest research papers for your industry application.</em></strong></li><li><strong><em>Always reach out to experts and ask for their advice before you start to implement something that requires as much time and effort like OKRs.</em></strong></li></ol><p>Lastly, there are a lot of idealized founders’ stories out there but no one really talks about the other side:</p><ul><li>The world doesn’t care <strong>how old you are</strong> (see above).</li><li>The world doesn’t care <strong>if it’s new years or your birthday</strong>. We were up until 4am in the night before my birthday, slept 2 hours and then went to a customer presentation in the morning. We worked all throughout new years eve.</li><li>The world doesn’t care <strong>how many hours you put in</strong>. 8.30am — 2.00am, 6 days a week.</li><li>The world doesn’t care<strong> where and how much you sleep</strong>. When we were sleeping in an office in LA we had to sleep on the floor because mattresses would’ve raised too much attention and in order to not get caught we had a sleeping window between 2am and 7am which was when the cleaning people left and the first people came to work. In Amsterdam we slept in a hostel room together with 30 other people.</li></ul><p>I didn’t include this so you feel sorry for us. There are people in this world who live in much worse conditions. I included this to point out that when people are thinking about starting companies because they celebrate the stories where Elon Musk slept in his office instead of getting an apartment or when he talks about putting in 120h weeks during crazy periods at Tesla, that they forget there is another side to this coin. <br><strong>Just because you do this doesn’t mean you will be successful and if you’re not, the world doesn’t care about it.</strong></p><p>Do the one thing the world does care about: <br>Build great products that solve a real need in people’s lives, make the world a better place and make sure to become profitable with doing that so you can build a sustainable business for the long-term.</p>","comment_id":"5f7a33833ffbdb6a6f04d6ac","plaintext":"The other often overlooked and not-so-glamorous side of the founder’s story.\n\nRead this article on Medium.\n[https://medium.com/@ricomeinl/the-world-doesnt-care-lessons-from-startup-failure-f960dfc6be8a]\n\nPhoto by Sebastian Unrau\n[https://unsplash.com/@sebastian_unrau?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText] \nonUnsplash\n[https://unsplash.com/s/photos/forest?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText]\nEveryone loves the good old startup story of the young college dropout who\nstarted from his dorm room, built an amazing product, assembled a team of\nequally smart people, worked incredibly hard and went on to change the world. In\nmy opinion the ideology of starting your own startup has been completely\noverhyped in the recent years (maybe even longer but that’s as far as I can\njudge) and young people start companies just for the sake of being a part of\nthis story. I thought it’d be interesting to contribute my story which often\nremains untold because we all shy away from admitting to failure.\n\nMy name is Rico, I am a 22 y/o entrepreneur and the technical co-founder of a\nFashionTech startup which we’ve recently put on hold. Having completed my first\nattempt of founding a startup I wanted to share a couple of painful lessons that\nI took away from this experience.\n\nBefore I get to my real list, let me quickly explain why I included my age in\nthe previous sentence. This is actually the first fallacy I fell for: thinking\nyou’re awesome because you went on a leave of absence from college to co-found a\nstartup at age 21. \nBreaking news: the world doesn’t care. \nInvestors don’t care. And most importantly, your customers don’t care. Don’t\nfollow the hype stories of Zuckerberg, Gates and Jobs and think it gives you an\nadvantage to start something while you’re young. It’s nice to have an idea and\nbe able to start something while you’re young\n[https://youtu.be/pg9fRGlW-2U?t=173] because you usually don’t have that much to\nlose and no family to take care of but it shouldn’t be the reason in the first\nplace.\n\nNow, to the actual learnings. Before you start reading this, I want to point out\nthat I made 1 attempt to start a company so far and it didn’t succeed. This\narticle is about what I learned not to do. \nBut, please take my advice with a grain of salt. \nIf you want to learn how to do it right, check out my blog\n[https://www.alicorn.blog]. It only contains books recommended or written by\nbillionaire founders.\n\n\n--------------------------------------------------------------------------------\n\nAs a quick background: I don’t like to go shopping and also don’t want to spend\nmuch of my time going to the mall. Still, I like to dress well. Online shopping\nis even worse because I have really long legs and nothing I ever ordered fit me\nwell. My co-founder and I bonded through that problem when he had started\nworking as a salesperson in a retail store in Hamburg to understand the customer\nneeds in this segment. We joined forces in November 2018 and built an algorithm\nthat allows people to measure themselves with their phone to find perfect\nfitting clothes. We started with only jeans to have focus and because so many\npeople struggle to find a pair that fits well. In April 2019 we moved to\nAmsterdam and started working with two jeans brands and tried to sell the\ntechnology as a plugin to the online retailers (we talked with ASOS, Levi’s,\nZappos, Nordstrom, AboutYou). In August 2019 we moved to Los Angeles and pivoted\ninto B2C (all the major jeans brands are located there). Recently we put the\ncompany on hold.\n\n\n--------------------------------------------------------------------------------\n\n#1 Start with a Problem in Your Own Life\n> We were building a product that we ourselves were the customer for. —Steve Jobs\n[https://youtu.be/pg9fRGlW-2U?t=479]\nThis is probably the most painful but also the most valuable lesson of all.\nEspecially because I had seen the video about Steve Jobs saying that a couple\ntimes. But there’s quite a difference between consuming information and then\nacting on it. We didn’t act on it. When we built the body measurement technology\nwe decided to start with women. There were many reasons for that decision and I\nwon’t go into depth here but what we painfully learned was that it is really\nhard to create a great consumer product. To get all the tiny details right,\nyou’ll have a much better starting point when you’re building something for\nyourself.\n\nTo frame the problem we were trying to solve we used the “Jobs Theory” framework\ndescribed by Clayton Christensen in his book “Competing Against Luck\n[https://www.alicorn.blog/books/competing-against-luck-innovation-customer]”: \nWhat job do people hire our product for? \nThough, we failed to apply this framework to our solution, aka how our product\nhelps people accomplish the jobs they hired it for. We realized this later on\nwhen we were already in L.A. and pivoted to men and couldn’t imagine how our\nproduct would fit into our own lives.\n\nThe learning here is: \nStart with a problem in your own life and build a solution that you would use\nyourself.\n\n#2 Stay Relentlessly Focused on the End Results with the Highest Impact on Your\nBusiness Strategy\nSetting measurable goals is great. Setting the right goals is hard. There is a\nreason why executives and company founders get paid so much. The hardest job in\nthe world is deciding and prioritizing what to work on. And if you work on the\nwrong things, it doesn’t matter how hard you work. You’re probably not gonna get\nwhere you want to go.\n\nWe learned this the hard way, when we spent three months trying to get to +-1%\nmeasurement inaccuracy to impress the big retailers (so we thought) and convince\nthem to work with us. Our assumption was that our product needs to work really\nwell to succeed. \nIn our field that meant, being able to recommend people jeans that fit\nperfectly. In order for the jeans to fit perfectly, it needs to sit well at the\nhip, waist, upper thigh, mid thigh, calf and ankle. That’s one reason why jeans\nare amongst the hardest products to fit (and therefore our reasoning: if we\nsolve this, everything else will be like a walk in the park). So, even though it\nis true that all the body parts I mentioned above need to be measured with +-1%\ninaccuracy for the jeans to fit perfectly, there’s a relative degree of\nimportance. We later found out that the hip and waist for example have the\nhighest impact on the end result.\n\nTaking it one step further, the +-1% inaccuracy was a terrible metric to focus\non when trying to start a business. The online retailers don’t care about the\nmeasurement inaccuracy. They care about products that drive conversion and\nreduce costs associated with returns. Customers don’t care about the measurement\ninaccuracy. They don’t even care about the technology in general. They care\nabout saving time and effort and eventually if the jeans makes them look and\nfeel good.\n\nIt’s so easy to feel good about yourself when you work super hard and make\nprogress towards achieving goals but none of that matters if those goals are not\naligned with your business strategy. I feel like this one is especially\nimportant for tech people (such as myself) who love to build cool things. The\nstuff that matters most for the business is not always the most fun.\n\nThe learning here is: \nDon’t get lost in the trenches and focus on the stuff that has the highest\nimpact on the results you are trying to achieve as a business.\n\nI’ll throw in another one here: Don’t build something that doesn’t have\nshort-term value because “we’ll definitely need it in the future”.\nI once cleaned up the whole code base for our web app and automatized one of our\ninternal processes, just because I had some time on hand and thought that\nautomation would definitely be useful and save time in the future. I was wrong.\nNot long after, the process changed and now it was super hard to add to it and I\nended up wasting a lot of time reverting the automation I just implemented a\nweek ago.\n\n#3 It’s not the money. It’s the f****** money.\nThis is what Bill Campbell told Ben Horowitz when he was planning to take his\ncompany Loudcloud public (from “The Hard Thing About Hard Things\n[https://www.alicorn.blog/books/hard-thing-about-hard-things-building-business]\n”).\n\nI thought this quote accurately captures the relationship you should entertain\nwith money when starting a company. And by that I mean, how are you going to\nmake money? As a tech person it’s easy to think that if you build something\ncool, you will somehow find a way for people to pay you for it.\nBut nowadays, especially in the era of mobile it’s not as easy as “just put ads\non it”.\n\nWe made the mistake of thinking that our product has the potential to be so\nuseful for people (save time and effort) and the online retailers (reduce online\nreturns, which are at 60% for jeans) that we don’t need a business model but\nrather investors will fund us and we’ll figure out how to make money later.\nNeedless to say, that was a bad strategy. During YC Startup School, Marc\nAndreessen once said the best way to raise money is to create a great business\nand then tell investors about it. [https://www.youtube.com/watch?v=uFX95HahaUs] \nNot the other way around.\n\nThe learning here is: \nYou’re running a business, not a research lab. If you don’t focus on the money,\nyour business will die.\n\n#4 Be careful with the latest research\nI think this one heavily depends on the field you’re in and I don’t know if this\nis the case in general so I’m happy to hear about your experience. We started\nwith three co-founders and my initial role was not the technology part. When we\nbecame two co-founders and I was in charge of getting to +-1% measurement\ninaccuracy my approach was to contact different companies that were already\nworking on this to see if we could buy the technology. \nNone of them had something that was good enough so we had to move ahead and\nbuild it ourselves. \nI locked myself in my room during all of November and December and basically\nread every research paper that was ever written in this field. That took a lot\nof time and effort because the barrier you need to overcome until you fully\nunderstand all these deeply technical papers is extremely steep. Not a very good\nidea, when you’re jumping off of a cliff trying to assemble a plane on the way\ndown (Reid Hoffman).\n\nIn addition to that almost all of the papers are not industry-ready, which means\nthey are presented nicely but have underlying flaws in terms of performance,\nthey only work for specific edge cases or with lab data. My advice is to always\nconnect with the authors and ask them to help you understand the algorithms and\nask about the limits of the paper beforehand. Another thing I learned is that\nmany papers are oversold. If you think about it, it makes sense because as a\nresearcher you have to show process in your work to keep the funding going. It’s\njust good to be aware of that when you are trying to assess whether any of the\nideas from the papers could be used in practice. In theory it looks amazing but\nin practice the performance is heavily limited.\n\nThe learning here is: \nUnless you’re a PhD and know about what’s really possible in your field, be\ncareful with trying to reimplement the latest research papers for your industry\napplication.\n\n#5 Reach out to Experts\nBefore we started our journey, we came across the book “Measure What Matters\n[https://www.alicorn.blog/books/measure-what-matters-okr]” by John Doerr, a\nheavily recommended book on OKRs (Objectives and Key Results), the management\nmethodology from Intel which was implemented by Google back in the day and is\nstill actively used. \nNaturally we were intrigued to make this our standard methodology to set our\nmonthly goals and how we’d get there. The book does mention the downside that\nit’s quite hard to implement and we struggled quite a bit with it. It just\ndidn’t feel like it was dynamic enough because in a startup things change almost\nevery day. \nAfter 9 months I was tired of it and shot an email to some of the people\ninterviewed in the book. Among them were Atticus Tysen, the CIO from Intuit and\nBrett Kopf, CEO of Remind. They both got back to me and their response was\nsimple and clear: the methodology is too heavy and too much process for an early\nstage startup. Would’ve been good to know that before we started using it.\n\nThe learning here is: \nAlways reach out to experts and ask for their advice before you start to\nimplement something that requires as much time and effort like OKRs.\n\n\n--------------------------------------------------------------------------------\n\nWrapping Up\nTo sum up, here are my 5 Learnings:\n\n 1. Start with a problem in your own life and build a solution that you would\n    use yourself.\n 2. Don’t get lost in the trenches and focus on the stuff that has the highest\n    impact on the results you are trying to achieve as a business.\n 3. You’re running a business, not a research lab. If you don’t focus on the\n    money, your business will die.\n 4. Unless you’re a PhD and know about what’s really possible in your field, be\n    careful with trying to reimplement the latest research papers for your\n    industry application.\n 5. Always reach out to experts and ask for their advice before you start to\n    implement something that requires as much time and effort like OKRs.\n\nLastly, there are a lot of idealized founders’ stories out there but no one\nreally talks about the other side:\n\n * The world doesn’t care how old you are (see above).\n * The world doesn’t care if it’s new years or your birthday. We were up until\n   4am in the night before my birthday, slept 2 hours and then went to a\n   customer presentation in the morning. We worked all throughout new years eve.\n * The world doesn’t care how many hours you put in. 8.30am — 2.00am, 6 days a\n   week.\n * The world doesn’t care where and how much you sleep. When we were sleeping in\n   an office in LA we had to sleep on the floor because mattresses would’ve\n   raised too much attention and in order to not get caught we had a sleeping\n   window between 2am and 7am which was when the cleaning people left and the\n   first people came to work. In Amsterdam we slept in a hostel room together\n   with 30 other people.\n\nI didn’t include this so you feel sorry for us. There are people in this world\nwho live in much worse conditions. I included this to point out that when people\nare thinking about starting companies because they celebrate the stories where\nElon Musk slept in his office instead of getting an apartment or when he talks\nabout putting in 120h weeks during crazy periods at Tesla, that they forget\nthere is another side to this coin. \nJust because you do this doesn’t mean you will be successful and if you’re not,\nthe world doesn’t care about it.\n\nDo the one thing the world does care about: \nBuild great products that solve a real need in people’s lives, make the world a\nbetter place and make sure to become profitable with doing that so you can build\na sustainable business for the long-term.","feature_image":null,"featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2020-10-04 20:41:39","created_by":"1","updated_at":"2021-04-25 14:07:17","updated_by":"1","published_at":"2019-12-16 21:41:00","published_by":"1","custom_excerpt":"The other often overlooked and not-so-glamorous side of the founder’s story.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"6085751174348916f1b0899d","uuid":"cd196b05-5544-4c0c-a522-76704596b1d9","title":"Recommender Systems: The Most Valuable Application of Machine Learning (Part 1)","slug":"recommender-systems-the-most-valuable-application-of-machine-learning-part-1","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"https://cdn-images-1.medium.com/max/1600/1*F2mBbZRHPXxa3cyg3z8esg.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"Recommender Systems already drive almost every aspect of our daily&nbsp;lives.\"}],[\"hr\",{}],[\"hr\",{}],[\"image\",{\"src\":\"https://cdn-images-1.medium.com/max/1600/1*U_eUe0NBy7uQPA10SFY-VQ.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"The Virtuous Business Cycle of Recommender Systems (source: <a href=\\\"https://www.mdpi.com/2199-8531/5/3/44/htm\\\" data-href=\\\"https://www.mdpi.com/2199-8531/5/3/44/htm\\\" class=\\\"markup--anchor markup--figure-anchor\\\" rel=\\\"noopener\\\" target=\\\"_blank\\\">MDPI</a>,&nbsp;CC)\"}],[\"hr\",{}],[\"hr\",{}],[\"hr\",{}],[\"image\",{\"src\":\"https://cdn-images-1.medium.com/max/1600/1*6LG9QN2XEtK6UCOZG4cavA.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"2-stage Recommender System (inspired by&nbsp;<a href=\\\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\\\" data-href=\\\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\\\" class=\\\"markup--anchor markup--figure-anchor\\\" rel=\\\"noopener\\\" target=\\\"_blank\\\">YouTube</a>)\"}],[\"image\",{\"src\":\"https://cdn-images-1.medium.com/max/1600/1*dkvXGVpAlK25F-WznatMMA.png\",\"alt\":\"\",\"title\":\"\"}],[\"hr\",{}],[\"hr\",{}]],\"markups\":[[\"a\",[\"href\",\"https://towardsdatascience.com/recommender-systems-the-most-valuable-application-of-machine-learning-part-1-f96ecbc4b7f5\"]],[\"a\",[\"href\",\"https://hbr.org/2017/08/great-digital-companies-build-great-recommendation-engines\",\"rel\",\"noopener\"]],[\"em\"],[\"a\",[\"href\",\"https://dl.acm.org/doi/pdf/10.1145/2843948\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.mckinsey.com/industries/retail/our-insights/how-retailers-can-keep-up-with-consumers\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e\"]],[\"strong\"],[\"a\",[\"href\",\"https://www.amazon.science/the-history-of-amazons-recommendation-algorithm\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://ls13-www.cs.tu-dortmund.de/homepage/rsweb2014/papers/rsweb2014_submission_3.pdf\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe\"]],[\"a\",[\"href\",\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-recommendation-engine-python/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://pdfs.semanticscholar.org/f635/6c70452b3f56dc1ae07b4649a80239afb1b6.pdf\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789\"]],[\"a\",[\"href\",\"https://arxiv.org/pdf/1409.2944.pdf\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=giIXNoiqO_U&list=PL-6SiIrhTAi6x4Oq28s7yy94ubLzVXabj\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://eng.uber.com/uber-eats-graph-learning/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.slideshare.net/MrChrisJohnson/from-idea-to-execution-spotifys-discover-weekly/31-1_0_0_0_1\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://arxiv.org/pdf/1606.07154.pdf\",\"rel\",\"noopener nofollow noopener noopener noopener\"]],[\"a\",[\"href\",\"https://arxiv.org/pdf/1607.01869.pdf\",\"rel\",\"noopener nofollow noopener noopener noopener\"]],[\"a\",[\"href\",\"https://www.zillow.com/tech/embedding-similar-home-recommendation/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"http://snap.stanford.edu/graphsage/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://keras.io/api/layers/core_layers/embedding/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://developers.google.com/machine-learning/crash-course/embeddings/obtaining-embeddings\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"http://en.wikipedia.org/wiki/Learning_to_rank\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://netflixtechblog.com/learning-a-personalized-homepage-aa8ec670359a\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://labs.spotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://eng.uber.com/uber-eats-recommending-marketplace/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.inf.unibz.it/~ricci/ISR/papers/p293-davidson.pdf\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture\",\"rel\",\"noopener\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Why Recommender Systems are the most valuable application of Machine Learning and how Machine Learning-driven Recommenders already drive almost every aspect of our lives.\"]]],[1,\"p\",[[0,[0],1,\"Read this article on Medium.\"]]],[10,0],[10,1],[1,\"p\",[[0,[],0,\"Look back at your week: a Machine Learning algorithm determined what songs you might like to listen to, what food to order online, what posts you see on your favorite social networks, as well as the next person you may want to connect with, what series or movies you would like to watch, etc…\"]]],[1,\"p\",[[0,[],0,\"Machine Learning already guides so many aspects of our life without us necessarily being conscious of it. All of the applications mentioned above are driven by one type of algorithm: recommender systems.\"]]],[1,\"p\",[[0,[],0,\"In this article, I will explore and dive deeper into all the aspects that come into play to build a successful recommender system. The length of this article got a little out of hand so I decided to split it into two parts. This first part will cover:\"]]],[3,\"ul\",[[[0,[],0,\"Business Value\"]],[[0,[],0,\"Problem Formulation\"]],[[0,[],0,\"Data\"]],[[0,[],0,\"Algorithms\"]]]],[1,\"p\",[[0,[],0,\"The Second Part will cover:\"]]],[3,\"ul\",[[[0,[],0,\"Evaluation Metrics\"]],[[0,[],0,\"User Interface\"]],[[0,[],0,\"Cold-start Problem\"]],[[0,[],0,\"Exploration vs. Exploitation\"]],[[0,[],0,\"The Future of Recommender Systems\"]]]],[1,\"p\",[[0,[],0,\"Throughout this article, I will be using examples of the companies that have built the most widely used systems over the last couple of years, including Airbnb, Amazon, Instagram, LinkedIn, Netflix, Spotify, Uber Eats, and YouTube.\"]]],[10,2],[1,\"h3\",[[0,[],0,\"Business Value\"]]],[1,\"p\",[[0,[],0,\"Harvard Business Review made a strong statement by calling Recommenders the \"],[0,[1],1,\"single most important algorithmic distinction between “born digital” enterprises and legacy companies\"],[0,[],0,\". HBR also described the virtuous business cycle these can generate: the more people use a company’s Recommender System, the more valuable they become and the more valuable they become, the more people use them.\"]]],[10,3],[1,\"p\",[[0,[],0,\"We are encouraged to look at recommender systems, not as a way to sell more online, but rather to see it as a renewable resource for \"],[0,[2],1,\"relentlessly improving customer insights and our own insights as well\"],[0,[],0,\". If we look at the illustration above, we can see that many legacy companies also have tons of users and therefore tons of data. The reason their virtuous cycle has not picked up as much as the ones off Amazon, Netflix or Spotify is because of the lack of knowledge on how to convert their user data into actionable insights, which can then be used to improve their product or services.\"]]],[1,\"p\",[[0,[],0,\"Looking at Netflix, for example, shows how crucial this is, as 80% of what people watch comes from some sort of recommendation. In \"],[0,[3],1,\"2015, one of their papers quoted\"],[0,[],0,\":\"]]],[1,\"blockquote\",[[0,[],0,\"“We think the combined effect of personalization and recommendations save us more than $1B per year.”\"]]],[1,\"p\",[[0,[],0,\"If we look at Amazon, \"],[0,[4],1,\"35% of what customers purchase at Amazon\"],[0,[],0,\" comes from product recommendations and at Airbnb, Search Ranking and Similar Listings drive \"],[0,[5],1,\"99% of all booking conversions\"],[0,[],0,\".\"]]],[10,4],[1,\"h3\",[[0,[],0,\"Problem Formulation\"]]],[1,\"p\",[[0,[],0,\"Now that we’ve seen the immense value, companies can gain from Recommender Systems, let’s look at the type of challenges that can be solved by them. Generally speaking, tech companies are trying to recommend the \"],[0,[6],1,\"most relevant content\"],[0,[],0,\" to their users. That could mean:\"]]],[3,\"ul\",[[[0,[],0,\"similar home listings (Airbnb, Zillow)\"]],[[0,[],0,\"relevant media, e.g. photos, videos and stories (Instagram)\"]],[[0,[],0,\"relevant series and movies (Netflix, Amazon Prime Video)\"]],[[0,[],0,\"relevant songs and podcasts (Spotify)\"]],[[0,[],0,\"relevant videos (YouTube)\"]],[[0,[],0,\"similar users, posts (LinkedIn, Twitter, Instagram)\"]],[[0,[],0,\"relevant dishes and restaurants (Uber Eats)\"]]]],[1,\"p\",[[0,[],0,\"The formulation of the problem is critical here. Most of the time, companies want to recommend content that users are most likely to enjoy in the future. The reformulation of this problem, as well as the algorithmic changes from recommending “what users are most likely to watch” to “what users are most likely to watch \"],[0,[2],1,\"in the future\"],[0,[],0,\"” \"],[0,[7],1,\"allowed Amazon PrimeVideo to gain a 2x improvement\"],[0,[],0,\", a “once-in-a-decade leap” for their movie Recommender System.\"]]],[1,\"blockquote\",[[0,[],0,\"“Amazon researchers found that using neural networks to generate movie recommendations worked much better when they sorted the input data chronologically and used it to predict future movie preferences over a short (one- to two-week) period.”\"]]],[10,5],[1,\"h3\",[[0,[],0,\"Data\"]]],[1,\"p\",[[0,[],0,\"Recommender Systems usually take two types of data as input:\"]]],[3,\"ul\",[[[0,[6],1,\"User Interaction Data \"],[0,[],0,\"(Implicit/Explicit)\"]],[[0,[6],1,\"Item Data\"],[0,[],0,\" (Features)\"]]]],[1,\"p\",[[0,[],0,\"The “classic”, and still widely used approach to recommender systems based on \"],[0,[6],1,\"collaborative filtering\"],[0,[],0,\" (used by \"],[0,[8],1,\"Amazon\"],[0,[],0,\", \"],[0,[9],1,\"Netflix\"],[0,[],0,\", \"],[0,[10],1,\"LinkedIn\"],[0,[],0,\", \"],[0,[11],1,\"Spotify\"],[0,[],0,\" and \"],[0,[12],1,\"YouTube\"],[0,[],0,\") uses either User-User or Item-Item relationships to find similar content. I’m not going to go deeper into the inner workings of this, as there are a lot of articles on that topic — \"],[0,[13],1,\"like this one\"],[0,[],0,\" — that explain this concept well.\"]]],[1,\"p\",[[0,[],0,\"The \"],[0,[2],1,\"user interaction data\"],[0,[],0,\" is the data we gather from the weblogs and can be divided into two groups:\"]]],[1,\"p\",[[0,[6,2],2,\"Explicit data\"],[0,[],0,\": explicit input from our users (e.g. movie ratings, search logs, liked, commented, watched, favorited, etc.)\"]]],[1,\"p\",[[0,[6,2],2,\"Implicit data\"],[0,[],0,\": information that is not provided intentionally but gathered from available data streams (e.g. search history, order history, clicked on, accounts interacted with, etc.)\"]]],[1,\"p\",[[0,[],0,\"The \"],[0,[2],1,\"item data\"],[0,[],0,\" consists mainly of an item’s features. In YouTube’s case that would be a video’s metadata such as title and description. For Zillow, this could be a home’s Zip Code, City Region, Price, or Number of Bedrooms for instance.\"]]],[1,\"p\",[[0,[],0,\"Other data sources could be \"],[0,[6,2],2,\"external data\"],[0,[],0,\" (for example, Netflix might \"],[0,[14],1,\"add external item data features\"],[0,[],0,\" such as box office performance or critic reviews) or \"],[0,[6],1,\"expert-generated data\"],[0,[],0,\" (Pandora’s \"],[0,[15],1,\"Music Genome Project\"],[0,[],0,\" uses human input to apply values for each song in each of approximately 400 musical attributes).\"]]],[1,\"p\",[[0,[],0,\"A key insight here is that obviously, having more data about your users will inevitably lead to better model results (if applied correctly), however, as Airbnb shows in their \"],[0,[16],1,\"3-part journey to building a Ranking Model for Airbnb Experiences\"],[0,[],0,\" you can already achieve quite a lot with lesser data: the team at Airbnb already improved bookings by +13% with just 500 experiences and 50k training data size.\"]]],[1,\"blockquote\",[[0,[],0,\"“The main take-away is: \"],[0,[2],1,\"Don’t wait until you have big data, you can do quite a bit with small data to help grow and improve your business.\"],[0,[],0,\"”\"]]],[10,6],[1,\"h3\",[[0,[],0,\"Algorithms\"]]],[1,\"p\",[[0,[],0,\"Often, we associate Recommender Systems with just collaborative filtering. That’s fair, as in the past this has been the go-to method for a lot of the companies that have deployed successful systems in practice. Amazon was probably the first company to leverage \"],[0,[8],1,\"item-to-item collaborative filtering\"],[0,[],0,\". When they first released the inner workings of their method in a paper in 2003, the system had already been in use for six years.\"]]],[1,\"p\",[[0,[],0,\"Then, in 2006 Netflix followed suit with its famous Netflix Price Challenge which offered $1 million to whoever improved the accuracy of their existing system called \"],[0,[2],1,\"Cinematch\"],[0,[],0,\" by 10%. Collaborative filtering was also a part of the early Recommender Systems at \"],[0,[11],1,\"Spotify\"],[0,[],0,\" and \"],[0,[17],1,\"YouTube\"],[0,[],0,\". LinkedIn even developed a horizontal collaborative filtering infrastructure, \"],[0,[10],1,\"known as Browsemaps\"],[0,[],0,\". This platform enables rapid development, deployment, and computation of collaborative filtering recommendations for almost any use case on LinkedIn.\"]]],[1,\"p\",[[0,[],0,\"If you want to know more about collaborative filtering, I would recommend checking out \"],[0,[18],1,\"Section 16 of Andrew Ng’s Machine Learning course on Coursera\"],[0,[],0,\" where he goes deeper into the math behind it.\"]]],[1,\"p\",[[0,[],0,\"Now, I would like to take a step back and generalize the concept of a Recommender System. While many companies used to rely on collaborative filtering, today there are a lot of other different algorithms at play that either complement or even replaced the collaborative filtering approach. Netflix went through this change when they shifted from a DVD shipping to a streaming business. As described in one of their papers:\"]]],[1,\"blockquote\",[[0,[],0,\"“We indeed relied on such an algorithm heavily when our main business was shipping DVDs by mail, partly because in that context, a star rating was the main feedback that we received that a member had actually watched the video. […] But the days when stars and DVDs were the focus of recommendations at Netflix have long passed. […] Now, our recommender system consists of a variety of algorithms that collectively define the Netflix experience, most of which come together on the Netflix homepage.”\"]]],[1,\"p\",[[0,[],0,\"If we zoom out a little bit and look at Recommender Systems more broadly we find that they essentially consist of two parts:\"]]],[3,\"ol\",[[[0,[6],1,\"Candidate Generation\"]],[[0,[6],1,\"Ranking\"]]]],[1,\"p\",[[0,[],0,\"I am going to use \"],[0,[12],1,\"YouTube’s Recommender System\"],[0,[],0,\" as an example below as they provided a good visualization, but that very same concept is applied by Instagram for \"],[0,[19],1,\"recommendations in “Instagram Explore”\"],[0,[],0,\", by Uber Eats in their \"],[0,[20],1,\"Dish and Restaurant Recommender System\"],[0,[],0,\", by Netflix for their \"],[0,[14],1,\"movie recommendations \"],[0,[],0,\"and probably many other companies.\"]]],[10,7],[1,\"p\",[[0,[],0,\"According to Netflix, the goal of Recommender Systems is to present a number of attractive items for a person to choose from. This is usually accomplished by selecting some items (\"],[0,[2],1,\"candidate generation\"],[0,[],0,\") and sorting them (\"],[0,[2],1,\"ranking\"],[0,[],0,\") in the order of expected enjoyment (or utility).\"]]],[1,\"p\",[[0,[],0,\"Let’s further investigate the two stages:\"]]],[1,\"h4\",[[0,[],0,\"Candidate Generation\"]]],[1,\"p\",[[0,[],0,\"In this stage, we want to source the relevant candidates that could be eligible to show to our users. Here, we are working with the whole catalog of items so it can be quite large (YouTube and Instagram are great examples here). The key to doing this is entity embeddings. What are entity embeddings?\"]]],[1,\"p\",[[0,[],0,\"An entity embedding is a mathematical vector representation of an entity such that its dimensions might represent certain properties. Twitter has a great example of this in a \"],[0,[21],1,\"blog post about Embeddings@Twitter\"],[0,[],0,\": say we have two NBA players (Stephen Curry and LeBron James) and two musicians (Kendrick Lamar and Bruno Mars). We expect the distance between the embeddings of the NBA players to be smaller than the distance between the embeddings of a player and a musician. We can calculate the distance between two embeddings using the formula for Euclidean distance.\"]]],[1,\"p\",[[0,[6,2],2,\"How do we come up with these embeddings?\"]]],[1,\"p\",[[0,[],0,\"Well, one way to do this would be collaborative filtering. We have our items and our users. If we put them in a matrix (for the example of Spotify) it could look like this:\"]]],[10,8],[1,\"p\",[[0,[],0,\"After applying the \"],[0,[22],1,\"matrix factorization algorithm\"],[0,[],0,\", we end up with user vectors and song vectors. To find out which users’ tastes are most similar to another’s, collaborative filtering compares one users’ vector with all of the other users’ vectors, ultimately spitting out which users are the closest matches. The same goes for the Y vector, \"],[0,[2],1,\"songs\"],[0,[],0,\": you can compare a single song’s vector with all the others, and find out which songs are most similar to the one in question.\"]]],[1,\"p\",[[0,[],0,\"Another way to do this takes inspiration from applications in the domain of Natural Language Processing. Researchers generalized the \"],[0,[23],1,\"word2vec algorithm\"],[0,[],0,\", developed by Google in the early 2010s to all entities appearing in a similar context. In word2vec, the networks are trained by directly taking into account the word order and their co-occurrence, based on the assumption that words frequently appearing together in the sentences also share more statistical dependence. As Airbnb describes, in their \"],[0,[5],1,\"blog post about creating Listing Embeddings\"],[0,[],0,\":\"]]],[1,\"blockquote\",[[0,[],0,\"More recently, the concept of embeddings has been extended beyond word representations to other applications outside of NLP domain. Researchers from the Web Search, E-commerce and Marketplace domains have realized that just like one can train word embeddings by treating a sequence of words in a sentence as context, the same can be done for training embeddings of user actions by treating sequence of user actions as context. Examples include learning representations of \"],[0,[24],1,\"items that were clicked or purchased\"],[0,[],0,\" or \"],[0,[25],1,\"queries and ads that were clicked\"],[0,[],0,\". These embeddings have subsequently been leveraged for a variety of recommendations on the Web.\"]]],[1,\"p\",[[0,[],0,\"Apart from Airbnb, this concept is used by Instagram (IG2Vec) to\"],[0,[19],1,\" learn account embeddings\"],[0,[],0,\", by YouTube to \"],[0,[12],1,\"learn video embeddings\"],[0,[],0,\" and by Zillow to \"],[0,[26],1,\"learn categorical embeddings\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Another, more novel approach to this is called Graph Learning and it is \"],[0,[20],1,\"used by Uber Eats for their dish and restaurant embeddings\"],[0,[],0,\". They represent each of their dishes and restaurant in a separate graph and apply the \"],[0,[27],1,\"GraphSAGE algorithm\"],[0,[],0,\" to obtain the representations (embeddings) of the respective nodes.\"]]],[1,\"p\",[[0,[],0,\"And last but not least, we can also learn an embedding as part of the neural network for our target task. This approach gets you an embedding well customized for your particular system, but may take longer than training the embedding separately. The \"],[0,[28],1,\"Keras Embedding Layer\"],[0,[],0,\" would be one way to achieve this. Google covers this well as part of their \"],[0,[29],1,\"Machine Learning Crash Course.\"]]],[1,\"p\",[[0,[],0,\"Once we have this vectorial representation of our items we can simply use Nearest Neighbour Search to find our potential candidates. \"],[1,[],0,0],[0,[19],1,\"Instagram, for example\"],[0,[],0,\", defines a couple of seed accounts (accounts that people have interacted with in the past) and uses their IG2Vec account embeddings to find similar accounts that are like those. Based on these accounts, they are able to find the media that these accounts posted or engaged with. By doing that, they are able to filter billions of media items down to a couple thousand and then sample 500 candidates from the pool and send those candidates downstream to the ranking stage.\"]]],[1,\"p\",[[0,[],0,\"This phase can also be guided by business rules or just user input (the more information we have the more specific we can be). As Uber Eats mentions \"],[0,[20],1,\"in one of their blog posts\"],[0,[],0,\", for instance, pre-filtering can be based on factors such as geographical location.\"]]],[1,\"p\",[[0,[],0,\"So, to summarize:\"]]],[1,\"p\",[[0,[2],1,\"In the candidate generation (or sourcing) phase, we filter our whole content catalog for a smaller subset of items that our users might be interested in. To do this we need to map our items into a mathematical representation called embeddings so we can use a similarity function to find the most similar items in space. There are several ways to achieve this. Three of them being collaborative filtering, word2vec for entities, and graph learning.\"]]],[1,\"h4\",[[0,[],0,\"Ranking\"]]],[1,\"p\",[[0,[],0,\"Let’s loop back to the case of Instagram. After the candidate generation stage, we have about 500 media items that are potentially relevant and that we could show to a user in their “Explore” feed. \"],[1,[],0,1],[0,[],0,\"But which ones are going to be the \"],[0,[6],1,\"most relevant\"],[0,[],0,\"?\"]]],[1,\"p\",[[0,[],0,\"Because, after all, there are only 25 spots on the first page of the “Explore” section. And if the first items suck, the user is not going to be impressed nor intrigued to keep browsing. Netflix’s and Amazon PrimeVideo’s web interface \"],[0,[7],1,\"shows only the top 6 recommendations on the first page\"],[0,[],0,\" associated with each title in its catalog. \"],[0,[22],1,\"Spotify’s Discover Weekly\"],[0,[],0,\" Playlist contains only 30 songs. \"],[1,[],0,2],[0,[],0,\"Also, all of this is subject to the users’ device. Smartphones, of course, allowing for less space for relevant recommendations than a web browser.\"]]],[1,\"p\",[[0,[],0,\"“There are many ways one could construct a ranking function ranging from simple scoring methods, to pairwise preferences, to optimization over the entire ranking. If we were to formulate this as a Machine Learning problem, we could select positive and negative examples from our historical data and let a Machine Learning algorithm learn the weights that optimize our goal. This family of Machine Learning problems is known as “\"],[0,[30],1,\"Learning to rank\"],[0,[],0,\"” and is central to application scenarios such as search engines or ad targeting. In the ranking stage, we are not aiming for our items to have a global notion of \"],[0,[2],1,\"relevance\"],[0,[],0,\", but rather look for ways of optimizing a personalized model” \"],[0,[2],1,\"(Extract from \"],[0,[14,2],2,\"Netflix Blog Post\"],[0,[2],1,\").\"]]],[1,\"p\",[[0,[],0,\"To accomplish this, \"],[0,[19],1,\"Instagram uses a three-stage ranking infrastructure\"],[0,[],0,\" to help balance the trade-offs between ranking relevance and computation efficiency. In the \"],[0,[20],1,\"case of Uber Eats\"],[0,[],0,\", their personalized ranking system is “a fully-fledged ML model that ranks the pre-filtered dish and restaurant candidates based on additional contextual information, such as the day, time, and current location of the user when they open the Uber Eats app”. In general, the level of complexity for your model really depends on the size of your feature space. Many supervised classification methods can be used for ranking. Typical choices include Logistic Regression, Support Vector Machines, Neural Networks, or Decision Tree-based methods such as Gradient Boosted Decision Trees (GBDT). On the other hand, a great number of algorithms specifically designed for learning to rank have appeared in recent years such as RankSVM or RankBoost.\"]]],[1,\"p\",[[0,[],0,\"To summarise:\"]]],[1,\"p\",[[0,[2],1,\"After selecting initial candidates for our recommendations, in the ranking stage, we need to design a ranking function that ranks items by their relevance. This can be formulated as a Machine Learning problem, and the goal here is to optimize a personalized model for each user. This step is important because in most interfaces we have limited space to recommend items so we need to make the best use of that space by putting the most relevant items at the very top.\"]]],[1,\"h4\",[[0,[],0,\"Baseline\"]]],[1,\"p\",[[0,[],0,\"As for every Machine Learning algorithm, we need a good baseline to measure the improvement of any change. A good baseline to start with is just to use the \"],[0,[7],1,\"most popular items in the catalog, as described by Amazon\"],[0,[],0,\":\"]]],[1,\"blockquote\",[[0,[],0,\"“In the recommendations world, there’s a cardinal rule. If I know nothing about you, then the best things to recommend to you are the most popular things in the world.”\"]]],[1,\"p\",[[0,[],0,\"However, if you don’t even know what is most popular, because you just launched a new product or new items — as was the case with \"],[0,[16],1,\"Airbnb Experiences\"],[0,[],0,\" — you can just randomly re-rank the item collection daily until you have gathered enough data for your first model.\"]]],[10,9],[1,\"p\",[[0,[],0,\"That’s a wrap for Part 1 of this series. There are a couple of points I wanted to emphasize in this article:\"]]],[3,\"ul\",[[[0,[],0,\"Recommender Systems are the most valuable application of Machine Learning as they are able to create a Virtuous Feedback Loop: the more people use a company’s Recommender System, the more valuable they become and the more valuable they become, the more people use them. Once you enter that Loop, the Sky is the Limit.\"]],[[0,[],0,\"The right Problem Formulation is key.\"]],[[0,[],0,\"In the Netflix Price Challenge, teams tried to build models that predict a users’ rating for a given movie. In the “real world”, companies use much more sophisticated data inputs which can be classified into two categories: Explicit and Implicit Data.\"]],[[0,[],0,\"In today’s world, Recommender Systems rely on much more than just Collaborative Filtering.\"]]]],[1,\"p\",[[0,[],0,\"In the Second Part I will cover:\"]]],[3,\"ul\",[[[0,[],0,\"Evaluation Metrics\"]],[[0,[],0,\"User Interface\"]],[[0,[],0,\"Cold-start Problem\"]],[[0,[],0,\"Exploration vs. Exploitation\"]]]],[10,10],[1,\"p\",[[0,[6,2],2,\"Resources\"]]],[1,\"p\",[[0,[5],1,\"Airbnb — Listing Embeddings in Search Ranking\"]]],[1,\"p\",[[0,[16],1,\"Airbnb — Machine Learning-Powered Search Ranking of Airbnb Experiences\"]]],[1,\"p\",[[0,[8],1,\"Amazon — Amazon.com Recommendations Item-to-Item Collaborative Filtering\"]]],[1,\"p\",[[0,[7],1,\"Amazon — The history of Amazon’s recommendation algorithm\"]]],[1,\"p\",[[0,[19],1,\"Instagram — Powered by AI: Instagram’s Explore recommender system\"]]],[1,\"p\",[[0,[10],1,\"LinkedIn — The Browsemaps: Collaborative Filtering at LinkedIn\"]]],[1,\"p\",[[0,[9],1,\"Netflix — Netflix Recommendations: Beyond the 5 stars (Part 1)\"]]],[1,\"p\",[[0,[14],1,\"Netflix — Netflix Recommendations: Beyond the 5 stars (Part 2)\"]]],[1,\"p\",[[0,[3],1,\"Netflix — The Netflix Recommender System: Algorithms, Business Value, and Innovation\"]]],[1,\"p\",[[0,[31],1,\"Netflix — Learning a Personalized Homepage\"]]],[1,\"p\",[[0,[15],1,\"Pandora — Pandora’s Music Recommender\"]]],[1,\"p\",[[0,[11],1,\"Spotify — Discover Weekly: How Does Spotify Know You So Well?\"]]],[1,\"p\",[[0,[32],1,\"Spotify — For Your Ears Only: Personalizing Spotify Home with Machine Learning\"]]],[1,\"p\",[[0,[22],1,\"Spotify — From Idea to Execution: Spotify’s Discover Weekly\"]]],[1,\"p\",[[0,[21],1,\"Twitter — Embeddings@Twitter\"]]],[1,\"p\",[[0,[33],1,\"Uber Eats — Food Discovery with Uber Eats: Recommending for the Marketplace\"]]],[1,\"p\",[[0,[20],1,\"Uber Eats — Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations\"]]],[1,\"p\",[[0,[34],1,\"YouTube — The YouTube Video Recommendation System\"]]],[1,\"p\",[[0,[17],1,\"YouTube — Collaborative Deep Learning for Recommender Systems\"]]],[1,\"p\",[[0,[12],1,\"YouTube — Deep Neural Networks for YouTube Recommendations\"]]],[1,\"p\",[[0,[26],1,\"Zillow — Home Embeddings for Similar Home Recommendations\"]]],[1,\"p\",[[0,[18],1,\"Andrew Ng’s Machine Learning Course (Recommender Systems)\"]]],[1,\"p\",[[0,[35],1,\"Google’s Machine Learning Crash Course — Embeddings\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>Why Recommender Systems are the most valuable application of Machine Learning and how Machine Learning-driven Recommenders already drive almost every aspect of our lives.</p><p><a href=\"https://towardsdatascience.com/recommender-systems-the-most-valuable-application-of-machine-learning-part-1-f96ecbc4b7f5\">Read this article on Medium.</a></p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*F2mBbZRHPXxa3cyg3z8esg.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Recommender Systems already drive almost every aspect of our daily&nbsp;lives.</figcaption></figure><hr><p>Look back at your week: a Machine Learning algorithm determined what songs you might like to listen to, what food to order online, what posts you see on your favorite social networks, as well as the next person you may want to connect with, what series or movies you would like to watch, etc…</p><p>Machine Learning already guides so many aspects of our life without us necessarily being conscious of it. All of the applications mentioned above are driven by one type of algorithm: recommender systems.</p><p>In this article, I will explore and dive deeper into all the aspects that come into play to build a successful recommender system. The length of this article got a little out of hand so I decided to split it into two parts. This first part will cover:</p><ul><li>Business Value</li><li>Problem Formulation</li><li>Data</li><li>Algorithms</li></ul><p>The Second Part will cover:</p><ul><li>Evaluation Metrics</li><li>User Interface</li><li>Cold-start Problem</li><li>Exploration vs. Exploitation</li><li>The Future of Recommender Systems</li></ul><p>Throughout this article, I will be using examples of the companies that have built the most widely used systems over the last couple of years, including Airbnb, Amazon, Instagram, LinkedIn, Netflix, Spotify, Uber Eats, and YouTube.</p><hr><h3 id=\"business-value\">Business Value</h3><p>Harvard Business Review made a strong statement by calling Recommenders the <a href=\"https://hbr.org/2017/08/great-digital-companies-build-great-recommendation-engines\" rel=\"noopener\">single most important algorithmic distinction between “born digital” enterprises and legacy companies</a>. HBR also described the virtuous business cycle these can generate: the more people use a company’s Recommender System, the more valuable they become and the more valuable they become, the more people use them.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*U_eUe0NBy7uQPA10SFY-VQ.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>The Virtuous Business Cycle of Recommender Systems (source: <a href=\"https://www.mdpi.com/2199-8531/5/3/44/htm\" data-href=\"https://www.mdpi.com/2199-8531/5/3/44/htm\" class=\"markup--anchor markup--figure-anchor\" rel=\"noopener\" target=\"_blank\">MDPI</a>,&nbsp;CC)</figcaption></figure><p>We are encouraged to look at recommender systems, not as a way to sell more online, but rather to see it as a renewable resource for <em>relentlessly improving customer insights and our own insights as well</em>. If we look at the illustration above, we can see that many legacy companies also have tons of users and therefore tons of data. The reason their virtuous cycle has not picked up as much as the ones off Amazon, Netflix or Spotify is because of the lack of knowledge on how to convert their user data into actionable insights, which can then be used to improve their product or services.</p><p>Looking at Netflix, for example, shows how crucial this is, as 80% of what people watch comes from some sort of recommendation. In <a href=\"https://dl.acm.org/doi/pdf/10.1145/2843948\" rel=\"noopener\">2015, one of their papers quoted</a>:</p><blockquote>“We think the combined effect of personalization and recommendations save us more than $1B per year.”</blockquote><p>If we look at Amazon, <a href=\"https://www.mckinsey.com/industries/retail/our-insights/how-retailers-can-keep-up-with-consumers\" rel=\"noopener\">35% of what customers purchase at Amazon</a> comes from product recommendations and at Airbnb, Search Ranking and Similar Listings drive <a href=\"https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e\">99% of all booking conversions</a>.</p><hr><h3 id=\"problem-formulation\">Problem Formulation</h3><p>Now that we’ve seen the immense value, companies can gain from Recommender Systems, let’s look at the type of challenges that can be solved by them. Generally speaking, tech companies are trying to recommend the <strong>most relevant content</strong> to their users. That could mean:</p><ul><li>similar home listings (Airbnb, Zillow)</li><li>relevant media, e.g. photos, videos and stories (Instagram)</li><li>relevant series and movies (Netflix, Amazon Prime Video)</li><li>relevant songs and podcasts (Spotify)</li><li>relevant videos (YouTube)</li><li>similar users, posts (LinkedIn, Twitter, Instagram)</li><li>relevant dishes and restaurants (Uber Eats)</li></ul><p>The formulation of the problem is critical here. Most of the time, companies want to recommend content that users are most likely to enjoy in the future. The reformulation of this problem, as well as the algorithmic changes from recommending “what users are most likely to watch” to “what users are most likely to watch <em>in the future</em>” <a href=\"https://www.amazon.science/the-history-of-amazons-recommendation-algorithm\" rel=\"noopener\">allowed Amazon PrimeVideo to gain a 2x improvement</a>, a “once-in-a-decade leap” for their movie Recommender System.</p><blockquote>“Amazon researchers found that using neural networks to generate movie recommendations worked much better when they sorted the input data chronologically and used it to predict future movie preferences over a short (one- to two-week) period.”</blockquote><hr><h3 id=\"data\">Data</h3><p>Recommender Systems usually take two types of data as input:</p><ul><li><strong>User Interaction Data </strong>(Implicit/Explicit)</li><li><strong>Item Data</strong> (Features)</li></ul><p>The “classic”, and still widely used approach to recommender systems based on <strong>collaborative filtering</strong> (used by <a href=\"https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf\" rel=\"noopener\">Amazon</a>, <a href=\"https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429\" rel=\"noopener\">Netflix</a>, <a href=\"https://ls13-www.cs.tu-dortmund.de/homepage/rsweb2014/papers/rsweb2014_submission_3.pdf\" rel=\"noopener\">LinkedIn</a>, <a href=\"https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe\">Spotify</a> and <a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\" rel=\"noopener\">YouTube</a>) uses either User-User or Item-Item relationships to find similar content. I’m not going to go deeper into the inner workings of this, as there are a lot of articles on that topic — <a href=\"https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-recommendation-engine-python/\" rel=\"noopener\">like this one</a> — that explain this concept well.</p><p>The <em>user interaction data</em> is the data we gather from the weblogs and can be divided into two groups:</p><p><strong><em>Explicit data</em></strong>: explicit input from our users (e.g. movie ratings, search logs, liked, commented, watched, favorited, etc.)</p><p><strong><em>Implicit data</em></strong>: information that is not provided intentionally but gathered from available data streams (e.g. search history, order history, clicked on, accounts interacted with, etc.)</p><p>The <em>item data</em> consists mainly of an item’s features. In YouTube’s case that would be a video’s metadata such as title and description. For Zillow, this could be a home’s Zip Code, City Region, Price, or Number of Bedrooms for instance.</p><p>Other data sources could be <strong><em>external data</em></strong> (for example, Netflix might <a href=\"https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5\" rel=\"noopener\">add external item data features</a> such as box office performance or critic reviews) or <strong>expert-generated data</strong> (Pandora’s <a href=\"https://pdfs.semanticscholar.org/f635/6c70452b3f56dc1ae07b4649a80239afb1b6.pdf\" rel=\"noopener\">Music Genome Project</a> uses human input to apply values for each song in each of approximately 400 musical attributes).</p><p>A key insight here is that obviously, having more data about your users will inevitably lead to better model results (if applied correctly), however, as Airbnb shows in their <a href=\"https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789\">3-part journey to building a Ranking Model for Airbnb Experiences</a> you can already achieve quite a lot with lesser data: the team at Airbnb already improved bookings by +13% with just 500 experiences and 50k training data size.</p><blockquote>“The main take-away is: <em>Don’t wait until you have big data, you can do quite a bit with small data to help grow and improve your business.</em>”</blockquote><hr><h3 id=\"algorithms\">Algorithms</h3><p>Often, we associate Recommender Systems with just collaborative filtering. That’s fair, as in the past this has been the go-to method for a lot of the companies that have deployed successful systems in practice. Amazon was probably the first company to leverage <a href=\"https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf\" rel=\"noopener\">item-to-item collaborative filtering</a>. When they first released the inner workings of their method in a paper in 2003, the system had already been in use for six years.</p><p>Then, in 2006 Netflix followed suit with its famous Netflix Price Challenge which offered $1 million to whoever improved the accuracy of their existing system called <em>Cinematch</em> by 10%. Collaborative filtering was also a part of the early Recommender Systems at <a href=\"https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe\">Spotify</a> and <a href=\"https://arxiv.org/pdf/1409.2944.pdf\" rel=\"noopener\">YouTube</a>. LinkedIn even developed a horizontal collaborative filtering infrastructure, <a href=\"https://ls13-www.cs.tu-dortmund.de/homepage/rsweb2014/papers/rsweb2014_submission_3.pdf\" rel=\"noopener\">known as Browsemaps</a>. This platform enables rapid development, deployment, and computation of collaborative filtering recommendations for almost any use case on LinkedIn.</p><p>If you want to know more about collaborative filtering, I would recommend checking out <a href=\"https://www.youtube.com/watch?v=giIXNoiqO_U&amp;list=PL-6SiIrhTAi6x4Oq28s7yy94ubLzVXabj\" rel=\"noopener\">Section 16 of Andrew Ng’s Machine Learning course on Coursera</a> where he goes deeper into the math behind it.</p><p>Now, I would like to take a step back and generalize the concept of a Recommender System. While many companies used to rely on collaborative filtering, today there are a lot of other different algorithms at play that either complement or even replaced the collaborative filtering approach. Netflix went through this change when they shifted from a DVD shipping to a streaming business. As described in one of their papers:</p><blockquote>“We indeed relied on such an algorithm heavily when our main business was shipping DVDs by mail, partly because in that context, a star rating was the main feedback that we received that a member had actually watched the video. […] But the days when stars and DVDs were the focus of recommendations at Netflix have long passed. […] Now, our recommender system consists of a variety of algorithms that collectively define the Netflix experience, most of which come together on the Netflix homepage.”</blockquote><p>If we zoom out a little bit and look at Recommender Systems more broadly we find that they essentially consist of two parts:</p><ol><li><strong>Candidate Generation</strong></li><li><strong>Ranking</strong></li></ol><p>I am going to use <a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\" rel=\"noopener\">YouTube’s Recommender System</a> as an example below as they provided a good visualization, but that very same concept is applied by Instagram for <a href=\"https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/\" rel=\"noopener\">recommendations in “Instagram Explore”</a>, by Uber Eats in their <a href=\"https://eng.uber.com/uber-eats-graph-learning/\" rel=\"noopener\">Dish and Restaurant Recommender System</a>, by Netflix for their <a href=\"https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5\" rel=\"noopener\">movie recommendations </a>and probably many other companies.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*6LG9QN2XEtK6UCOZG4cavA.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>2-stage Recommender System (inspired by&nbsp;<a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\" data-href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\" class=\"markup--anchor markup--figure-anchor\" rel=\"noopener\" target=\"_blank\">YouTube</a>)</figcaption></figure><p>According to Netflix, the goal of Recommender Systems is to present a number of attractive items for a person to choose from. This is usually accomplished by selecting some items (<em>candidate generation</em>) and sorting them (<em>ranking</em>) in the order of expected enjoyment (or utility).</p><p>Let’s further investigate the two stages:</p><h4 id=\"candidate-generation\">Candidate Generation</h4><p>In this stage, we want to source the relevant candidates that could be eligible to show to our users. Here, we are working with the whole catalog of items so it can be quite large (YouTube and Instagram are great examples here). The key to doing this is entity embeddings. What are entity embeddings?</p><p>An entity embedding is a mathematical vector representation of an entity such that its dimensions might represent certain properties. Twitter has a great example of this in a <a href=\"https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html\" rel=\"noopener\">blog post about Embeddings@Twitter</a>: say we have two NBA players (Stephen Curry and LeBron James) and two musicians (Kendrick Lamar and Bruno Mars). We expect the distance between the embeddings of the NBA players to be smaller than the distance between the embeddings of a player and a musician. We can calculate the distance between two embeddings using the formula for Euclidean distance.</p><p><strong><em>How do we come up with these embeddings?</em></strong></p><p>Well, one way to do this would be collaborative filtering. We have our items and our users. If we put them in a matrix (for the example of Spotify) it could look like this:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*dkvXGVpAlK25F-WznatMMA.png\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>After applying the <a href=\"https://www.slideshare.net/MrChrisJohnson/from-idea-to-execution-spotifys-discover-weekly/31-1_0_0_0_1\" rel=\"noopener\">matrix factorization algorithm</a>, we end up with user vectors and song vectors. To find out which users’ tastes are most similar to another’s, collaborative filtering compares one users’ vector with all of the other users’ vectors, ultimately spitting out which users are the closest matches. The same goes for the Y vector, <em>songs</em>: you can compare a single song’s vector with all the others, and find out which songs are most similar to the one in question.</p><p>Another way to do this takes inspiration from applications in the domain of Natural Language Processing. Researchers generalized the <a href=\"https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf\" rel=\"noopener\">word2vec algorithm</a>, developed by Google in the early 2010s to all entities appearing in a similar context. In word2vec, the networks are trained by directly taking into account the word order and their co-occurrence, based on the assumption that words frequently appearing together in the sentences also share more statistical dependence. As Airbnb describes, in their <a href=\"https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e\">blog post about creating Listing Embeddings</a>:</p><blockquote>More recently, the concept of embeddings has been extended beyond word representations to other applications outside of NLP domain. Researchers from the Web Search, E-commerce and Marketplace domains have realized that just like one can train word embeddings by treating a sequence of words in a sentence as context, the same can be done for training embeddings of user actions by treating sequence of user actions as context. Examples include learning representations of <a href=\"https://arxiv.org/pdf/1606.07154.pdf\" rel=\"noopener nofollow noopener noopener noopener\">items that were clicked or purchased</a> or <a href=\"https://arxiv.org/pdf/1607.01869.pdf\" rel=\"noopener nofollow noopener noopener noopener\">queries and ads that were clicked</a>. These embeddings have subsequently been leveraged for a variety of recommendations on the Web.</blockquote><p>Apart from Airbnb, this concept is used by Instagram (IG2Vec) to<a href=\"https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/\" rel=\"noopener\"> learn account embeddings</a>, by YouTube to <a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\" rel=\"noopener\">learn video embeddings</a> and by Zillow to <a href=\"https://www.zillow.com/tech/embedding-similar-home-recommendation/\" rel=\"noopener\">learn categorical embeddings</a>.</p><p>Another, more novel approach to this is called Graph Learning and it is <a href=\"https://eng.uber.com/uber-eats-graph-learning/\" rel=\"noopener\">used by Uber Eats for their dish and restaurant embeddings</a>. They represent each of their dishes and restaurant in a separate graph and apply the <a href=\"http://snap.stanford.edu/graphsage/\" rel=\"noopener\">GraphSAGE algorithm</a> to obtain the representations (embeddings) of the respective nodes.</p><p>And last but not least, we can also learn an embedding as part of the neural network for our target task. This approach gets you an embedding well customized for your particular system, but may take longer than training the embedding separately. The <a href=\"https://keras.io/api/layers/core_layers/embedding/\" rel=\"noopener\">Keras Embedding Layer</a> would be one way to achieve this. Google covers this well as part of their <a href=\"https://developers.google.com/machine-learning/crash-course/embeddings/obtaining-embeddings\" rel=\"noopener\">Machine Learning Crash Course.</a></p><p>Once we have this vectorial representation of our items we can simply use Nearest Neighbour Search to find our potential candidates. <br><a href=\"https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/\" rel=\"noopener\">Instagram, for example</a>, defines a couple of seed accounts (accounts that people have interacted with in the past) and uses their IG2Vec account embeddings to find similar accounts that are like those. Based on these accounts, they are able to find the media that these accounts posted or engaged with. By doing that, they are able to filter billions of media items down to a couple thousand and then sample 500 candidates from the pool and send those candidates downstream to the ranking stage.</p><p>This phase can also be guided by business rules or just user input (the more information we have the more specific we can be). As Uber Eats mentions <a href=\"https://eng.uber.com/uber-eats-graph-learning/\" rel=\"noopener\">in one of their blog posts</a>, for instance, pre-filtering can be based on factors such as geographical location.</p><p>So, to summarize:</p><p><em>In the candidate generation (or sourcing) phase, we filter our whole content catalog for a smaller subset of items that our users might be interested in. To do this we need to map our items into a mathematical representation called embeddings so we can use a similarity function to find the most similar items in space. There are several ways to achieve this. Three of them being collaborative filtering, word2vec for entities, and graph learning.</em></p><h4 id=\"ranking\">Ranking</h4><p>Let’s loop back to the case of Instagram. After the candidate generation stage, we have about 500 media items that are potentially relevant and that we could show to a user in their “Explore” feed. <br>But which ones are going to be the <strong>most relevant</strong>?</p><p>Because, after all, there are only 25 spots on the first page of the “Explore” section. And if the first items suck, the user is not going to be impressed nor intrigued to keep browsing. Netflix’s and Amazon PrimeVideo’s web interface <a href=\"https://www.amazon.science/the-history-of-amazons-recommendation-algorithm\" rel=\"noopener\">shows only the top 6 recommendations on the first page</a> associated with each title in its catalog. <a href=\"https://www.slideshare.net/MrChrisJohnson/from-idea-to-execution-spotifys-discover-weekly/31-1_0_0_0_1\" rel=\"noopener\">Spotify’s Discover Weekly</a> Playlist contains only 30 songs. <br>Also, all of this is subject to the users’ device. Smartphones, of course, allowing for less space for relevant recommendations than a web browser.</p><p>“There are many ways one could construct a ranking function ranging from simple scoring methods, to pairwise preferences, to optimization over the entire ranking. If we were to formulate this as a Machine Learning problem, we could select positive and negative examples from our historical data and let a Machine Learning algorithm learn the weights that optimize our goal. This family of Machine Learning problems is known as “<a href=\"http://en.wikipedia.org/wiki/Learning_to_rank\" rel=\"noopener\">Learning to rank</a>” and is central to application scenarios such as search engines or ad targeting. In the ranking stage, we are not aiming for our items to have a global notion of <em>relevance</em>, but rather look for ways of optimizing a personalized model” <em>(Extract from </em><a href=\"https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5\" rel=\"noopener\"><em>Netflix Blog Post</em></a><em>).</em></p><p>To accomplish this, <a href=\"https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/\" rel=\"noopener\">Instagram uses a three-stage ranking infrastructure</a> to help balance the trade-offs between ranking relevance and computation efficiency. In the <a href=\"https://eng.uber.com/uber-eats-graph-learning/\" rel=\"noopener\">case of Uber Eats</a>, their personalized ranking system is “a fully-fledged ML model that ranks the pre-filtered dish and restaurant candidates based on additional contextual information, such as the day, time, and current location of the user when they open the Uber Eats app”. In general, the level of complexity for your model really depends on the size of your feature space. Many supervised classification methods can be used for ranking. Typical choices include Logistic Regression, Support Vector Machines, Neural Networks, or Decision Tree-based methods such as Gradient Boosted Decision Trees (GBDT). On the other hand, a great number of algorithms specifically designed for learning to rank have appeared in recent years such as RankSVM or RankBoost.</p><p>To summarise:</p><p><em>After selecting initial candidates for our recommendations, in the ranking stage, we need to design a ranking function that ranks items by their relevance. This can be formulated as a Machine Learning problem, and the goal here is to optimize a personalized model for each user. This step is important because in most interfaces we have limited space to recommend items so we need to make the best use of that space by putting the most relevant items at the very top.</em></p><h4 id=\"baseline\">Baseline</h4><p>As for every Machine Learning algorithm, we need a good baseline to measure the improvement of any change. A good baseline to start with is just to use the <a href=\"https://www.amazon.science/the-history-of-amazons-recommendation-algorithm\" rel=\"noopener\">most popular items in the catalog, as described by Amazon</a>:</p><blockquote>“In the recommendations world, there’s a cardinal rule. If I know nothing about you, then the best things to recommend to you are the most popular things in the world.”</blockquote><p>However, if you don’t even know what is most popular, because you just launched a new product or new items — as was the case with <a href=\"https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789\">Airbnb Experiences</a> — you can just randomly re-rank the item collection daily until you have gathered enough data for your first model.</p><hr><p>That’s a wrap for Part 1 of this series. There are a couple of points I wanted to emphasize in this article:</p><ul><li>Recommender Systems are the most valuable application of Machine Learning as they are able to create a Virtuous Feedback Loop: the more people use a company’s Recommender System, the more valuable they become and the more valuable they become, the more people use them. Once you enter that Loop, the Sky is the Limit.</li><li>The right Problem Formulation is key.</li><li>In the Netflix Price Challenge, teams tried to build models that predict a users’ rating for a given movie. In the “real world”, companies use much more sophisticated data inputs which can be classified into two categories: Explicit and Implicit Data.</li><li>In today’s world, Recommender Systems rely on much more than just Collaborative Filtering.</li></ul><p>In the Second Part I will cover:</p><ul><li>Evaluation Metrics</li><li>User Interface</li><li>Cold-start Problem</li><li>Exploration vs. Exploitation</li></ul><hr><p><strong><em>Resources</em></strong></p><p><a href=\"https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e\">Airbnb — Listing Embeddings in Search Ranking</a></p><p><a href=\"https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789\">Airbnb — Machine Learning-Powered Search Ranking of Airbnb Experiences</a></p><p><a href=\"https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf\" rel=\"noopener\">Amazon — Amazon.com Recommendations Item-to-Item Collaborative Filtering</a></p><p><a href=\"https://www.amazon.science/the-history-of-amazons-recommendation-algorithm\" rel=\"noopener\">Amazon — The history of Amazon’s recommendation algorithm</a></p><p><a href=\"https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/\" rel=\"noopener\">Instagram — Powered by AI: Instagram’s Explore recommender system</a></p><p><a href=\"https://ls13-www.cs.tu-dortmund.de/homepage/rsweb2014/papers/rsweb2014_submission_3.pdf\" rel=\"noopener\">LinkedIn — The Browsemaps: Collaborative Filtering at LinkedIn</a></p><p><a href=\"https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429\" rel=\"noopener\">Netflix — Netflix Recommendations: Beyond the 5 stars (Part 1)</a></p><p><a href=\"https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5\" rel=\"noopener\">Netflix — Netflix Recommendations: Beyond the 5 stars (Part 2)</a></p><p><a href=\"https://dl.acm.org/doi/pdf/10.1145/2843948\" rel=\"noopener\">Netflix — The Netflix Recommender System: Algorithms, Business Value, and Innovation</a></p><p><a href=\"https://netflixtechblog.com/learning-a-personalized-homepage-aa8ec670359a\" rel=\"noopener\">Netflix — Learning a Personalized Homepage</a></p><p><a href=\"https://pdfs.semanticscholar.org/f635/6c70452b3f56dc1ae07b4649a80239afb1b6.pdf\" rel=\"noopener\">Pandora — Pandora’s Music Recommender</a></p><p><a href=\"https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe\">Spotify — Discover Weekly: How Does Spotify Know You So Well?</a></p><p><a href=\"https://labs.spotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/\" rel=\"noopener\">Spotify — For Your Ears Only: Personalizing Spotify Home with Machine Learning</a></p><p><a href=\"https://www.slideshare.net/MrChrisJohnson/from-idea-to-execution-spotifys-discover-weekly/31-1_0_0_0_1\" rel=\"noopener\">Spotify — From Idea to Execution: Spotify’s Discover Weekly</a></p><p><a href=\"https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html\" rel=\"noopener\">Twitter — Embeddings@Twitter</a></p><p><a href=\"https://eng.uber.com/uber-eats-recommending-marketplace/\" rel=\"noopener\">Uber Eats — Food Discovery with Uber Eats: Recommending for the Marketplace</a></p><p><a href=\"https://eng.uber.com/uber-eats-graph-learning/\" rel=\"noopener\">Uber Eats — Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations</a></p><p><a href=\"https://www.inf.unibz.it/~ricci/ISR/papers/p293-davidson.pdf\" rel=\"noopener\">YouTube — The YouTube Video Recommendation System</a></p><p><a href=\"https://arxiv.org/pdf/1409.2944.pdf\" rel=\"noopener\">YouTube — Collaborative Deep Learning for Recommender Systems</a></p><p><a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\" rel=\"noopener\">YouTube — Deep Neural Networks for YouTube Recommendations</a></p><p><a href=\"https://www.zillow.com/tech/embedding-similar-home-recommendation/\" rel=\"noopener\">Zillow — Home Embeddings for Similar Home Recommendations</a></p><p><a href=\"https://www.youtube.com/watch?v=giIXNoiqO_U&amp;list=PL-6SiIrhTAi6x4Oq28s7yy94ubLzVXabj\" rel=\"noopener\">Andrew Ng’s Machine Learning Course (Recommender Systems)</a></p><p><a href=\"https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture\" rel=\"noopener\">Google’s Machine Learning Crash Course — Embeddings</a></p>","comment_id":"5f7a340e3ffbdb6a6f04d6c4","plaintext":"Why Recommender Systems are the most valuable application of Machine Learning\nand how Machine Learning-driven Recommenders already drive almost every aspect\nof our lives.\n\nRead this article on Medium.\n[https://towardsdatascience.com/recommender-systems-the-most-valuable-application-of-machine-learning-part-1-f96ecbc4b7f5]\n\nRecommender Systems already drive almost every aspect of our daily lives.\n--------------------------------------------------------------------------------\n\nLook back at your week: a Machine Learning algorithm determined what songs you\nmight like to listen to, what food to order online, what posts you see on your\nfavorite social networks, as well as the next person you may want to connect\nwith, what series or movies you would like to watch, etc…\n\nMachine Learning already guides so many aspects of our life without us\nnecessarily being conscious of it. All of the applications mentioned above are\ndriven by one type of algorithm: recommender systems.\n\nIn this article, I will explore and dive deeper into all the aspects that come\ninto play to build a successful recommender system. The length of this article\ngot a little out of hand so I decided to split it into two parts. This first\npart will cover:\n\n * Business Value\n * Problem Formulation\n * Data\n * Algorithms\n\nThe Second Part will cover:\n\n * Evaluation Metrics\n * User Interface\n * Cold-start Problem\n * Exploration vs. Exploitation\n * The Future of Recommender Systems\n\nThroughout this article, I will be using examples of the companies that have\nbuilt the most widely used systems over the last couple of years, including\nAirbnb, Amazon, Instagram, LinkedIn, Netflix, Spotify, Uber Eats, and YouTube.\n\n\n--------------------------------------------------------------------------------\n\nBusiness Value\nHarvard Business Review made a strong statement by calling Recommenders the \nsingle most important algorithmic distinction between “born digital”\nenterprises\nand legacy companies\n[https://hbr.org/2017/08/great-digital-companies-build-great-recommendation-engines]\n. HBR also described the virtuous business cycle these can generate: the more\npeople use a company’s Recommender System, the more valuable they become and the\nmore valuable they become, the more people use them.\n\nThe Virtuous Business Cycle of Recommender Systems (source: MDPI\n[https://www.mdpi.com/2199-8531/5/3/44/htm], CC)We are encouraged to look at\nrecommender systems, not as a way to sell more online, but rather to see it as a\nrenewable resource for relentlessly improving customer insights and our own\ninsights as well. If we look at the illustration above, we can see that many\nlegacy companies also have tons of users and therefore tons of data. The reason\ntheir virtuous cycle has not picked up as much as the ones off Amazon, Netflix\nor Spotify is because of the lack of knowledge on how to convert their user data\ninto actionable insights, which can then be used to improve their product or\nservices.\n\nLooking at Netflix, for example, shows how crucial this is, as 80% of what\npeople watch comes from some sort of recommendation. In 2015, one of their\npapers quoted [https://dl.acm.org/doi/pdf/10.1145/2843948]:\n\n> “We think the combined effect of personalization and recommendations save us\nmore than $1B per year.”\nIf we look at Amazon, 35% of what customers purchase at Amazon\n[https://www.mckinsey.com/industries/retail/our-insights/how-retailers-can-keep-up-with-consumers] \ncomes from product recommendations and at Airbnb, Search Ranking and Similar\nListings drive 99% of all booking conversions\n[https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e]\n.\n\n\n--------------------------------------------------------------------------------\n\nProblem Formulation\nNow that we’ve seen the immense value, companies can gain from Recommender\nSystems, let’s look at the type of challenges that can be solved by them.\nGenerally speaking, tech companies are trying to recommend the most relevant\ncontent to their users. That could mean:\n\n * similar home listings (Airbnb, Zillow)\n * relevant media, e.g. photos, videos and stories (Instagram)\n * relevant series and movies (Netflix, Amazon Prime Video)\n * relevant songs and podcasts (Spotify)\n * relevant videos (YouTube)\n * similar users, posts (LinkedIn, Twitter, Instagram)\n * relevant dishes and restaurants (Uber Eats)\n\nThe formulation of the problem is critical here. Most of the time, companies\nwant to recommend content that users are most likely to enjoy in the future. The\nreformulation of this problem, as well as the algorithmic changes from\nrecommending “what users are most likely to watch” to “what users are most\nlikely to watch in the future” allowed Amazon PrimeVideo to gain a 2x\nimprovement\n[https://www.amazon.science/the-history-of-amazons-recommendation-algorithm], a\n“once-in-a-decade leap” for their movie Recommender System.\n\n> “Amazon researchers found that using neural networks to generate movie\nrecommendations worked much better when they sorted the input data\nchronologically and used it to predict future movie preferences over a short\n(one- to two-week) period.”\n\n--------------------------------------------------------------------------------\n\nData\nRecommender Systems usually take two types of data as input:\n\n * User Interaction Data (Implicit/Explicit)\n * Item Data (Features)\n\nThe “classic”, and still widely used approach to recommender systems based on \ncollaborative filtering (used by Amazon\n[https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf], Netflix\n[https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429]\n, LinkedIn\n[https://ls13-www.cs.tu-dortmund.de/homepage/rsweb2014/papers/rsweb2014_submission_3.pdf]\n, Spotify\n[https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe] \nand YouTube\n[https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf]\n) uses either User-User or Item-Item relationships to find similar content. I’m\nnot going to go deeper into the inner workings of this, as there are a lot of\narticles on that topic —like this one\n[https://www.analyticsvidhya.com/blog/2018/06/comprehensive-guide-recommendation-engine-python/]\n— that explain this concept well.\n\nThe user interaction data is the data we gather from the weblogs and can be\ndivided into two groups:\n\nExplicit data: explicit input from our users (e.g. movie ratings, search logs,\nliked, commented, watched, favorited, etc.)\n\nImplicit data: information that is not provided intentionally but gathered from\navailable data streams (e.g. search history, order history, clicked on, accounts\ninteracted with, etc.)\n\nThe item data consists mainly of an item’s features. In YouTube’s case that\nwould be a video’s metadata such as title and description. For Zillow, this\ncould be a home’s Zip Code, City Region, Price, or Number of Bedrooms for\ninstance.\n\nOther data sources could be external data (for example, Netflix might add\nexternal item data features\n[https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5] \nsuch as box office performance or critic reviews) or expert-generated data \n(Pandora’s Music Genome Project\n[https://pdfs.semanticscholar.org/f635/6c70452b3f56dc1ae07b4649a80239afb1b6.pdf] \nuses human input to apply values for each song in each of approximately 400\nmusical attributes).\n\nA key insight here is that obviously, having more data about your users will\ninevitably lead to better model results (if applied correctly), however, as\nAirbnb shows in their 3-part journey to building a Ranking Model for Airbnb\nExperiences\n[https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789] \nyou can already achieve quite a lot with lesser data: the team at Airbnb already\nimproved bookings by +13% with just 500 experiences and 50k training data size.\n\n> “The main take-away is: Don’t wait until you have big data, you can do quite a\nbit with small data to help grow and improve your business.”\n\n--------------------------------------------------------------------------------\n\nAlgorithms\nOften, we associate Recommender Systems with just collaborative filtering.\nThat’s fair, as in the past this has been the go-to method for a lot of the\ncompanies that have deployed successful systems in practice. Amazon was probably\nthe first company to leverage item-to-item collaborative filtering\n[https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf]. When they first\nreleased the inner workings of their method in a paper in 2003, the system had\nalready been in use for six years.\n\nThen, in 2006 Netflix followed suit with its famous Netflix Price Challenge\nwhich offered $1 million to whoever improved the accuracy of their existing\nsystem called Cinematch by 10%. Collaborative filtering was also a part of the\nearly Recommender Systems at Spotify\n[https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe] \nand YouTube [https://arxiv.org/pdf/1409.2944.pdf]. LinkedIn even developed a\nhorizontal collaborative filtering infrastructure, known as Browsemaps\n[https://ls13-www.cs.tu-dortmund.de/homepage/rsweb2014/papers/rsweb2014_submission_3.pdf]\n. This platform enables rapid development, deployment, and computation of\ncollaborative filtering recommendations for almost any use case on LinkedIn.\n\nIf you want to know more about collaborative filtering, I would recommend\nchecking out Section 16 of Andrew Ng’s Machine Learning course on Coursera\n[https://www.youtube.com/watch?v=giIXNoiqO_U&list=PL-6SiIrhTAi6x4Oq28s7yy94ubLzVXabj] \nwhere he goes deeper into the math behind it.\n\nNow, I would like to take a step back and generalize the concept of a\nRecommender System. While many companies used to rely on collaborative\nfiltering, today there are a lot of other different algorithms at play that\neither complement or even replaced the collaborative filtering approach. Netflix\nwent through this change when they shifted from a DVD shipping to a streaming\nbusiness. As described in one of their papers:\n\n> “We indeed relied on such an algorithm heavily when our main business was\nshipping DVDs by mail, partly because in that context, a star rating was the\nmain feedback that we received that a member had actually watched the video. […]\nBut the days when stars and DVDs were the focus of recommendations at Netflix\nhave long passed. […] Now, our recommender system consists of a variety of\nalgorithms that collectively define the Netflix experience, most of which come\ntogether on the Netflix homepage.”\nIf we zoom out a little bit and look at Recommender Systems more broadly we find\nthat they essentially consist of two parts:\n\n 1. Candidate Generation\n 2. Ranking\n\nI am going to use YouTube’s Recommender System\n[https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf] \nas an example below as they provided a good visualization, but that very same\nconcept is applied by Instagram for recommendations in “Instagram Explore”\n[https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/]\n, by Uber Eats in their Dish and Restaurant Recommender System\n[https://eng.uber.com/uber-eats-graph-learning/], by Netflix for their movie\nrecommendations\n[https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5]\nand probably many other companies.\n\n2-stage Recommender System (inspired byYouTube\n[https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf]\n)According to Netflix, the goal of Recommender Systems is to present a number of\nattractive items for a person to choose from. This is usually accomplished by\nselecting some items (candidate generation) and sorting them (ranking) in the\norder of expected enjoyment (or utility).\n\nLet’s further investigate the two stages:\n\nCandidate Generation\nIn this stage, we want to source the relevant candidates that could be eligible\nto show to our users. Here, we are working with the whole catalog of items so it\ncan be quite large (YouTube and Instagram are great examples here). The key to\ndoing this is entity embeddings. What are entity embeddings?\n\nAn entity embedding is a mathematical vector representation of an entity such\nthat its dimensions might represent certain properties. Twitter has a great\nexample of this in a blog post about Embeddings@Twitter\n[https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html]\n: say we have two NBA players (Stephen Curry and LeBron James) and two musicians\n(Kendrick Lamar and Bruno Mars). We expect the distance between the embeddings\nof the NBA players to be smaller than the distance between the embeddings of a\nplayer and a musician. We can calculate the distance between two embeddings\nusing the formula for Euclidean distance.\n\nHow do we come up with these embeddings?\n\nWell, one way to do this would be collaborative filtering. We have our items and\nour users. If we put them in a matrix (for the example of Spotify) it could look\nlike this:\n\nAfter applying the matrix factorization algorithm\n[https://www.slideshare.net/MrChrisJohnson/from-idea-to-execution-spotifys-discover-weekly/31-1_0_0_0_1]\n, we end up with user vectors and song vectors. To find out which users’ tastes\nare most similar to another’s, collaborative filtering compares one users’\nvector with all of the other users’ vectors, ultimately spitting out which users\nare the closest matches. The same goes for the Y vector, songs: you can compare\na single song’s vector with all the others, and find out which songs are most\nsimilar to the one in question.\n\nAnother way to do this takes inspiration from applications in the domain of\nNatural Language Processing. Researchers generalized the word2vec algorithm\n[https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf]\n, developed by Google in the early 2010s to all entities appearing in a similar\ncontext. In word2vec, the networks are trained by directly taking into account\nthe word order and their co-occurrence, based on the assumption that words\nfrequently appearing together in the sentences also share more statistical\ndependence. As Airbnb describes, in their blog post about creating Listing\nEmbeddings\n[https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e]\n:\n\n> More recently, the concept of embeddings has been extended beyond word\nrepresentations to other applications outside of NLP domain. Researchers from\nthe Web Search, E-commerce and Marketplace domains have realized that just like\none can train word embeddings by treating a sequence of words in a sentence as\ncontext, the same can be done for training embeddings of user actions by\ntreating sequence of user actions as context. Examples include learning\nrepresentations of items that were clicked or purchased\n[https://arxiv.org/pdf/1606.07154.pdf] or queries and ads that were clicked\n[https://arxiv.org/pdf/1607.01869.pdf]. These embeddings have subsequently been\nleveraged for a variety of recommendations on the Web.\nApart from Airbnb, this concept is used by Instagram (IG2Vec) to learn account\nembeddings\n[https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/]\n, by YouTube to learn video embeddings\n[https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf] \nand by Zillow to learn categorical embeddings\n[https://www.zillow.com/tech/embedding-similar-home-recommendation/].\n\nAnother, more novel approach to this is called Graph Learning and it is used by\nUber Eats for their dish and restaurant embeddings\n[https://eng.uber.com/uber-eats-graph-learning/]. They represent each of their\ndishes and restaurant in a separate graph and apply the GraphSAGE algorithm\n[http://snap.stanford.edu/graphsage/] to obtain the representations (embeddings)\nof the respective nodes.\n\nAnd last but not least, we can also learn an embedding as part of the neural\nnetwork for our target task. This approach gets you an embedding well customized\nfor your particular system, but may take longer than training the embedding\nseparately. The Keras Embedding Layer\n[https://keras.io/api/layers/core_layers/embedding/] would be one way to achieve\nthis. Google covers this well as part of their Machine Learning Crash Course.\n[https://developers.google.com/machine-learning/crash-course/embeddings/obtaining-embeddings]\n\nOnce we have this vectorial representation of our items we can simply use\nNearest Neighbour Search to find our potential candidates. \nInstagram, for example\n[https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/]\n, defines a couple of seed accounts (accounts that people have interacted with\nin the past) and uses their IG2Vec account embeddings to find similar accounts\nthat are like those. Based on these accounts, they are able to find the media\nthat these accounts posted or engaged with. By doing that, they are able to\nfilter billions of media items down to a couple thousand and then sample 500\ncandidates from the pool and send those candidates downstream to the ranking\nstage.\n\nThis phase can also be guided by business rules or just user input (the more\ninformation we have the more specific we can be). As Uber Eats mentions in one\nof their blog posts [https://eng.uber.com/uber-eats-graph-learning/], for\ninstance, pre-filtering can be based on factors such as geographical location.\n\nSo, to summarize:\n\nIn the candidate generation (or sourcing) phase, we filter our whole content\ncatalog for a smaller subset of items that our users might be interested in. To\ndo this we need to map our items into a mathematical representation called\nembeddings so we can use a similarity function to find the most similar items in\nspace. There are several ways to achieve this. Three of them being collaborative\nfiltering, word2vec for entities, and graph learning.\n\nRanking\nLet’s loop back to the case of Instagram. After the candidate generation stage,\nwe have about 500 media items that are potentially relevant and that we could\nshow to a user in their “Explore” feed. \nBut which ones are going to be the most relevant?\n\nBecause, after all, there are only 25 spots on the first page of the “Explore”\nsection. And if the first items suck, the user is not going to be impressed nor\nintrigued to keep browsing. Netflix’s and Amazon PrimeVideo’s web interface \nshows only the top 6 recommendations on the first page\n[https://www.amazon.science/the-history-of-amazons-recommendation-algorithm] \nassociated with each title in its catalog. Spotify’s Discover Weekly\n[https://www.slideshare.net/MrChrisJohnson/from-idea-to-execution-spotifys-discover-weekly/31-1_0_0_0_1] \nPlaylist contains only 30 songs. \nAlso, all of this is subject to the users’ device. Smartphones, of course,\nallowing for less space for relevant recommendations than a web browser.\n\n“There are many ways one could construct a ranking function ranging from simple\nscoring methods, to pairwise preferences, to optimization over the entire\nranking. If we were to formulate this as a Machine Learning problem, we could\nselect positive and negative examples from our historical data and let a Machine\nLearning algorithm learn the weights that optimize our goal. This family of\nMachine Learning problems is known as “Learning to rank\n[http://en.wikipedia.org/wiki/Learning_to_rank]” and is central to application\nscenarios such as search engines or ad targeting. In the ranking stage, we are\nnot aiming for our items to have a global notion of relevance, but rather look\nfor ways of optimizing a personalized model” (Extract from Netflix Blog Post\n[https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5]\n).\n\nTo accomplish this, Instagram uses a three-stage ranking infrastructure\n[https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/] \nto help balance the trade-offs between ranking relevance and computation\nefficiency. In the case of Uber Eats\n[https://eng.uber.com/uber-eats-graph-learning/], their personalized ranking\nsystem is “a fully-fledged ML model that ranks the pre-filtered dish and\nrestaurant candidates based on additional contextual information, such as the\nday, time, and current location of the user when they open the Uber Eats app”.\nIn general, the level of complexity for your model really depends on the size of\nyour feature space. Many supervised classification methods can be used for\nranking. Typical choices include Logistic Regression, Support Vector Machines,\nNeural Networks, or Decision Tree-based methods such as Gradient Boosted\nDecision Trees (GBDT). On the other hand, a great number of algorithms\nspecifically designed for learning to rank have appeared in recent years such as\nRankSVM or RankBoost.\n\nTo summarise:\n\nAfter selecting initial candidates for our recommendations, in the ranking\nstage, we need to design a ranking function that ranks items by their relevance.\nThis can be formulated as a Machine Learning problem, and the goal here is to\noptimize a personalized model for each user. This step is important because in\nmost interfaces we have limited space to recommend items so we need to make the\nbest use of that space by putting the most relevant items at the very top.\n\nBaseline\nAs for every Machine Learning algorithm, we need a good baseline to measure the\nimprovement of any change. A good baseline to start with is just to use the \nmost\npopular items in the catalog, as described by Amazon\n[https://www.amazon.science/the-history-of-amazons-recommendation-algorithm]:\n\n> “In the recommendations world, there’s a cardinal rule. If I know nothing about\nyou, then the best things to recommend to you are the most popular things in the\nworld.”\nHowever, if you don’t even know what is most popular, because you just launched\na new product or new items — as was the case with Airbnb Experiences\n[https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789]\n— you can just randomly re-rank the item collection daily until you have\ngathered enough data for your first model.\n\n\n--------------------------------------------------------------------------------\n\nThat’s a wrap for Part 1 of this series. There are a couple of points I wanted\nto emphasize in this article:\n\n * Recommender Systems are the most valuable application of Machine Learning as\n   they are able to create a Virtuous Feedback Loop: the more people use a\n   company’s Recommender System, the more valuable they become and the more\n   valuable they become, the more people use them. Once you enter that Loop, the\n   Sky is the Limit.\n * The right Problem Formulation is key.\n * In the Netflix Price Challenge, teams tried to build models that predict a\n   users’ rating for a given movie. In the “real world”, companies use much more\n   sophisticated data inputs which can be classified into two categories:\n   Explicit and Implicit Data.\n * In today’s world, Recommender Systems rely on much more than just\n   Collaborative Filtering.\n\nIn the Second Part I will cover:\n\n * Evaluation Metrics\n * User Interface\n * Cold-start Problem\n * Exploration vs. Exploitation\n\n\n--------------------------------------------------------------------------------\n\nResources\n\nAirbnb — Listing Embeddings in Search Ranking\n[https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e]\n\nAirbnb — Machine Learning-Powered Search Ranking of Airbnb Experiences\n[https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789]\n\nAmazon — Amazon.com Recommendations Item-to-Item Collaborative Filtering\n[https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf]\n\nAmazon — The history of Amazon’s recommendation algorithm\n[https://www.amazon.science/the-history-of-amazons-recommendation-algorithm]\n\nInstagram — Powered by AI: Instagram’s Explore recommender system\n[https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/]\n\nLinkedIn — The Browsemaps: Collaborative Filtering at LinkedIn\n[https://ls13-www.cs.tu-dortmund.de/homepage/rsweb2014/papers/rsweb2014_submission_3.pdf]\n\nNetflix — Netflix Recommendations: Beyond the 5 stars (Part 1)\n[https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429]\n\nNetflix — Netflix Recommendations: Beyond the 5 stars (Part 2)\n[https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5]\n\nNetflix — The Netflix Recommender System: Algorithms, Business Value, and\nInnovation [https://dl.acm.org/doi/pdf/10.1145/2843948]\n\nNetflix — Learning a Personalized Homepage\n[https://netflixtechblog.com/learning-a-personalized-homepage-aa8ec670359a]\n\nPandora — Pandora’s Music Recommender\n[https://pdfs.semanticscholar.org/f635/6c70452b3f56dc1ae07b4649a80239afb1b6.pdf]\n\nSpotify — Discover Weekly: How Does Spotify Know You So Well?\n[https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe]\n\nSpotify — For Your Ears Only: Personalizing Spotify Home with Machine Learning\n[https://labs.spotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/]\n\nSpotify — From Idea to Execution: Spotify’s Discover Weekly\n[https://www.slideshare.net/MrChrisJohnson/from-idea-to-execution-spotifys-discover-weekly/31-1_0_0_0_1]\n\nTwitter — Embeddings@Twitter\n[https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html]\n\nUber Eats — Food Discovery with Uber Eats: Recommending for the Marketplace\n[https://eng.uber.com/uber-eats-recommending-marketplace/]\n\nUber Eats — Food Discovery with Uber Eats: Using Graph Learning to Power\nRecommendations [https://eng.uber.com/uber-eats-graph-learning/]\n\nYouTube — The YouTube Video Recommendation System\n[https://www.inf.unibz.it/~ricci/ISR/papers/p293-davidson.pdf]\n\nYouTube — Collaborative Deep Learning for Recommender Systems\n[https://arxiv.org/pdf/1409.2944.pdf]\n\nYouTube — Deep Neural Networks for YouTube Recommendations\n[https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf]\n\nZillow — Home Embeddings for Similar Home Recommendations\n[https://www.zillow.com/tech/embedding-similar-home-recommendation/]\n\nAndrew Ng’s Machine Learning Course (Recommender Systems)\n[https://www.youtube.com/watch?v=giIXNoiqO_U&list=PL-6SiIrhTAi6x4Oq28s7yy94ubLzVXabj]\n\nGoogle’s Machine Learning Crash Course — Embeddings\n[https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture]","feature_image":null,"featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2020-10-04 20:43:58","created_by":"1","updated_at":"2021-04-25 14:07:38","updated_by":"1","published_at":"2020-10-04 20:46:09","published_by":"1","custom_excerpt":"Why Recommender Systems are the most valuable application of Machine Learning and how Machine Learning-driven Recommenders already drive almost every aspect of our lives.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"6085751174348916f1b0899e","uuid":"4dc90488-b8fd-475d-9dff-cf939b942457","title":"Recommender Systems: The Most Valuable Application of Machine Learning (Part 2)","slug":"recommender-systems-the-most-valuable-application-of-machine-learning-part-2","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"https://cdn-images-1.medium.com/max/1600/1*F2mBbZRHPXxa3cyg3z8esg.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"Recommender Systems already drive almost every aspect of our daily&nbsp;lives.\"}],[\"hr\",{}],[\"hr\",{}],[\"image\",{\"src\":\"https://cdn-images-1.medium.com/max/1600/1*HjqVASOg7qdIUEafmYK9rg.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"Offline/Online Testing Framework\"}],[\"hr\",{}],[\"image\",{\"src\":\"https://cdn-images-1.medium.com/max/1600/1*i-3rNsokIOjyoBRgeiOhvA.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"Similar User Recommendations on&nbsp;Linkedin\"}],[\"image\",{\"src\":\"https://cdn-images-1.medium.com/max/1600/1*A1NpLcH0HG0RrBB3oOTVKA.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"Similar Companies Recommendations on&nbsp;Linkedin\"}],[\"image\",{\"src\":\"https://cdn-images-1.medium.com/max/1600/1*ZopV25d9-x1Gma5-YIbkIA.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"Personalizing Spotify Home with Machine Learning (Source:&nbsp;<a href=\\\"https://www.oreilly.com/radar/personalization-of-spotify-home-and-tensorflow/\\\" data-href=\\\"https://www.oreilly.com/radar/personalization-of-spotify-home-and-tensorflow/\\\" class=\\\"markup--anchor markup--figure-anchor\\\" rel=\\\"noopener\\\" target=\\\"_blank\\\">Spotify</a>)\"}],[\"image\",{\"src\":\"https://cdn-images-1.medium.com/max/1600/1*Edcu3SHtcLuF5aZqI1N_rw.png\",\"alt\":\"\",\"title\":\"\",\"caption\":\"New YouTube Home&nbsp;Page\"}],[\"hr\",{}],[\"hr\",{}],[\"hr\",{}],[\"hr\",{}],[\"hr\",{}]],\"markups\":[[\"a\",[\"href\",\"https://towardsdatascience.com/recommender-systems-the-most-valuable-application-of-machine-learning-2bc6903c63ce\"]],[\"em\"],[\"a\",[\"href\",\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\",\"rel\",\"noopener\"]],[\"strong\"],[\"a\",[\"href\",\"https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.udacity.com/course/ab-testing--ud257\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://netflixtechblog.com/how-we-determine-product-success-980f81f0047e\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://eng.uber.com/uber-eats-recommending-marketplace/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://dl.acm.org/doi/pdf/10.1145/2843948\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://youtube-creators.googleblog.com/2012/08/youtube-now-why-we-focus-on-watch-time.html\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e\"]],[\"a\",[\"href\",\"https://netflixtechblog.com/learning-a-personalized-homepage-aa8ec670359a\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://labs.spotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Cold_start_%28computing%29\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.zillow.com/tech/embedding-similar-home-recommendation/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://anotherdatum.com/exploration-exploitation.html\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"http://sigir.org/afirm2019/slides/16.%20Friday%20-%20Music%20Recommendation%20at%20Spotify%20-%20Ben%20Carterette.pdf\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=kY-BCNHd_dM\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=Bo8MY4JpiXE\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://www.amazon.science/the-history-of-amazons-recommendation-algorithm\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://ls13-www.cs.tu-dortmund.de/homepage/rsweb2014/papers/rsweb2014_submission_3.pdf\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://dl.acm.org/doi/pdf/10.1145/2843948\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://netflixtechblog.com/learning-a-personalized-homepage-aa8ec670359a\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://pdfs.semanticscholar.org/f635/6c70452b3f56dc1ae07b4649a80239afb1b6.pdf\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://labs.spotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://www.slideshare.net/MrChrisJohnson/from-idea-to-execution-spotifys-discover-weekly/31-1_0_0_0_1\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://eng.uber.com/uber-eats-recommending-marketplace/\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://eng.uber.com/uber-eats-graph-learning/\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://www.inf.unibz.it/~ricci/ISR/papers/p293-davidson.pdf\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://arxiv.org/pdf/1409.2944.pdf\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://www.zillow.com/tech/embedding-similar-home-recommendation/\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=giIXNoiqO_U&list=PL-6SiIrhTAi6x4Oq28s7yy94ubLzVXabj\",\"rel\",\"noopener nofollow noopener noopener\"]],[\"a\",[\"href\",\"https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture\",\"rel\",\"noopener nofollow noopener noopener\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Why Recommender Systems are the most valuable application of Machine Learning and how Machine Learning-driven Recommenders already drive almost every aspect of our lives.\"]]],[1,\"p\",[[0,[0],1,\"Read this article on Medium.\"]]],[10,0],[10,1],[1,\"p\",[[0,[],0,\"This is the second part of the article published on 11 May. In the first part I covered:\"]]],[3,\"ul\",[[[0,[],0,\"Business Value\"]],[[0,[],0,\"Problem Formulation\"]],[[0,[],0,\"Data\"]],[[0,[],0,\"Algorithms\"]]]],[1,\"p\",[[0,[],0,\"In this second part I will cover the following topics:\"]]],[3,\"ul\",[[[0,[],0,\"Evaluation Metrics\"]],[[0,[],0,\"User Interface\"]],[[0,[],0,\"Cold-start Problem\"]],[[0,[],0,\"Exploration vs. Exploitation\"]],[[0,[],0,\"The Future of Recommender Systems\"]]]],[1,\"p\",[[0,[],0,\"Throughout this article, I will continue to use examples of the companies that have built the most widely used systems over the last couple of years, including Airbnb, Amazon, Instagram, LinkedIn, Netflix, Spotify, Uber Eats, and YouTube.\"]]],[10,2],[1,\"h3\",[[0,[],0,\"Evaluation Metrics\"]]],[1,\"p\",[[0,[],0,\"Now that we have the algorithm for our Recommender System, we need to find a way to evaluate its performance. As with every Machine Learning model, there are two types of evaluation:\"]]],[3,\"ol\",[[[0,[],0,\"Offline Evaluation\"]],[[0,[],0,\"Online Evaluation\"]]]],[10,3],[1,\"p\",[[0,[],0,\"Generally speaking, we can consider the Offline Evaluation metrics as \"],[0,[1],1,\"low-level\"],[0,[],0,\" metrics, that are usually easily measurable. The most well-known example would be Netflix choosing to use \"],[0,[1],1,\"root mean squared error\"],[0,[],0,\" (RMSE) as a proxy metric for their Netflix Prize Challenge. The Online Evaluation metrics are the \"],[0,[1],1,\"high-level\"],[0,[],0,\" business metrics that are only measurable as soon as we ship our model into the real world and test it with real users. Some examples include customer retention, click-through rate, or user engagement.\"]]],[1,\"h4\",[[0,[],0,\"Offline Evaluation\"]]],[1,\"p\",[[0,[],0,\"As most of the existing Recommender Systems consist of two stages (candidate generation and ranking), we need to pick the right metrics for each stage. For the candidate generation stage,\"],[0,[2],1,\" YouTube\"],[0,[],0,\", for instance, focuses on \"],[0,[3],1,\"high precision\"],[0,[],0,\" so \"],[0,[1],1,\"“out of all the videos that were pre-selected how many are relevant”\"],[0,[],0,\". This makes sense given that in the first stage we want to filter for a smaller set of videos whilst making sure all of them are potentially relevant to the user. In the second stage, presenting a few “best” recommendations in a list requires a fine-level representation to distinguish relative importance among candidates with \"],[0,[3],1,\"high recall \"],[0,[],0,\"(\"],[0,[1],1,\"“how many of the relevant videos did we find”\"],[0,[],0,\")\"],[0,[3],1,\".\"]]],[1,\"p\",[[0,[],0,\"Often, most of the examples are using the standard evaluation metrics used in the Machine Learning community: from ranking measures, such as normalized discounted cumulative gain, mean reciprocal rank, or fraction of concordant pairs, to classification metrics including accuracy, precision, recall, or F-score.\"]]],[1,\"p\",[[0,[4],1,\"Instagram formulated\"],[0,[],0,\" the optimization function of their final pass model a little different:\"]]],[1,\"blockquote\",[[0,[],0,\"We predict individual actions that people take on each piece of media, whether they’re positive actions such as like and save, or negative actions such as “See Fewer Posts Like This” (SFPLT). We use a multi-task multi-label (MTML) neural network to predict these events.\"]]],[1,\"p\",[[0,[],0,\"As appealing as offline experiments are, they have a major drawback: they assume that members would have behaved in the same way, for example, playing the same videos, if the new algorithm being evaluated had been used to generate the recommendations. That’s why we need online evaluation to measure the actual impact our model has on the higher-level business metrics.\"]]],[1,\"h4\",[[0,[],0,\"Online Evaluation\"]]],[1,\"p\",[[0,[],0,\"The approach to be aware of here is A/B testing. There are many interesting and exhaustive articles/\"],[0,[5],1,\"courses\"],[0,[],0,\" that cover this well, therefore I won’t spend too much time on this. The only slight variation I have encountered is Netflix’s approach called “Consumer Data Science” that you can\"],[0,[6],1,\" read about it here\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"The most popular high-level metrics that companies are measuring here are \"],[0,[1],1,\"Click-Through Rate\"],[0,[],0,\" and \"],[0,[1],1,\"Engagement\"],[0,[],0,\". Uber Eats goes further here and designed a multi-objective tradeoff that\"],[0,[7],1,\" captures multiple high-level metrics\"],[0,[],0,\" to account for the overall health of their three-sided marketplace (among others: Marketplace Fairness, Gross Bookings, Reliability, Eater Happiness). In addition to medium-term engagement, Netflix focuses on member retention rates as their online tests can\"],[0,[8],1,\" range from between 2–6 months\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"YouTube famously prioritizes watch-time over click-through rate. They even\"],[0,[9],1,\" wrote an article, explaining why\"],[0,[],0,\":\"]]],[1,\"blockquote\",[[0,[],0,\"Ranking by click-through rate often promotes deceptive videos that the user does not complete (“clickbait”) whereas watch time better captures engagement\"]]],[1,\"h4\",[[0,[],0,\"Evaluating Embeddings\"]]],[1,\"p\",[[0,[],0,\"As covered in the section on algorithms, embeddings are a crucial part of the candidate generation stage. However, unlike with a classification or regression model, it’s\"],[0,[10],1,\" notoriously difficult to measure the quality of an embedding\"],[0,[],0,\" given that they are often being used in different contexts. A sanity check we can perform is to map the high-dimensional embedding vector into a lower-dimensional representation (via PCA, t-SNE, or UMAP) or apply clustering techniques such as k-means and then visualize the results. Airbnb did this with their\"],[0,[11],1,\" listing embeddings\"],[0,[],0,\" to confirm that listings from similar locations are clustered together.\"]]],[10,4],[1,\"h3\",[[0,[],0,\"User Interface\"]]],[1,\"p\",[[0,[],0,\"For a Machine Learning Engineer or Data Scientist, the probably most overlooked aspect of the equation is the User Interface. The problem is that if your UI does not contain the needed components to showcase the recommendations or showcases them in the wrong context, the feedback loop is inherently flawed.\"]]],[1,\"p\",[[0,[],0,\"Let’s take Linkedin as an example to illustrate this. If I’m browsing through people’s profiles, on the right-hand side of the screen I see recommendations for \"],[0,[1],1,\"similar people\"],[0,[],0,\". When I’m browsing through companies, I see recommendations for \"],[0,[1],1,\"similar companies\"],[0,[],0,\". The recommendations are adapted to my current goals and context and encourage me to keep browsing the site. If the \"],[0,[1],1,\"similar companies\"],[0,[],0,\" recommendations would appear on a person’s profile, I would probably be less encouraged to click on their profile as it is not what I am currently looking for.\"]]],[10,5],[10,6],[1,\"p\",[[0,[],0,\"You can build the best Recommender System in the world, however, if your interface is not designed to serve the user’s needs and wants, no one will appreciate the recommendations. In fact, the User Interface challenge is so crucial that\"],[0,[12],1,\" Netflix turned all components on their website into dynamic ones\"],[0,[],0,\" which are assembled by a Machine Learning algorithm to best reflect the goals of a user.\"]]],[1,\"p\",[[0,[],0,\"Spotify followed that model and \"],[0,[13],1,\"adopted a similar layout for their home screen design\"],[0,[],0,\", as can be seen below.\"]]],[10,7],[1,\"p\",[[0,[],0,\"This is an ongoing area where there is still a lot of experimentation. As an example, YouTube recently changed their homepage interface to enable users to narrow down the recommendations for different topics:\"]]],[10,8],[10,9],[1,\"h3\",[[0,[],0,\"Cold-start Problem\"]]],[1,\"p\",[[0,[],0,\"The\"],[0,[14],1,\" cold-start problem\"],[0,[],0,\" is often seen in Recommender Systems because methods such as collaborative filtering rely heavily on past user-item interactions. Companies are confronted with the cold-start problem in two ways: user and item cold-start. Depending on the type of platform, either one of them is more prevalent.\"]]],[1,\"h4\",[[0,[],0,\"User cold-start\"]]],[1,\"p\",[[0,[],0,\"Imagine a new member signs up for Netflix. At this point, the company doesn’t know anything about the new members’ preferences. How does the company keep her engaged by providing great recommendations?\"]]],[1,\"p\",[[0,[],0,\"In Netflix’s case, new members get a one-month free trial, during which cancellation rates are the highest while they decrease quickly after that. This is why any improvements to the cold-start problem present an immense business opportunity for Netflix, in order to increase engagement and retention in those first 30 days. Today, their members are given a survey during the sign-up process, during which they are asked to select videos from an algorithmically populated set that is then used as an input into all of their algorithms.\"]]],[1,\"h4\",[[0,[],0,\"Item cold-start\"]]],[1,\"p\",[[0,[],0,\"Companies face a similar challenge when new items or content are added to the catalog. Platforms like Netflix or Prime Video hold an existing catalog of media items that changes less frequently (it takes time to create movies or series!), therefore they struggle less with this. On the contrary, on Airbnb or Zillow, new listings are created every day and at that point, they do not have an embedding as they were not present during the training process. Airbnb solves this the following way:\"]]],[1,\"blockquote\",[[0,[],0,\"To create embeddings for a new listing we find 3 geographically closest listings that do have embeddings, and are of same listing type and price range as the new listing, and calculate their mean vector.\"]]],[1,\"p\",[[0,[],0,\"For Zillow, this is especially critical as some of the new home listings might only be on the site for a couple of days. They\"],[0,[15],1,\" creatively solved this problem\"],[0,[],0,\" by creating a neural network-based mapping function from the content space to the embedding space, which is guided by the engagement data from users during the learning phase. This allows them to map a new home listing to the learned embedding space just by using its features.\"]]],[10,10],[1,\"h3\",[[0,[],0,\"Exploration vs. Exploitation\"]]],[1,\"p\",[[0,[],0,\"The concept of exploration/exploitation can be seen as the balancing of new content with well-established content. I was going to illustrate this concept myself, while I found this great excerpt that hits it right out of the ballpark:\"]]],[1,\"blockquote\",[[0,[],0,\"“Imagine you’ve just entered an ice cream shop. You now face a crucial decision — out of about 30 flavors you need to choose only one!\"],[1,[],0,0],[0,[],0,\"You can go with two strategies: either go with that favorite flavor of yours that you already know is the best; or explore new flavors you never tried before, and maybe find a new best flavor.\"],[1,[],0,1],[0,[],0,\"These two strategies — exploitation and exploration — can also be used when recommending content. We can either exploit items that have high click-through rate with high certainty — maybe because these items have been shown thousands of times to similar users, or we can explore new items we haven’t shown to many users in the past. Incorporating exploration into your recommendation strategy is crucial — without it, new items don’t stand a chance against older, more familiar ones.”\"]]],[1,\"p\",[[0,[1],1,\"(Source: \"],[0,[16,1],2,\"Recommender Systems: Exploring the Unknown Using Uncertainty\"],[0,[1],1,\")\"]]],[1,\"p\",[[0,[],0,\"This tradeoff is a typical reinforcement learning problem and a commonly used approach is the multi-armed bandit algorithm. This is used by Spotify for the\"],[0,[17],1,\" personalization of each users’ home page\"],[0,[],0,\" as well as Uber Eats for personalized recommendations\"],[0,[7],1,\" optimized for their three-sided marketplace\"],[0,[],0,\". Two scientists at Netflix gave a great talk about how they are\"],[0,[18],1,\" using the MAB framework for movie recommendations\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"Though I should mention that this is, by no means, the final solution to this problem, it seems to work for Netflix, Spotify, and Uber Eats, right?\"]]],[1,\"p\",[[0,[],0,\"Yes. But!\"]]],[1,\"p\",[[0,[],0,\"Netflix has roughly 160 million users and about 6.000 movies/shows. Spotify has about 230 million users and 50 million songs + 500.000 podcasts.\"]]],[1,\"p\",[[0,[],0,\"Twitter’s 330 million active users generate more than \"],[0,[3,1],2,\"500 million tweets\"],[0,[],0,\" per day (350.000 tweets per minute, 6.000 tweets per second). And then there’s YouTube, with its \"],[0,[3,1],2,\"300 hours of videos\"],[0,[],0,\" uploaded every minute!\"]]],[1,\"p\",[[0,[],0,\"The exploration space in the two latter cases is a \"],[0,[1],1,\"little\"],[0,[],0,\" bit bigger than in the case of Netflix or Uber Eats, which makes the problem a lot more challenging.\"]]],[10,11],[1,\"h3\",[[0,[],0,\"The Future of Recommender Systems\"]]],[1,\"p\",[[0,[],0,\"This is the end of my little survey over Recommender Systems. As we have observed, Recommender Systems already guide so many aspects of our life. All the algorithms we covered over the course of these two articles are competing for our attention every day. And after all, they are all maximizing the time spent on their platform. As I illustrated in the section on Evaluation methods, most of the algorithms are optimizing for something like Click-through rate, engagement, or in YouTube’s case: watch time.\"]]],[1,\"p\",[[0,[3,1],2,\"What does that mean for us as a consumer?\"]]],[1,\"p\",[[0,[],0,\"What it means is, that we are not in control of our desires anymore. While this might sound poetic, think about it. Let’s look at YouTube; we all have goals when coming to the site. We might want to listen to music, watch something funny, or learn something new. But all the content that is recommended to us (either through the Home Page recommendations, Search Ranking, or Watch Next) is optimized to keep us on the site for longer.\"]]],[1,\"p\",[[0,[],0,\"Lex Fridman and François Chollet had a\"],[0,[19],1,\" great conversation about this\"],[0,[],0,\" on the Artificial Intelligence Podcast. Instead of choosing the metric to optimize for, what if companies would put the user in charge of choosing their own objective function? What if they would take the personal goals of the user’s profile into account and ask the user, what do you want to achieve? Right now, this technology is almost like our boss and we’re not in control of it. Wouldn’t it be incredible to leverage the power of Recommender Systems to be more like a mentor, a coach, or an assistant?\"]]],[1,\"p\",[[0,[],0,\"Imagine, as a consumer, you could ask YouTube to optimize the content to maximize learning outcomes. The technology is certainly already there. The challenge would really lie in aligning this with the existing business models and designing the right interface to empower the user to make that choice, and also to change as their goals evolve. With its new interface, YouTube is perhaps already taking baby-steps in that direction by putting the user in charge to select categories that she wants to see recommendations for. But this is just the beginning.\"]]],[1,\"p\",[[0,[],0,\"Could this be the way forward or is this just a consumer’s dream?\"]]],[10,12],[1,\"p\",[[0,[3,1],2,\"Resources\"]]],[1,\"p\",[[0,[19],1,\"François Chollet: Keras, Deep Learning, and the Progress of AI | Artificial Intelligence Podcast\"]]],[1,\"p\",[[0,[20],1,\"Airbnb — Listing Embeddings in Search Ranking\"]]],[1,\"p\",[[0,[21],1,\"Airbnb — Machine Learning-Powered Search Ranking of Airbnb Experiences\"]]],[1,\"p\",[[0,[22],1,\"Amazon — Amazon.com Recommendations Item-to-Item Collaborative Filtering\"]]],[1,\"p\",[[0,[23],1,\"Amazon — The history of Amazon’s recommendation algorithm\"]]],[1,\"p\",[[0,[24],1,\"Instagram — Powered by AI: Instagram’s Explore recommender system\"]]],[1,\"p\",[[0,[25],1,\"LinkedIn — The Browsemaps: Collaborative Filtering at LinkedIn\"]]],[1,\"p\",[[0,[26],1,\"Netflix — Netflix Recommendations: Beyond the 5 stars (Part 1)\"]]],[1,\"p\",[[0,[27],1,\"Netflix — Netflix Recommendations: Beyond the 5 stars (Part 2)\"]]],[1,\"p\",[[0,[28],1,\"Netflix — The Netflix Recommender System: Algorithms, Business Value, and Innovation\"]]],[1,\"p\",[[0,[29],1,\"Netflix — Learning a Personalized Homepage\"]]],[1,\"p\",[[0,[30],1,\"Pandora — Pandora’s Music Recommender\"]]],[1,\"p\",[[0,[31],1,\"Spotify — Discover Weekly: How Does Spotify Know You So Well?\"]]],[1,\"p\",[[0,[32],1,\"Spotify — For Your Ears Only: Personalizing Spotify Home with Machine Learning\"]]],[1,\"p\",[[0,[33],1,\"Spotify — From Idea to Execution: Spotify’s Discover Weekly\"]]],[1,\"p\",[[0,[34],1,\"Twitter — Embeddings@Twitter\"]]],[1,\"p\",[[0,[35],1,\"Uber Eats — Food Discovery with Uber Eats: Recommending for the Marketplace\"]]],[1,\"p\",[[0,[36],1,\"Uber Eats — Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations\"]]],[1,\"p\",[[0,[37],1,\"YouTube — The YouTube Video Recommendation System\"]]],[1,\"p\",[[0,[38],1,\"YouTube — Collaborative Deep Learning for Recommender Systems\"]]],[1,\"p\",[[0,[39],1,\"YouTube — Deep Neural Networks for YouTube Recommendations\"]]],[1,\"p\",[[0,[40],1,\"Zillow — Home Embeddings for Similar Home Recommendations\"]]],[1,\"p\",[[0,[41],1,\"Andrew Ng’s Machine Learning Course (Recommender Systems)\"]]],[1,\"p\",[[0,[42],1,\"Google’s Machine Learning Crash Course — Embeddings\"]]],[10,13],[1,\"p\",[[1,[],0,2]]]],\"ghostVersion\":\"3.0\"}","html":"<p>Why Recommender Systems are the most valuable application of Machine Learning and how Machine Learning-driven Recommenders already drive almost every aspect of our lives.</p><p><a href=\"https://towardsdatascience.com/recommender-systems-the-most-valuable-application-of-machine-learning-2bc6903c63ce\">Read this article on Medium.</a></p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*F2mBbZRHPXxa3cyg3z8esg.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Recommender Systems already drive almost every aspect of our daily&nbsp;lives.</figcaption></figure><hr><p>This is the second part of the article published on 11 May. In the first part I covered:</p><ul><li>Business Value</li><li>Problem Formulation</li><li>Data</li><li>Algorithms</li></ul><p>In this second part I will cover the following topics:</p><ul><li>Evaluation Metrics</li><li>User Interface</li><li>Cold-start Problem</li><li>Exploration vs. Exploitation</li><li>The Future of Recommender Systems</li></ul><p>Throughout this article, I will continue to use examples of the companies that have built the most widely used systems over the last couple of years, including Airbnb, Amazon, Instagram, LinkedIn, Netflix, Spotify, Uber Eats, and YouTube.</p><hr><h3 id=\"evaluation-metrics\">Evaluation Metrics</h3><p>Now that we have the algorithm for our Recommender System, we need to find a way to evaluate its performance. As with every Machine Learning model, there are two types of evaluation:</p><ol><li>Offline Evaluation</li><li>Online Evaluation</li></ol><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*HjqVASOg7qdIUEafmYK9rg.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Offline/Online Testing Framework</figcaption></figure><p>Generally speaking, we can consider the Offline Evaluation metrics as <em>low-level</em> metrics, that are usually easily measurable. The most well-known example would be Netflix choosing to use <em>root mean squared error</em> (RMSE) as a proxy metric for their Netflix Prize Challenge. The Online Evaluation metrics are the <em>high-level</em> business metrics that are only measurable as soon as we ship our model into the real world and test it with real users. Some examples include customer retention, click-through rate, or user engagement.</p><h4 id=\"offline-evaluation\">Offline Evaluation</h4><p>As most of the existing Recommender Systems consist of two stages (candidate generation and ranking), we need to pick the right metrics for each stage. For the candidate generation stage,<a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\" rel=\"noopener\"> YouTube</a>, for instance, focuses on <strong>high precision</strong> so <em>“out of all the videos that were pre-selected how many are relevant”</em>. This makes sense given that in the first stage we want to filter for a smaller set of videos whilst making sure all of them are potentially relevant to the user. In the second stage, presenting a few “best” recommendations in a list requires a fine-level representation to distinguish relative importance among candidates with <strong>high recall </strong>(<em>“how many of the relevant videos did we find”</em>)<strong>.</strong></p><p>Often, most of the examples are using the standard evaluation metrics used in the Machine Learning community: from ranking measures, such as normalized discounted cumulative gain, mean reciprocal rank, or fraction of concordant pairs, to classification metrics including accuracy, precision, recall, or F-score.</p><p><a href=\"https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/\" rel=\"noopener\">Instagram formulated</a> the optimization function of their final pass model a little different:</p><blockquote>We predict individual actions that people take on each piece of media, whether they’re positive actions such as like and save, or negative actions such as “See Fewer Posts Like This” (SFPLT). We use a multi-task multi-label (MTML) neural network to predict these events.</blockquote><p>As appealing as offline experiments are, they have a major drawback: they assume that members would have behaved in the same way, for example, playing the same videos, if the new algorithm being evaluated had been used to generate the recommendations. That’s why we need online evaluation to measure the actual impact our model has on the higher-level business metrics.</p><h4 id=\"online-evaluation\">Online Evaluation</h4><p>The approach to be aware of here is A/B testing. There are many interesting and exhaustive articles/<a href=\"https://www.udacity.com/course/ab-testing--ud257\" rel=\"noopener\">courses</a> that cover this well, therefore I won’t spend too much time on this. The only slight variation I have encountered is Netflix’s approach called “Consumer Data Science” that you can<a href=\"https://netflixtechblog.com/how-we-determine-product-success-980f81f0047e\" rel=\"noopener\"> read about it here</a>.</p><p>The most popular high-level metrics that companies are measuring here are <em>Click-Through Rate</em> and <em>Engagement</em>. Uber Eats goes further here and designed a multi-objective tradeoff that<a href=\"https://eng.uber.com/uber-eats-recommending-marketplace/\" rel=\"noopener\"> captures multiple high-level metrics</a> to account for the overall health of their three-sided marketplace (among others: Marketplace Fairness, Gross Bookings, Reliability, Eater Happiness). In addition to medium-term engagement, Netflix focuses on member retention rates as their online tests can<a href=\"https://dl.acm.org/doi/pdf/10.1145/2843948\" rel=\"noopener\"> range from between 2–6 months</a>.</p><p>YouTube famously prioritizes watch-time over click-through rate. They even<a href=\"https://youtube-creators.googleblog.com/2012/08/youtube-now-why-we-focus-on-watch-time.html\" rel=\"noopener\"> wrote an article, explaining why</a>:</p><blockquote>Ranking by click-through rate often promotes deceptive videos that the user does not complete (“clickbait”) whereas watch time better captures engagement</blockquote><h4 id=\"evaluating-embeddings\">Evaluating Embeddings</h4><p>As covered in the section on algorithms, embeddings are a crucial part of the candidate generation stage. However, unlike with a classification or regression model, it’s<a href=\"https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html\" rel=\"noopener\"> notoriously difficult to measure the quality of an embedding</a> given that they are often being used in different contexts. A sanity check we can perform is to map the high-dimensional embedding vector into a lower-dimensional representation (via PCA, t-SNE, or UMAP) or apply clustering techniques such as k-means and then visualize the results. Airbnb did this with their<a href=\"https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e\"> listing embeddings</a> to confirm that listings from similar locations are clustered together.</p><hr><h3 id=\"user-interface\">User Interface</h3><p>For a Machine Learning Engineer or Data Scientist, the probably most overlooked aspect of the equation is the User Interface. The problem is that if your UI does not contain the needed components to showcase the recommendations or showcases them in the wrong context, the feedback loop is inherently flawed.</p><p>Let’s take Linkedin as an example to illustrate this. If I’m browsing through people’s profiles, on the right-hand side of the screen I see recommendations for <em>similar people</em>. When I’m browsing through companies, I see recommendations for <em>similar companies</em>. The recommendations are adapted to my current goals and context and encourage me to keep browsing the site. If the <em>similar companies</em> recommendations would appear on a person’s profile, I would probably be less encouraged to click on their profile as it is not what I am currently looking for.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*i-3rNsokIOjyoBRgeiOhvA.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Similar User Recommendations on&nbsp;Linkedin</figcaption></figure><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*A1NpLcH0HG0RrBB3oOTVKA.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Similar Companies Recommendations on&nbsp;Linkedin</figcaption></figure><p>You can build the best Recommender System in the world, however, if your interface is not designed to serve the user’s needs and wants, no one will appreciate the recommendations. In fact, the User Interface challenge is so crucial that<a href=\"https://netflixtechblog.com/learning-a-personalized-homepage-aa8ec670359a\" rel=\"noopener\"> Netflix turned all components on their website into dynamic ones</a> which are assembled by a Machine Learning algorithm to best reflect the goals of a user.</p><p>Spotify followed that model and <a href=\"https://labs.spotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/\" rel=\"noopener\">adopted a similar layout for their home screen design</a>, as can be seen below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*ZopV25d9-x1Gma5-YIbkIA.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>Personalizing Spotify Home with Machine Learning (Source:&nbsp;<a href=\"https://www.oreilly.com/radar/personalization-of-spotify-home-and-tensorflow/\" data-href=\"https://www.oreilly.com/radar/personalization-of-spotify-home-and-tensorflow/\" class=\"markup--anchor markup--figure-anchor\" rel=\"noopener\" target=\"_blank\">Spotify</a>)</figcaption></figure><p>This is an ongoing area where there is still a lot of experimentation. As an example, YouTube recently changed their homepage interface to enable users to narrow down the recommendations for different topics:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://cdn-images-1.medium.com/max/1600/1*Edcu3SHtcLuF5aZqI1N_rw.png\" class=\"kg-image\" alt loading=\"lazy\"><figcaption>New YouTube Home&nbsp;Page</figcaption></figure><hr><h3 id=\"cold-start-problem\">Cold-start Problem</h3><p>The<a href=\"https://en.wikipedia.org/wiki/Cold_start_%28computing%29\" rel=\"noopener\"> cold-start problem</a> is often seen in Recommender Systems because methods such as collaborative filtering rely heavily on past user-item interactions. Companies are confronted with the cold-start problem in two ways: user and item cold-start. Depending on the type of platform, either one of them is more prevalent.</p><h4 id=\"user-cold-start\">User cold-start</h4><p>Imagine a new member signs up for Netflix. At this point, the company doesn’t know anything about the new members’ preferences. How does the company keep her engaged by providing great recommendations?</p><p>In Netflix’s case, new members get a one-month free trial, during which cancellation rates are the highest while they decrease quickly after that. This is why any improvements to the cold-start problem present an immense business opportunity for Netflix, in order to increase engagement and retention in those first 30 days. Today, their members are given a survey during the sign-up process, during which they are asked to select videos from an algorithmically populated set that is then used as an input into all of their algorithms.</p><h4 id=\"item-cold-start\">Item cold-start</h4><p>Companies face a similar challenge when new items or content are added to the catalog. Platforms like Netflix or Prime Video hold an existing catalog of media items that changes less frequently (it takes time to create movies or series!), therefore they struggle less with this. On the contrary, on Airbnb or Zillow, new listings are created every day and at that point, they do not have an embedding as they were not present during the training process. Airbnb solves this the following way:</p><blockquote>To create embeddings for a new listing we find 3 geographically closest listings that do have embeddings, and are of same listing type and price range as the new listing, and calculate their mean vector.</blockquote><p>For Zillow, this is especially critical as some of the new home listings might only be on the site for a couple of days. They<a href=\"https://www.zillow.com/tech/embedding-similar-home-recommendation/\" rel=\"noopener\"> creatively solved this problem</a> by creating a neural network-based mapping function from the content space to the embedding space, which is guided by the engagement data from users during the learning phase. This allows them to map a new home listing to the learned embedding space just by using its features.</p><hr><h3 id=\"exploration-vs-exploitation\">Exploration vs. Exploitation</h3><p>The concept of exploration/exploitation can be seen as the balancing of new content with well-established content. I was going to illustrate this concept myself, while I found this great excerpt that hits it right out of the ballpark:</p><blockquote>“Imagine you’ve just entered an ice cream shop. You now face a crucial decision — out of about 30 flavors you need to choose only one!<br>You can go with two strategies: either go with that favorite flavor of yours that you already know is the best; or explore new flavors you never tried before, and maybe find a new best flavor.<br>These two strategies — exploitation and exploration — can also be used when recommending content. We can either exploit items that have high click-through rate with high certainty — maybe because these items have been shown thousands of times to similar users, or we can explore new items we haven’t shown to many users in the past. Incorporating exploration into your recommendation strategy is crucial — without it, new items don’t stand a chance against older, more familiar ones.”</blockquote><p><em>(Source: </em><a href=\"https://anotherdatum.com/exploration-exploitation.html\" rel=\"noopener\"><em>Recommender Systems: Exploring the Unknown Using Uncertainty</em></a><em>)</em></p><p>This tradeoff is a typical reinforcement learning problem and a commonly used approach is the multi-armed bandit algorithm. This is used by Spotify for the<a href=\"http://sigir.org/afirm2019/slides/16.%20Friday%20-%20Music%20Recommendation%20at%20Spotify%20-%20Ben%20Carterette.pdf\" rel=\"noopener\"> personalization of each users’ home page</a> as well as Uber Eats for personalized recommendations<a href=\"https://eng.uber.com/uber-eats-recommending-marketplace/\" rel=\"noopener\"> optimized for their three-sided marketplace</a>. Two scientists at Netflix gave a great talk about how they are<a href=\"https://www.youtube.com/watch?v=kY-BCNHd_dM\" rel=\"noopener\"> using the MAB framework for movie recommendations</a>.</p><p>Though I should mention that this is, by no means, the final solution to this problem, it seems to work for Netflix, Spotify, and Uber Eats, right?</p><p>Yes. But!</p><p>Netflix has roughly 160 million users and about 6.000 movies/shows. Spotify has about 230 million users and 50 million songs + 500.000 podcasts.</p><p>Twitter’s 330 million active users generate more than <strong><em>500 million tweets</em></strong> per day (350.000 tweets per minute, 6.000 tweets per second). And then there’s YouTube, with its <strong><em>300 hours of videos</em></strong> uploaded every minute!</p><p>The exploration space in the two latter cases is a <em>little</em> bit bigger than in the case of Netflix or Uber Eats, which makes the problem a lot more challenging.</p><hr><h3 id=\"the-future-of-recommender-systems\">The Future of Recommender Systems</h3><p>This is the end of my little survey over Recommender Systems. As we have observed, Recommender Systems already guide so many aspects of our life. All the algorithms we covered over the course of these two articles are competing for our attention every day. And after all, they are all maximizing the time spent on their platform. As I illustrated in the section on Evaluation methods, most of the algorithms are optimizing for something like Click-through rate, engagement, or in YouTube’s case: watch time.</p><p><strong><em>What does that mean for us as a consumer?</em></strong></p><p>What it means is, that we are not in control of our desires anymore. While this might sound poetic, think about it. Let’s look at YouTube; we all have goals when coming to the site. We might want to listen to music, watch something funny, or learn something new. But all the content that is recommended to us (either through the Home Page recommendations, Search Ranking, or Watch Next) is optimized to keep us on the site for longer.</p><p>Lex Fridman and François Chollet had a<a href=\"https://www.youtube.com/watch?v=Bo8MY4JpiXE\" rel=\"noopener\"> great conversation about this</a> on the Artificial Intelligence Podcast. Instead of choosing the metric to optimize for, what if companies would put the user in charge of choosing their own objective function? What if they would take the personal goals of the user’s profile into account and ask the user, what do you want to achieve? Right now, this technology is almost like our boss and we’re not in control of it. Wouldn’t it be incredible to leverage the power of Recommender Systems to be more like a mentor, a coach, or an assistant?</p><p>Imagine, as a consumer, you could ask YouTube to optimize the content to maximize learning outcomes. The technology is certainly already there. The challenge would really lie in aligning this with the existing business models and designing the right interface to empower the user to make that choice, and also to change as their goals evolve. With its new interface, YouTube is perhaps already taking baby-steps in that direction by putting the user in charge to select categories that she wants to see recommendations for. But this is just the beginning.</p><p>Could this be the way forward or is this just a consumer’s dream?</p><hr><p><strong><em>Resources</em></strong></p><p><a href=\"https://www.youtube.com/watch?v=Bo8MY4JpiXE\" rel=\"noopener\">François Chollet: Keras, Deep Learning, and the Progress of AI | Artificial Intelligence Podcast</a></p><p><a href=\"https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e\" rel=\"noopener\">Airbnb — Listing Embeddings in Search Ranking</a></p><p><a href=\"https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789\" rel=\"noopener\">Airbnb — Machine Learning-Powered Search Ranking of Airbnb Experiences</a></p><p><a href=\"https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf\" rel=\"noopener nofollow noopener noopener\">Amazon — Amazon.com Recommendations Item-to-Item Collaborative Filtering</a></p><p><a href=\"https://www.amazon.science/the-history-of-amazons-recommendation-algorithm\" rel=\"noopener nofollow noopener noopener\">Amazon — The history of Amazon’s recommendation algorithm</a></p><p><a href=\"https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/\" rel=\"noopener nofollow noopener noopener\">Instagram — Powered by AI: Instagram’s Explore recommender system</a></p><p><a href=\"https://ls13-www.cs.tu-dortmund.de/homepage/rsweb2014/papers/rsweb2014_submission_3.pdf\" rel=\"noopener nofollow noopener noopener\">LinkedIn — The Browsemaps: Collaborative Filtering at LinkedIn</a></p><p><a href=\"https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429\" rel=\"noopener nofollow noopener noopener\">Netflix — Netflix Recommendations: Beyond the 5 stars (Part 1)</a></p><p><a href=\"https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5\" rel=\"noopener nofollow noopener noopener\">Netflix — Netflix Recommendations: Beyond the 5 stars (Part 2)</a></p><p><a href=\"https://dl.acm.org/doi/pdf/10.1145/2843948\" rel=\"noopener nofollow noopener noopener\">Netflix — The Netflix Recommender System: Algorithms, Business Value, and Innovation</a></p><p><a href=\"https://netflixtechblog.com/learning-a-personalized-homepage-aa8ec670359a\" rel=\"noopener nofollow noopener noopener\">Netflix — Learning a Personalized Homepage</a></p><p><a href=\"https://pdfs.semanticscholar.org/f635/6c70452b3f56dc1ae07b4649a80239afb1b6.pdf\" rel=\"noopener nofollow noopener noopener\">Pandora — Pandora’s Music Recommender</a></p><p><a href=\"https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe\" rel=\"noopener\">Spotify — Discover Weekly: How Does Spotify Know You So Well?</a></p><p><a href=\"https://labs.spotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/\" rel=\"noopener nofollow noopener noopener\">Spotify — For Your Ears Only: Personalizing Spotify Home with Machine Learning</a></p><p><a href=\"https://www.slideshare.net/MrChrisJohnson/from-idea-to-execution-spotifys-discover-weekly/31-1_0_0_0_1\" rel=\"noopener nofollow noopener noopener\">Spotify — From Idea to Execution: Spotify’s Discover Weekly</a></p><p><a href=\"https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html\" rel=\"noopener nofollow noopener noopener\">Twitter — Embeddings@Twitter</a></p><p><a href=\"https://eng.uber.com/uber-eats-recommending-marketplace/\" rel=\"noopener nofollow noopener noopener\">Uber Eats — Food Discovery with Uber Eats: Recommending for the Marketplace</a></p><p><a href=\"https://eng.uber.com/uber-eats-graph-learning/\" rel=\"noopener nofollow noopener noopener\">Uber Eats — Food Discovery with Uber Eats: Using Graph Learning to Power Recommendations</a></p><p><a href=\"https://www.inf.unibz.it/~ricci/ISR/papers/p293-davidson.pdf\" rel=\"noopener nofollow noopener noopener\">YouTube — The YouTube Video Recommendation System</a></p><p><a href=\"https://arxiv.org/pdf/1409.2944.pdf\" rel=\"noopener nofollow noopener noopener\">YouTube — Collaborative Deep Learning for Recommender Systems</a></p><p><a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf\" rel=\"noopener nofollow noopener noopener\">YouTube — Deep Neural Networks for YouTube Recommendations</a></p><p><a href=\"https://www.zillow.com/tech/embedding-similar-home-recommendation/\" rel=\"noopener nofollow noopener noopener\">Zillow — Home Embeddings for Similar Home Recommendations</a></p><p><a href=\"https://www.youtube.com/watch?v=giIXNoiqO_U&amp;list=PL-6SiIrhTAi6x4Oq28s7yy94ubLzVXabj\" rel=\"noopener nofollow noopener noopener\">Andrew Ng’s Machine Learning Course (Recommender Systems)</a></p><p><a href=\"https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture\" rel=\"noopener nofollow noopener noopener\">Google’s Machine Learning Crash Course — Embeddings</a></p><hr>","comment_id":"5f7a34da3ffbdb6a6f04d6db","plaintext":"Why Recommender Systems are the most valuable application of Machine Learning\nand how Machine Learning-driven Recommenders already drive almost every aspect\nof our lives.\n\nRead this article on Medium.\n[https://towardsdatascience.com/recommender-systems-the-most-valuable-application-of-machine-learning-2bc6903c63ce]\n\nRecommender Systems already drive almost every aspect of our daily lives.\n--------------------------------------------------------------------------------\n\nThis is the second part of the article published on 11 May. In the first part I\ncovered:\n\n * Business Value\n * Problem Formulation\n * Data\n * Algorithms\n\nIn this second part I will cover the following topics:\n\n * Evaluation Metrics\n * User Interface\n * Cold-start Problem\n * Exploration vs. Exploitation\n * The Future of Recommender Systems\n\nThroughout this article, I will continue to use examples of the companies that\nhave built the most widely used systems over the last couple of years, including\nAirbnb, Amazon, Instagram, LinkedIn, Netflix, Spotify, Uber Eats, and YouTube.\n\n\n--------------------------------------------------------------------------------\n\nEvaluation Metrics\nNow that we have the algorithm for our Recommender System, we need to find a way\nto evaluate its performance. As with every Machine Learning model, there are two\ntypes of evaluation:\n\n 1. Offline Evaluation\n 2. Online Evaluation\n\nOffline/Online Testing FrameworkGenerally speaking, we can consider the Offline\nEvaluation metrics as low-level metrics, that are usually easily measurable. The\nmost well-known example would be Netflix choosing to use root mean squared error \n(RMSE) as a proxy metric for their Netflix Prize Challenge. The Online\nEvaluation metrics are the high-level business metrics that are only measurable\nas soon as we ship our model into the real world and test it with real users.\nSome examples include customer retention, click-through rate, or user\nengagement.\n\nOffline Evaluation\nAs most of the existing Recommender Systems consist of two stages (candidate\ngeneration and ranking), we need to pick the right metrics for each stage. For\nthe candidate generation stage, YouTube\n[https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf]\n, for instance, focuses on high precision so “out of all the videos that were\npre-selected how many are relevant”. This makes sense given that in the first\nstage we want to filter for a smaller set of videos whilst making sure all of\nthem are potentially relevant to the user. In the second stage, presenting a few\n“best” recommendations in a list requires a fine-level representation to\ndistinguish relative importance among candidates with high recall (“how many of\nthe relevant videos did we find”).\n\nOften, most of the examples are using the standard evaluation metrics used in\nthe Machine Learning community: from ranking measures, such as normalized\ndiscounted cumulative gain, mean reciprocal rank, or fraction of concordant\npairs, to classification metrics including accuracy, precision, recall, or\nF-score.\n\nInstagram formulated\n[https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/] \nthe optimization function of their final pass model a little different:\n\n> We predict individual actions that people take on each piece of media, whether\nthey’re positive actions such as like and save, or negative actions such as “See\nFewer Posts Like This” (SFPLT). We use a multi-task multi-label (MTML) neural\nnetwork to predict these events.\nAs appealing as offline experiments are, they have a major drawback: they assume\nthat members would have behaved in the same way, for example, playing the same\nvideos, if the new algorithm being evaluated had been used to generate the\nrecommendations. That’s why we need online evaluation to measure the actual\nimpact our model has on the higher-level business metrics.\n\nOnline Evaluation\nThe approach to be aware of here is A/B testing. There are many interesting and\nexhaustive articles/courses [https://www.udacity.com/course/ab-testing--ud257] \nthat cover this well, therefore I won’t spend too much time on this. The only\nslight variation I have encountered is Netflix’s approach called “Consumer Data\nScience” that you can read about it here\n[https://netflixtechblog.com/how-we-determine-product-success-980f81f0047e].\n\nThe most popular high-level metrics that companies are measuring here are \nClick-Through Rate and Engagement. Uber Eats goes further here and designed a\nmulti-objective tradeoff that captures multiple high-level metrics\n[https://eng.uber.com/uber-eats-recommending-marketplace/] to account for the\noverall health of their three-sided marketplace (among others: Marketplace\nFairness, Gross Bookings, Reliability, Eater Happiness). In addition to\nmedium-term engagement, Netflix focuses on member retention rates as their\nonline tests can range from between 2–6 months\n[https://dl.acm.org/doi/pdf/10.1145/2843948].\n\nYouTube famously prioritizes watch-time over click-through rate. They even \nwrote\nan article, explaining why\n[https://youtube-creators.googleblog.com/2012/08/youtube-now-why-we-focus-on-watch-time.html]\n:\n\n> Ranking by click-through rate often promotes deceptive videos that the user does\nnot complete (“clickbait”) whereas watch time better captures engagement\nEvaluating Embeddings\nAs covered in the section on algorithms, embeddings are a crucial part of the\ncandidate generation stage. However, unlike with a classification or regression\nmodel, it’s notoriously difficult to measure the quality of an embedding\n[https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html] \ngiven that they are often being used in different contexts. A sanity check we\ncan perform is to map the high-dimensional embedding vector into a\nlower-dimensional representation (via PCA, t-SNE, or UMAP) or apply clustering\ntechniques such as k-means and then visualize the results. Airbnb did this with\ntheir listing embeddings\n[https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e] \nto confirm that listings from similar locations are clustered together.\n\n\n--------------------------------------------------------------------------------\n\nUser Interface\nFor a Machine Learning Engineer or Data Scientist, the probably most overlooked\naspect of the equation is the User Interface. The problem is that if your UI\ndoes not contain the needed components to showcase the recommendations or\nshowcases them in the wrong context, the feedback loop is inherently flawed.\n\nLet’s take Linkedin as an example to illustrate this. If I’m browsing through\npeople’s profiles, on the right-hand side of the screen I see recommendations\nfor similar people. When I’m browsing through companies, I see recommendations\nfor similar companies. The recommendations are adapted to my current goals and\ncontext and encourage me to keep browsing the site. If the similar companies \nrecommendations would appear on a person’s profile, I would probably be less\nencouraged to click on their profile as it is not what I am currently looking\nfor.\n\nSimilar User Recommendations on LinkedinSimilar Companies Recommendations\non LinkedinYou can build the best Recommender System in the world, however, if\nyour interface is not designed to serve the user’s needs and wants, no one will\nappreciate the recommendations. In fact, the User Interface challenge is so\ncrucial that Netflix turned all components on their website into dynamic ones\n[https://netflixtechblog.com/learning-a-personalized-homepage-aa8ec670359a] \nwhich are assembled by a Machine Learning algorithm to best reflect the goals of\na user.\n\nSpotify followed that model and adopted a similar layout for their home screen\ndesign\n[https://labs.spotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/]\n, as can be seen below.\n\nPersonalizing Spotify Home with Machine Learning (Source:Spotify\n[https://www.oreilly.com/radar/personalization-of-spotify-home-and-tensorflow/])\nThis is an ongoing area where there is still a lot of experimentation. As an\nexample, YouTube recently changed their homepage interface to enable users to\nnarrow down the recommendations for different topics:\n\nNew YouTube Home Page\n--------------------------------------------------------------------------------\n\nCold-start Problem\nThe cold-start problem\n[https://en.wikipedia.org/wiki/Cold_start_%28computing%29] is often seen in\nRecommender Systems because methods such as collaborative filtering rely heavily\non past user-item interactions. Companies are confronted with the cold-start\nproblem in two ways: user and item cold-start. Depending on the type of\nplatform, either one of them is more prevalent.\n\nUser cold-start\nImagine a new member signs up for Netflix. At this point, the company doesn’t\nknow anything about the new members’ preferences. How does the company keep her\nengaged by providing great recommendations?\n\nIn Netflix’s case, new members get a one-month free trial, during which\ncancellation rates are the highest while they decrease quickly after that. This\nis why any improvements to the cold-start problem present an immense business\nopportunity for Netflix, in order to increase engagement and retention in those\nfirst 30 days. Today, their members are given a survey during the sign-up\nprocess, during which they are asked to select videos from an algorithmically\npopulated set that is then used as an input into all of their algorithms.\n\nItem cold-start\nCompanies face a similar challenge when new items or content are added to the\ncatalog. Platforms like Netflix or Prime Video hold an existing catalog of media\nitems that changes less frequently (it takes time to create movies or series!),\ntherefore they struggle less with this. On the contrary, on Airbnb or Zillow,\nnew listings are created every day and at that point, they do not have an\nembedding as they were not present during the training process. Airbnb solves\nthis the following way:\n\n> To create embeddings for a new listing we find 3 geographically closest listings\nthat do have embeddings, and are of same listing type and price range as the new\nlisting, and calculate their mean vector.\nFor Zillow, this is especially critical as some of the new home listings might\nonly be on the site for a couple of days. They creatively solved this problem\n[https://www.zillow.com/tech/embedding-similar-home-recommendation/] by creating\na neural network-based mapping function from the content space to the embedding\nspace, which is guided by the engagement data from users during the learning\nphase. This allows them to map a new home listing to the learned embedding space\njust by using its features.\n\n\n--------------------------------------------------------------------------------\n\nExploration vs. Exploitation\nThe concept of exploration/exploitation can be seen as the balancing of new\ncontent with well-established content. I was going to illustrate this concept\nmyself, while I found this great excerpt that hits it right out of the ballpark:\n\n> “Imagine you’ve just entered an ice cream shop. You now face a crucial\ndecision — out of about 30 flavors you need to choose only one!\nYou can go with two strategies: either go with that favorite flavor of yours\nthat you already know is the best; or explore new flavors you never tried\nbefore, and maybe find a new best flavor.\nThese two strategies — exploitation and exploration — can also be used when\nrecommending content. We can either exploit items that have high click-through\nrate with high certainty — maybe because these items have been shown thousands\nof times to similar users, or we can explore new items we haven’t shown to many\nusers in the past. Incorporating exploration into your recommendation strategy\nis crucial — without it, new items don’t stand a chance against older, more\nfamiliar ones.”\n(Source: Recommender Systems: Exploring the Unknown Using Uncertainty\n[https://anotherdatum.com/exploration-exploitation.html])\n\nThis tradeoff is a typical reinforcement learning problem and a commonly used\napproach is the multi-armed bandit algorithm. This is used by Spotify for the \npersonalization of each users’ home page\n[http://sigir.org/afirm2019/slides/16.%20Friday%20-%20Music%20Recommendation%20at%20Spotify%20-%20Ben%20Carterette.pdf] \nas well as Uber Eats for personalized recommendations optimized for their\nthree-sided marketplace\n[https://eng.uber.com/uber-eats-recommending-marketplace/]. Two scientists at\nNetflix gave a great talk about how they are using the MAB framework for movie\nrecommendations [https://www.youtube.com/watch?v=kY-BCNHd_dM].\n\nThough I should mention that this is, by no means, the final solution to this\nproblem, it seems to work for Netflix, Spotify, and Uber Eats, right?\n\nYes. But!\n\nNetflix has roughly 160 million users and about 6.000 movies/shows. Spotify has\nabout 230 million users and 50 million songs + 500.000 podcasts.\n\nTwitter’s 330 million active users generate more than 500 million tweets per day\n(350.000 tweets per minute, 6.000 tweets per second). And then there’s YouTube,\nwith its 300 hours of videos uploaded every minute!\n\nThe exploration space in the two latter cases is a little bit bigger than in the\ncase of Netflix or Uber Eats, which makes the problem a lot more challenging.\n\n\n--------------------------------------------------------------------------------\n\nThe Future of Recommender Systems\nThis is the end of my little survey over Recommender Systems. As we have\nobserved, Recommender Systems already guide so many aspects of our life. All the\nalgorithms we covered over the course of these two articles are competing for\nour attention every day. And after all, they are all maximizing the time spent\non their platform. As I illustrated in the section on Evaluation methods, most\nof the algorithms are optimizing for something like Click-through rate,\nengagement, or in YouTube’s case: watch time.\n\nWhat does that mean for us as a consumer?\n\nWhat it means is, that we are not in control of our desires anymore. While this\nmight sound poetic, think about it. Let’s look at YouTube; we all have goals\nwhen coming to the site. We might want to listen to music, watch something\nfunny, or learn something new. But all the content that is recommended to us\n(either through the Home Page recommendations, Search Ranking, or Watch Next) is\noptimized to keep us on the site for longer.\n\nLex Fridman and François Chollet had a great conversation about this\n[https://www.youtube.com/watch?v=Bo8MY4JpiXE] on the Artificial Intelligence\nPodcast. Instead of choosing the metric to optimize for, what if companies would\nput the user in charge of choosing their own objective function? What if they\nwould take the personal goals of the user’s profile into account and ask the\nuser, what do you want to achieve? Right now, this technology is almost like our\nboss and we’re not in control of it. Wouldn’t it be incredible to leverage the\npower of Recommender Systems to be more like a mentor, a coach, or an assistant?\n\nImagine, as a consumer, you could ask YouTube to optimize the content to\nmaximize learning outcomes. The technology is certainly already there. The\nchallenge would really lie in aligning this with the existing business models\nand designing the right interface to empower the user to make that choice, and\nalso to change as their goals evolve. With its new interface, YouTube is perhaps\nalready taking baby-steps in that direction by putting the user in charge to\nselect categories that she wants to see recommendations for. But this is just\nthe beginning.\n\nCould this be the way forward or is this just a consumer’s dream?\n\n\n--------------------------------------------------------------------------------\n\nResources\n\nFrançois Chollet: Keras, Deep Learning, and the Progress of AI | Artificial\nIntelligence Podcast [https://www.youtube.com/watch?v=Bo8MY4JpiXE]\n\nAirbnb — Listing Embeddings in Search Ranking\n[https://medium.com/airbnb-engineering/listing-embeddings-for-similar-listing-recommendations-and-real-time-personalization-in-search-601172f7603e]\n\nAirbnb — Machine Learning-Powered Search Ranking of Airbnb Experiences\n[https://medium.com/airbnb-engineering/machine-learning-powered-search-ranking-of-airbnb-experiences-110b4b1a0789]\n\nAmazon — Amazon.com Recommendations Item-to-Item Collaborative Filtering\n[https://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf]\n\nAmazon — The history of Amazon’s recommendation algorithm\n[https://www.amazon.science/the-history-of-amazons-recommendation-algorithm]\n\nInstagram — Powered by AI: Instagram’s Explore recommender system\n[https://ai.facebook.com/blog/powered-by-ai-instagrams-explore-recommender-system/]\n\nLinkedIn — The Browsemaps: Collaborative Filtering at LinkedIn\n[https://ls13-www.cs.tu-dortmund.de/homepage/rsweb2014/papers/rsweb2014_submission_3.pdf]\n\nNetflix — Netflix Recommendations: Beyond the 5 stars (Part 1)\n[https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429]\n\nNetflix — Netflix Recommendations: Beyond the 5 stars (Part 2)\n[https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-2-d9b96aa399f5]\n\nNetflix — The Netflix Recommender System: Algorithms, Business Value, and\nInnovation [https://dl.acm.org/doi/pdf/10.1145/2843948]\n\nNetflix — Learning a Personalized Homepage\n[https://netflixtechblog.com/learning-a-personalized-homepage-aa8ec670359a]\n\nPandora — Pandora’s Music Recommender\n[https://pdfs.semanticscholar.org/f635/6c70452b3f56dc1ae07b4649a80239afb1b6.pdf]\n\nSpotify — Discover Weekly: How Does Spotify Know You So Well?\n[https://medium.com/s/story/spotifys-discover-weekly-how-machine-learning-finds-your-new-music-19a41ab76efe]\n\nSpotify — For Your Ears Only: Personalizing Spotify Home with Machine Learning\n[https://labs.spotify.com/2020/01/16/for-your-ears-only-personalizing-spotify-home-with-machine-learning/]\n\nSpotify — From Idea to Execution: Spotify’s Discover Weekly\n[https://www.slideshare.net/MrChrisJohnson/from-idea-to-execution-spotifys-discover-weekly/31-1_0_0_0_1]\n\nTwitter — Embeddings@Twitter\n[https://blog.twitter.com/engineering/en_us/topics/insights/2018/embeddingsattwitter.html]\n\nUber Eats — Food Discovery with Uber Eats: Recommending for the Marketplace\n[https://eng.uber.com/uber-eats-recommending-marketplace/]\n\nUber Eats — Food Discovery with Uber Eats: Using Graph Learning to Power\nRecommendations [https://eng.uber.com/uber-eats-graph-learning/]\n\nYouTube — The YouTube Video Recommendation System\n[https://www.inf.unibz.it/~ricci/ISR/papers/p293-davidson.pdf]\n\nYouTube — Collaborative Deep Learning for Recommender Systems\n[https://arxiv.org/pdf/1409.2944.pdf]\n\nYouTube — Deep Neural Networks for YouTube Recommendations\n[https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf]\n\nZillow — Home Embeddings for Similar Home Recommendations\n[https://www.zillow.com/tech/embedding-similar-home-recommendation/]\n\nAndrew Ng’s Machine Learning Course (Recommender Systems)\n[https://www.youtube.com/watch?v=giIXNoiqO_U&list=PL-6SiIrhTAi6x4Oq28s7yy94ubLzVXabj]\n\nGoogle’s Machine Learning Crash Course — Embeddings\n[https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture]\n\n\n--------------------------------------------------------------------------------","feature_image":null,"featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2020-10-04 20:47:22","created_by":"1","updated_at":"2021-04-25 14:07:49","updated_by":"1","published_at":"2020-10-04 20:50:12","published_by":"1","custom_excerpt":"Why Recommender Systems are the most valuable application of Machine Learning and how Machine Learning-driven Recommenders already drive almost every aspect of our lives.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"6085751174348916f1b089a0","uuid":"22ba24c0-8171-4cdd-a7f4-67160e2cf20a","title":"Embed Twitter Threads in Roam Research","slug":"embed-tweet-threads-in-roam-research","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/10/roam-twitter.gif\",\"width\":800,\"height\":374}]],\"markups\":[[\"a\",[\"href\",\"https://chrome.google.com/webstore/detail/scify/kedfefpmgjcfidhnabfodadhnlabpili\"]]],\"sections\":[[1,\"h3\",[]],[1,\"p\",[[0,[0],1,\"Get it here\"]]],[1,\"p\",[[0,[],0,\"How to use:\"],[1,[],0,0],[0,[],0,\"- Paste a tweet url into Roam. \"],[1,[],0,1],[0,[],0,\"- The thread is then copied to your clipboard. \"],[1,[],0,2],[0,[],0,\"- Paste it into Roam via CMD+V (Mac) CTRL-V (Windows).\"]]],[10,0]],\"ghostVersion\":\"3.0\"}","html":"<h3></h3><p><a href=\"https://chrome.google.com/webstore/detail/scify/kedfefpmgjcfidhnabfodadhnlabpili\">Get it here</a></p><p>How to use:<br>- Paste a tweet url into Roam. <br>- The thread is then copied to your clipboard. <br>- Paste it into Roam via CMD+V (Mac) CTRL-V (Windows).</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/10/roam-twitter.gif\" class=\"kg-image\" alt loading=\"lazy\" width=\"800\" height=\"374\"></figure>","comment_id":"5f93253e206b80565c1df14d","plaintext":"\nGet it here\n[https://chrome.google.com/webstore/detail/scify/kedfefpmgjcfidhnabfodadhnlabpili]\n\nHow to use:\n- Paste a tweet url into Roam. \n- The thread is then copied to your clipboard. \n- Paste it into Roam via CMD+V (Mac) CTRL-V (Windows).","feature_image":null,"featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2020-10-23 18:47:26","created_by":"1","updated_at":"2021-04-25 14:08:04","updated_by":"1","published_at":"2020-10-23 18:50:23","published_by":"1","custom_excerpt":" Paste a tweet url into Roam. The thread is then copied to your clipboard. Paste it into Roam via CMD+V (Mac) CTRL-V (Windows).","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"6085751174348916f1b089a1","uuid":"d88da608-2ba0-4354-bddc-710b06eec405","title":"Why we gain compounding benefits from incremental knowledge tools","slug":"the-marginal-benefits-we-gain-from-knowledge-tools-are","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"embed\",{\"url\":\"https://twitter.com/rmeinl/status/1320877510586966017\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\" data-width=\\\"550\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">When you zoom out and look at the bigger picture, a tool like <a href=\\\"https://twitter.com/RoamResearch?ref_src=twsrc%5Etfw\\\">@RoamResearch</a> perhaps makes you 5% more productive in the short term. I realized today why this still matters a lot:</p>&mdash; Rico Meinl (@rmeinl) <a href=\\\"https://twitter.com/rmeinl/status/1320877510586966017?ref_src=twsrc%5Etfw\\\">October 26, 2020</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\",\"metadata\":{\"url\":\"https://twitter.com/rmeinl/status/1320877510586966017\",\"author_name\":\"Rico Meinl\",\"author_url\":\"https://twitter.com/rmeinl\",\"width\":550,\"height\":null,\"cache_age\":\"3153600000\",\"provider_name\":\"Twitter\",\"provider_url\":\"http://www.twitter.com/\",\"version\":\"1.0\"},\"caption\":\"Discussed on Twitter.\"}]],\"markups\":[[\"a\",[\"href\",\"https://notes.andymatuschak.org/Knowledge_work_should_accrete\"]],[\"a\",[\"href\",\"https://notes.andymatuschak.org/z7DvEiUpF6dYkFGbpZZTBKQVM9jjNnx8D8Xzu\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Knowledge and productivity are like compound interest. As knowledge workers, we live on the margins and every seemingly little improvement can add up to that compound in the long run.\"]]],[1,\"p\",[[0,[0],1,\"The more you know, the more you learn\"],[0,[],0,\"; the more you learn, the more you can do; the more you can do, the more the opportunity. \"]]],[1,\"p\",[[0,[],0,\"With the old file cabinet like note taking systems there was literally no gain when going from 10 notes to 10.000 notes. It was probably more of a downward linear trend because of the growing lack of structure. With graph-based tools like Roam Research, your knowledge management system can improve almost exponentially the more you add to it (if done right). The increasing number of notes allows for ever more unexpected connections.\"]]],[1,\"p\",[[0,[],0,\"Roam Research is also an IDE for knowledge work and enables us to treat notes as composable blocks of knowledge. \"],[0,[1],1,\"Text is not as composable as code or graphic elements.\"]]],[1,\"p\",[[0,[],0,\"But as the Zettelkasten shows, the notes that contribute to an idea and eventually to a piece of content are very much composable. Knowledge systems that compose and have atomic statements make it much easier to write and publish.\"]]],[1,\"p\",[[0,[],0,\"The interface of Roam is mouldable and we can build our own meta-tools on top of it. The question for all the builders will be if we can make the new meta-tools for knowledge as valuable as the meta-tools for programming.\"]]],[10,0]],\"ghostVersion\":\"3.0\"}","html":"<p>Knowledge and productivity are like compound interest. As knowledge workers, we live on the margins and every seemingly little improvement can add up to that compound in the long run.</p><p><a href=\"https://notes.andymatuschak.org/Knowledge_work_should_accrete\">The more you know, the more you learn</a>; the more you learn, the more you can do; the more you can do, the more the opportunity. </p><p>With the old file cabinet like note taking systems there was literally no gain when going from 10 notes to 10.000 notes. It was probably more of a downward linear trend because of the growing lack of structure. With graph-based tools like Roam Research, your knowledge management system can improve almost exponentially the more you add to it (if done right). The increasing number of notes allows for ever more unexpected connections.</p><p>Roam Research is also an IDE for knowledge work and enables us to treat notes as composable blocks of knowledge. <a href=\"https://notes.andymatuschak.org/z7DvEiUpF6dYkFGbpZZTBKQVM9jjNnx8D8Xzu\">Text is not as composable as code or graphic elements.</a></p><p>But as the Zettelkasten shows, the notes that contribute to an idea and eventually to a piece of content are very much composable. Knowledge systems that compose and have atomic statements make it much easier to write and publish.</p><p>The interface of Roam is mouldable and we can build our own meta-tools on top of it. The question for all the builders will be if we can make the new meta-tools for knowledge as valuable as the meta-tools for programming.</p><figure class=\"kg-card kg-embed-card kg-card-hascaption\"><blockquote class=\"twitter-tweet\" data-width=\"550\"><p lang=\"en\" dir=\"ltr\">When you zoom out and look at the bigger picture, a tool like <a href=\"https://twitter.com/RoamResearch?ref_src=twsrc%5Etfw\">@RoamResearch</a> perhaps makes you 5% more productive in the short term. I realized today why this still matters a lot:</p>&mdash; Rico Meinl (@rmeinl) <a href=\"https://twitter.com/rmeinl/status/1320877510586966017?ref_src=twsrc%5Etfw\">October 26, 2020</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n<figcaption>Discussed on Twitter.</figcaption></figure>","comment_id":"5f9805ab206b80565c1df172","plaintext":"Knowledge and productivity are like compound interest. As knowledge workers, we\nlive on the margins and every seemingly little improvement can add up to that\ncompound in the long run.\n\nThe more you know, the more you learn\n[https://notes.andymatuschak.org/Knowledge_work_should_accrete]; the more you\nlearn, the more you can do; the more you can do, the more the opportunity. \n\nWith the old file cabinet like note taking systems there was literally no gain\nwhen going from 10 notes to 10.000 notes. It was probably more of a downward\nlinear trend because of the growing lack of structure. With graph-based tools\nlike Roam Research, your knowledge management system can improve almost\nexponentially the more you add to it (if done right). The increasing number of\nnotes allows for ever more unexpected connections.\n\nRoam Research is also an IDE for knowledge work and enables us to treat notes as\ncomposable blocks of knowledge. Text is not as composable as code or graphic\nelements.\n[https://notes.andymatuschak.org/z7DvEiUpF6dYkFGbpZZTBKQVM9jjNnx8D8Xzu]\n\nBut as the Zettelkasten shows, the notes that contribute to an idea and\neventually to a piece of content are very much composable. Knowledge systems\nthat compose and have atomic statements make it much easier to write and\npublish.\n\nThe interface of Roam is mouldable and we can build our own meta-tools on top of\nit. The question for all the builders will be if we can make the new meta-tools\nfor knowledge as valuable as the meta-tools for programming.\n\n> When you zoom out and look at the bigger picture, a tool like @RoamResearch\n[https://twitter.com/RoamResearch?ref_src=twsrc%5Etfw] perhaps makes you 5% more\nproductive in the short term. I realized today why this still matters a lot:\n\n— Rico Meinl (@rmeinl) October 26, 2020\n[https://twitter.com/rmeinl/status/1320877510586966017?ref_src=twsrc%5Etfw]\nDiscussed on Twitter.","feature_image":null,"featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2020-10-27 11:34:03","created_by":"1","updated_at":"2021-04-25 14:08:11","updated_by":"1","published_at":"2020-10-27 11:43:49","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"6085751174348916f1b089a2","uuid":"a76b4696-f65d-42a9-99ea-592afb59f9aa","title":"The best way to encompass the future is by building a strong set of beliefs.","slug":"the-best-way-to-encompass-the-future-is-by-building-a-strong-set-of-beliefs","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"embed\",{\"url\":\"https://twitter.com/rmeinl/status/1321574734161694720\",\"html\":\"<blockquote class=\\\"twitter-tweet\\\" data-width=\\\"550\\\"><p lang=\\\"en\\\" dir=\\\"ltr\\\">The best way to encompass the future is by building a strong set of beliefs.</p>&mdash; Rico Meinl (@rmeinl) <a href=\\\"https://twitter.com/rmeinl/status/1321574734161694720?ref_src=twsrc%5Etfw\\\">October 28, 2020</a></blockquote>\\n<script async src=\\\"https://platform.twitter.com/widgets.js\\\" charset=\\\"utf-8\\\"></script>\\n\",\"type\":\"rich\",\"metadata\":{\"url\":\"https://twitter.com/rmeinl/status/1321574734161694720\",\"author_name\":\"Rico Meinl\",\"author_url\":\"https://twitter.com/rmeinl\",\"width\":550,\"height\":null,\"cache_age\":\"3153600000\",\"provider_name\":\"Twitter\",\"provider_url\":\"http://www.twitter.com/\",\"version\":\"1.0\"},\"caption\":\"Discussed on Twitter.\"}]],\"markups\":[[\"a\",[\"href\",\"https://www.saffo.com/02008/07/26/strong-opinions-weakly-held/\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Using claims as a first-class citizen in your thinking helps you move towards strong beliefs.\"]]],[1,\"p\",[[0,[],0,\"If you don't explicitly state your claims you're never going to move in any direction. Everything will seem kind of relevant and worth pursuing.\"]]],[1,\"p\",[[0,[],0,\"Writing down claims can help manifest them. It helps to understand their implications, as well as supporting and opposing claims.\"]]],[1,\"p\",[[0,[],0,\"Claims eventually turn into beliefs and beliefs give perspective. They act like gravity. Strong beliefs are something that new information can be attached to.\"]]],[1,\"p\",[[0,[],0,\"Related:\"]]],[1,\"blockquote\",[[0,[0],1,\"The best way to get to a good forecast is by making predictions with limited information and trying to find opposing evidence; then using the accumulated insights to improve your predictions. \"]]],[10,0],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<p>Using claims as a first-class citizen in your thinking helps you move towards strong beliefs.</p><p>If you don't explicitly state your claims you're never going to move in any direction. Everything will seem kind of relevant and worth pursuing.</p><p>Writing down claims can help manifest them. It helps to understand their implications, as well as supporting and opposing claims.</p><p>Claims eventually turn into beliefs and beliefs give perspective. They act like gravity. Strong beliefs are something that new information can be attached to.</p><p>Related:</p><blockquote><a href=\"https://www.saffo.com/02008/07/26/strong-opinions-weakly-held/\">The best way to get to a good forecast is by making predictions with limited information and trying to find opposing evidence; then using the accumulated insights to improve your predictions. </a></blockquote><figure class=\"kg-card kg-embed-card kg-card-hascaption\"><blockquote class=\"twitter-tweet\" data-width=\"550\"><p lang=\"en\" dir=\"ltr\">The best way to encompass the future is by building a strong set of beliefs.</p>&mdash; Rico Meinl (@rmeinl) <a href=\"https://twitter.com/rmeinl/status/1321574734161694720?ref_src=twsrc%5Etfw\">October 28, 2020</a></blockquote>\n<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n<figcaption>Discussed on Twitter.</figcaption></figure>","comment_id":"5f99eca9206b80565c1df1b4","plaintext":"Using claims as a first-class citizen in your thinking helps you move towards\nstrong beliefs.\n\nIf you don't explicitly state your claims you're never going to move in any\ndirection. Everything will seem kind of relevant and worth pursuing.\n\nWriting down claims can help manifest them. It helps to understand their\nimplications, as well as supporting and opposing claims.\n\nClaims eventually turn into beliefs and beliefs give perspective. They act like\ngravity. Strong beliefs are something that new information can be attached to.\n\nRelated:\n\n> The best way to get to a good forecast is by making predictions with limited\ninformation and trying to find opposing evidence; then using the accumulated\ninsights to improve your predictions.\n[https://www.saffo.com/02008/07/26/strong-opinions-weakly-held/]\n> The best way to encompass the future is by building a strong set of beliefs.\n\n— Rico Meinl (@rmeinl) October 28, 2020\n[https://twitter.com/rmeinl/status/1321574734161694720?ref_src=twsrc%5Etfw]\nDiscussed on Twitter.","feature_image":null,"featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2020-10-28 22:11:53","created_by":"1","updated_at":"2021-04-25 14:08:19","updated_by":"1","published_at":"2020-10-28 22:13:50","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"6085751174348916f1b089a3","uuid":"679fcef5-df64-459a-bda1-8b8a110a2413","title":"Sequential and simultaneous modes of awareness","slug":"sequential-and-simultaneous-modes-of-awareness","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/11/Swimmer-and-Lifeguard-2.jpg\",\"width\":960,\"height\":720,\"cardWidth\":\"\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2020/11/rQkQZ6pDZbEHz23rxckWPm.png\",\"width\":900,\"height\":1235}],[\"hr\",{}]],\"markups\":[[\"em\"]],\"sections\":[[1,\"p\",[[0,[],0,\"The most interesting part in Ted Chiang's \\\"Story of your life\\\" is the parallel of the causal and teleological explanation with a sequential and simultaneous mode of awareness.\"]]],[1,\"p\",[[0,[],0,\"Fermat's principle of least time can be interpreted in terms of cause and effect: a difference in the index of refraction caused the light ray to change direction when it hit the surface of the water. This is most intuitive to us humans. \"]]],[10,0],[1,\"p\",[[0,[],0,\"It can also be interpreted teleologically: the ray of light has to know where its destination is in order to compute the path of least time. This is more intuitive to the heptapods.\"]]],[1,\"p\",[[0,[],0,\"The parallel to the causal explanation is a sequential mode of awareness: experiencing events in order, and perceiving their relationship as cause and effect. This is how humans experience things. We don't know the future and are therefore able to exercise free will.\"]]],[1,\"p\",[[0,[],0,\"The parallel to the teleological explanation is a simultaneous mode of awareness: experiencing events all at once, and perceiving a purpose underlying them all. This is how heptapods experience. They already know the future, so freedom is meaningless and every act is performative*.\"]]],[1,\"p\",[[0,[],0,\"If you have free will, it's impossible to know about the future because you could change it. On the other side, if you know the future you cannot act freely anymore. (as in the example of the book of ages).\"]]],[1,\"p\",[[0,[],0,\"Sequential and simultaneous modes of awareness are like the optical illusion of the old and young lady. Both are valid but you can't see them at the same time.\"]]],[10,1],[10,2],[1,\"p\",[[0,[],0,\"*Performative language: Saying equals doing.\"],[1,[],0,0],[0,[],0,\"\\t\"],[0,[0],1,\"Example\"],[0,[],0,\": At a wedding ceremony everybody knows that at the end the pastor will pronounce the couple husband and wife but it doesn't count until he actually says it.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>The most interesting part in Ted Chiang's \"Story of your life\" is the parallel of the causal and teleological explanation with a sequential and simultaneous mode of awareness.</p><p>Fermat's principle of least time can be interpreted in terms of cause and effect: a difference in the index of refraction caused the light ray to change direction when it hit the surface of the water. This is most intuitive to us humans. </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/11/Swimmer-and-Lifeguard-2.jpg\" class=\"kg-image\" alt loading=\"lazy\" width=\"960\" height=\"720\" srcset=\"__GHOST_URL__/content/images/size/w600/2020/11/Swimmer-and-Lifeguard-2.jpg 600w, __GHOST_URL__/content/images/2020/11/Swimmer-and-Lifeguard-2.jpg 960w\" sizes=\"(min-width: 720px) 720px\"></figure><p>It can also be interpreted teleologically: the ray of light has to know where its destination is in order to compute the path of least time. This is more intuitive to the heptapods.</p><p>The parallel to the causal explanation is a sequential mode of awareness: experiencing events in order, and perceiving their relationship as cause and effect. This is how humans experience things. We don't know the future and are therefore able to exercise free will.</p><p>The parallel to the teleological explanation is a simultaneous mode of awareness: experiencing events all at once, and perceiving a purpose underlying them all. This is how heptapods experience. They already know the future, so freedom is meaningless and every act is performative*.</p><p>If you have free will, it's impossible to know about the future because you could change it. On the other side, if you know the future you cannot act freely anymore. (as in the example of the book of ages).</p><p>Sequential and simultaneous modes of awareness are like the optical illusion of the old and young lady. Both are valid but you can't see them at the same time.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2020/11/rQkQZ6pDZbEHz23rxckWPm.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"900\" height=\"1235\" srcset=\"__GHOST_URL__/content/images/size/w600/2020/11/rQkQZ6pDZbEHz23rxckWPm.png 600w, __GHOST_URL__/content/images/2020/11/rQkQZ6pDZbEHz23rxckWPm.png 900w\" sizes=\"(min-width: 720px) 720px\"></figure><hr><p>*Performative language: Saying equals doing.<br>\t<em>Example</em>: At a wedding ceremony everybody knows that at the end the pastor will pronounce the couple husband and wife but it doesn't count until he actually says it.</p>","comment_id":"5fa82585206b80565c1df1ca","plaintext":"The most interesting part in Ted Chiang's \"Story of your life\" is the parallel\nof the causal and teleological explanation with a sequential and simultaneous\nmode of awareness.\n\nFermat's principle of least time can be interpreted in terms of cause and\neffect: a difference in the index of refraction caused the light ray to change\ndirection when it hit the surface of the water. This is most intuitive to us\nhumans. \n\nIt can also be interpreted teleologically: the ray of light has to know where\nits destination is in order to compute the path of least time. This is more\nintuitive to the heptapods.\n\nThe parallel to the causal explanation is a sequential mode of awareness:\nexperiencing events in order, and perceiving their relationship as cause and\neffect. This is how humans experience things. We don't know the future and are\ntherefore able to exercise free will.\n\nThe parallel to the teleological explanation is a simultaneous mode of\nawareness: experiencing events all at once, and perceiving a purpose underlying\nthem all. This is how heptapods experience. They already know the future, so\nfreedom is meaningless and every act is performative*.\n\nIf you have free will, it's impossible to know about the future because you\ncould change it. On the other side, if you know the future you cannot act freely\nanymore. (as in the example of the book of ages).\n\nSequential and simultaneous modes of awareness are like the optical illusion of\nthe old and young lady. Both are valid but you can't see them at the same time.\n\n\n--------------------------------------------------------------------------------\n\n*Performative language: Saying equals doing.\nExample: At a wedding ceremony everybody knows that at the end the pastor will\npronounce the couple husband and wife but it doesn't count until he actually\nsays it.","feature_image":null,"featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2020-11-08 17:06:13","created_by":"1","updated_at":"2021-04-25 14:08:52","updated_by":"1","published_at":"2020-11-30 17:24:24","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"6085751174348916f1b089a7","uuid":"39090668-099b-48ce-8d31-f81cca1d4aca","title":"The 80/20 Computer Science Degree","slug":"nand2tetris","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}]],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/03/nand2tetris-1.png\",\"width\":2000,\"height\":1216}],[\"html\",{\"html\":\"<iframe src=\\\"https://docs.google.com/forms/d/e/1FAIpQLSfZ4OSXgNF7mvOJt4q65xd-g2SeRNIgPqFSpmHYOLBJVpCSSg/viewform?embedded=true\\\" width=\\\"640\\\" height=\\\"1451\\\" frameborder=\\\"0\\\" marginheight=\\\"0\\\" marginwidth=\\\"0\\\">Loading…</iframe>\"}]],\"markups\":[[\"a\",[\"href\",\"http://1729.com/\",\"rel\",\"noopener noreferrer\"]],[\"a\",[\"href\",\"https://1729.com/decentralized-task-creation\",\"rel\",\"noopener noreferrer\"]],[\"a\",[\"href\",\"https://www.playpiper.com/\"]],[\"a\",[\"href\",\"https://www.nand2tetris.org/\"]],[\"a\",[\"href\",\"http://www.cs.huji.ac.il/~noam/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"http://www.shimonschocken.com/\",\"rel\",\"noopener\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/NAND_gate#:~:text=In%20digital%20electronics%2C%20a%20NAND,HIGH%20(1)%20output%20results.\"]],[\"a\",[\"href\",\"https://drive.google.com/file/d/1MY1buFHo_Wx5DPrKhCNSA2cm5ltwFJzM/view\"]],[\"a\",[\"href\",\"https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_2e6113c60ec34ed0bc2035c9d1313066.pdf\"]],[\"a\",[\"href\",\"https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_e458602dcb0c4af9aaeb7fdaa34bb2b4.pdf\"]],[\"a\",[\"href\",\"https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_12f488fe481344328506857e6a799f79.pdf\"]],[\"a\",[\"href\",\"https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_96cbb9c6b8b84760a04c369453b62908.pdf\"]],[\"a\",[\"href\",\"https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_65a2d8eef0ed4e0ea2471030206269b5.pdf\"]],[\"a\",[\"href\",\"https://drive.google.com/file/d/19fe1PeGnggDHymu4LlVY08KmDdhMVRpm/view\"]],[\"a\",[\"href\",\"https://drive.google.com/file/d/1lBsaO5XKLkUgrGY6g6vLMsiZo6rWxlYJ/view\"]],[\"a\",[\"href\",\"https://drive.google.com/file/d/1rbHGZV8AK4UalmdJyivgt0fpPiD1Q6Vk/view\"]],[\"a\",[\"href\",\"https://drive.google.com/file/d/1ujgcS7GoI-zu56FxhfkTAvEgZ6JT7Dxl/view\"]],[\"a\",[\"href\",\"https://drive.google.com/file/d/1DfGKr0fuJcCvlIPABNSg7fsLfFFqRLex/view\"]],[\"a\",[\"href\",\"https://drive.google.com/file/d/137PiYjt4CAZ3ROWiD0DJ8XMUbMM0_VHR/view\"]],[\"a\",[\"href\",\"https://www.coursera.org/learn/build-a-computer\"]],[\"a\",[\"href\",\"https://www.coursera.org/learn/nand2tetris2\"]],[\"a\",[\"href\",\"https://www.amazon.com/Elements-Computing-Systems-Building-Principles/dp/0262640686/ref=ed_oe_p\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=wTl5wRDT0CU\"]],[\"a\",[\"href\",\"https://www.nand2tetris.org/copy-of-talks\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"DRAFT/DISCLAIMER — This post is a submission to a competition on \"],[0,[0],1,\"1729.com\"],[0,[],0,\". No prizes will be awarded for any submissions at this time. Learn more at \"],[0,[1],1,\"1729.com/decentralized-task-creation\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"Nonetheless, I highly recommend everyone who is interested in CS to take this course.\"]]],[10,0],[1,\"p\",[[0,[],0,\"Listening to podcasts with people in tech, you'll often hear that they got interested in the field because they built their own computers or coded their own games. Elon, for example, sold his first computer game at the age of 12 and built custom computers for others in university. \"]]],[1,\"p\",[[0,[],0,\"Now, that most people have laptops it becomes harder to just open them up, check what's inside and put it back together. Of course you could buy go and buy all the parts separately or get \"],[0,[2],1,\"a DIY kit\"],[0,[],0,\". Though this might not be logistically feasible for everyone which is a shame because this kind of tinkering is a great learning vehicle for anything related to Computer Science. \"]]],[1,\"p\",[[0,[],0,\"What if you could virtualize the whole experience while being guided by some world-class CS professors? Enter \"],[0,[3],1,\"Nand to Tetris\"],[0,[],0,\".\"]]],[1,\"h2\",[[0,[],0,\"A game changer in CS education\"]]],[1,\"p\",[[0,[],0,\"Nand to Tetris was created by two CS professors, \"],[0,[4],1,\"Noam Nisan\"],[0,[],0,\" and \"],[0,[5],1,\"Shimon Schocken\"],[0,[],0,\". In a nutshell, you'll build your own computer in a bottom-up fashion all the way up from \"],[0,[6],1,\"NAND gates\"],[0,[],0,\". \"],[1,[],0,0],[0,[],0,\"In the process, you'll get a hands-on coverage of most of the important ideas and techniques in applied computer science, focusing on computer architecture, compilation, and software engineering, in one course. Nand to Tetris also provides a hands-on overview of key data structures and algorithms, as they unfold in the context of 12 captivating hardware and software development projects.\"]]],[1,\"blockquote\",[[0,[],0,\"Nand to Tetris courses are now taught at 200+ universities and high schools around the world. The students who take them range from high school students to Ph.D. students to Google engineers.\"]]],[1,\"h2\",[[0,[],0,\"Task: Earn $500 in BTC\"]]],[1,\"h3\",[[0,[],0,\"Complete all 12 projects and submit a link to the Github project repository\"]]],[3,\"ol\",[[[0,[7],1,\"Boolean Logic\"]],[[0,[8],1,\"Boolean Arithmetic\"]],[[0,[9],1,\"Sequential Logic\"]],[[0,[10],1,\"Machine Language\"]],[[0,[11],1,\"Computer Architecture\"]],[[0,[12],1,\"Assembler\"]],[[0,[13],1,\"Virtual Machine I: Stack Arithmetic\"]],[[0,[14],1,\"Virtual Machine II: Program Control\"]],[[0,[15],1,\"High Level Language\"]],[[0,[16],1,\"Compiler I: Syntax Analysis\"]],[[0,[17],1,\"Compiler II: Code Generation\"]],[[0,[18],1,\"Operating System\"]],[[0,[],0,\"Tetris\"]]]],[1,\"p\",[[0,[],0,\"During these 12 projects you will build your own Assembler, Virtual Machine, Java-like High Level Language, Compiler and Operating System. In the optional 13th project you can tie all these things together to write an implementation of Tetris or any other game of your choice using all the components you previously built.\"]]],[1,\"p\",[[0,[],0,\"There is a guided Coursera course with \"],[0,[19],1,\"two\"],[0,[],0,\" \"],[0,[20],1,\"parts\"],[0,[],0,\" but just using the links above or the \"],[0,[21],1,\"book\"],[0,[],0,\" works perfectly fine. \"],[0,[22],1,\"Check out the introduction video here\"],[0,[],0,\". Some inspirational projects can be found \"],[0,[23],1,\"here\"],[0,[],0,\".\"]]],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<p>DRAFT/DISCLAIMER — This post is a submission to a competition on <a href=\"http://1729.com/\" rel=\"noopener noreferrer\">1729.com</a>. No prizes will be awarded for any submissions at this time. Learn more at <a href=\"https://1729.com/decentralized-task-creation\" rel=\"noopener noreferrer\">1729.com/decentralized-task-creation</a>. </p><p>Nonetheless, I highly recommend everyone who is interested in CS to take this course.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/03/nand2tetris-1.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1216\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/03/nand2tetris-1.png 600w, __GHOST_URL__/content/images/size/w1000/2021/03/nand2tetris-1.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/03/nand2tetris-1.png 1600w, __GHOST_URL__/content/images/2021/03/nand2tetris-1.png 2000w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Listening to podcasts with people in tech, you'll often hear that they got interested in the field because they built their own computers or coded their own games. Elon, for example, sold his first computer game at the age of 12 and built custom computers for others in university. </p><p>Now, that most people have laptops it becomes harder to just open them up, check what's inside and put it back together. Of course you could buy go and buy all the parts separately or get <a href=\"https://www.playpiper.com/\">a DIY kit</a>. Though this might not be logistically feasible for everyone which is a shame because this kind of tinkering is a great learning vehicle for anything related to Computer Science. </p><p>What if you could virtualize the whole experience while being guided by some world-class CS professors? Enter <a href=\"https://www.nand2tetris.org/\">Nand to Tetris</a>.</p><h2 id=\"a-game-changer-in-cs-education\">A game changer in CS education</h2><p>Nand to Tetris was created by two CS professors, <a href=\"http://www.cs.huji.ac.il/~noam/\" rel=\"noopener\">Noam Nisan</a> and <a href=\"http://www.shimonschocken.com/\" rel=\"noopener\">Shimon Schocken</a>. In a nutshell, you'll build your own computer in a bottom-up fashion all the way up from <a href=\"https://en.wikipedia.org/wiki/NAND_gate#:~:text=In%20digital%20electronics%2C%20a%20NAND,HIGH%20(1)%20output%20results.\">NAND gates</a>. <br>In the process, you'll get a hands-on coverage of most of the important ideas and techniques in applied computer science, focusing on computer architecture, compilation, and software engineering, in one course. Nand to Tetris also provides a hands-on overview of key data structures and algorithms, as they unfold in the context of 12 captivating hardware and software development projects.</p><blockquote>Nand to Tetris courses are now taught at 200+ universities and high schools around the world. The students who take them range from high school students to Ph.D. students to Google engineers.</blockquote><h2 id=\"task-earn-500-in-btc\">Task: Earn $500 in BTC</h2><h3 id=\"complete-all-12-projects-and-submit-a-link-to-the-github-project-repository\">Complete all 12 projects and submit a link to the Github project repository</h3><ol><li><a href=\"https://drive.google.com/file/d/1MY1buFHo_Wx5DPrKhCNSA2cm5ltwFJzM/view\">Boolean Logic</a></li><li><a href=\"https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_2e6113c60ec34ed0bc2035c9d1313066.pdf\">Boolean Arithmetic</a></li><li><a href=\"https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_e458602dcb0c4af9aaeb7fdaa34bb2b4.pdf\">Sequential Logic</a></li><li><a href=\"https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_12f488fe481344328506857e6a799f79.pdf\">Machine Language</a></li><li><a href=\"https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_96cbb9c6b8b84760a04c369453b62908.pdf\">Computer Architecture</a></li><li><a href=\"https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_65a2d8eef0ed4e0ea2471030206269b5.pdf\">Assembler</a></li><li><a href=\"https://drive.google.com/file/d/19fe1PeGnggDHymu4LlVY08KmDdhMVRpm/view\">Virtual Machine I: Stack Arithmetic</a></li><li><a href=\"https://drive.google.com/file/d/1lBsaO5XKLkUgrGY6g6vLMsiZo6rWxlYJ/view\">Virtual Machine II: Program Control</a></li><li><a href=\"https://drive.google.com/file/d/1rbHGZV8AK4UalmdJyivgt0fpPiD1Q6Vk/view\">High Level Language</a></li><li><a href=\"https://drive.google.com/file/d/1ujgcS7GoI-zu56FxhfkTAvEgZ6JT7Dxl/view\">Compiler I: Syntax Analysis</a></li><li><a href=\"https://drive.google.com/file/d/1DfGKr0fuJcCvlIPABNSg7fsLfFFqRLex/view\">Compiler II: Code Generation</a></li><li><a href=\"https://drive.google.com/file/d/137PiYjt4CAZ3ROWiD0DJ8XMUbMM0_VHR/view\">Operating System</a></li><li>Tetris</li></ol><p>During these 12 projects you will build your own Assembler, Virtual Machine, Java-like High Level Language, Compiler and Operating System. In the optional 13th project you can tie all these things together to write an implementation of Tetris or any other game of your choice using all the components you previously built.</p><p>There is a guided Coursera course with <a href=\"https://www.coursera.org/learn/build-a-computer\">two</a> <a href=\"https://www.coursera.org/learn/nand2tetris2\">parts</a> but just using the links above or the <a href=\"https://www.amazon.com/Elements-Computing-Systems-Building-Principles/dp/0262640686/ref=ed_oe_p\">book</a> works perfectly fine. <a href=\"https://www.youtube.com/watch?v=wTl5wRDT0CU\">Check out the introduction video here</a>. Some inspirational projects can be found <a href=\"https://www.nand2tetris.org/copy-of-talks\">here</a>.</p><!--kg-card-begin: html--><iframe src=\"https://docs.google.com/forms/d/e/1FAIpQLSfZ4OSXgNF7mvOJt4q65xd-g2SeRNIgPqFSpmHYOLBJVpCSSg/viewform?embedded=true\" width=\"640\" height=\"1451\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">Loading…</iframe><!--kg-card-end: html-->","comment_id":"603bf484064f9e780b0d827c","plaintext":"DRAFT/DISCLAIMER — This post is a submission to a competition on 1729.com\n[http://1729.com/]. No prizes will be awarded for any submissions at this time.\nLearn more at 1729.com/decentralized-task-creation\n[https://1729.com/decentralized-task-creation]. \n\nNonetheless, I highly recommend everyone who is interested in CS to take this\ncourse.\n\nListening to podcasts with people in tech, you'll often hear that they got\ninterested in the field because they built their own computers or coded their\nown games. Elon, for example, sold his first computer game at the age of 12 and\nbuilt custom computers for others in university. \n\nNow, that most people have laptops it becomes harder to just open them up, check\nwhat's inside and put it back together. Of course you could buy go and buy all\nthe parts separately or get a DIY kit [https://www.playpiper.com/]. Though this\nmight not be logistically feasible for everyone which is a shame because this\nkind of tinkering is a great learning vehicle for anything related to Computer\nScience. \n\nWhat if you could virtualize the whole experience while being guided by some\nworld-class CS professors? Enter Nand to Tetris [https://www.nand2tetris.org/].\n\nA game changer in CS education\nNand to Tetris was created by two CS professors, Noam Nisan\n[http://www.cs.huji.ac.il/~noam/] and Shimon Schocken\n[http://www.shimonschocken.com/]. In a nutshell, you'll build your own computer\nin a bottom-up fashion all the way up from NAND gates\n[https://en.wikipedia.org/wiki/NAND_gate#:~:text=In%20digital%20electronics%2C%20a%20NAND,HIGH%20(1)%20output%20results.]\n. \nIn the process, you'll get a hands-on coverage of most of the important ideas\nand techniques in applied computer science, focusing on computer architecture,\ncompilation, and software engineering, in one course. Nand to Tetris also\nprovides a hands-on overview of key data structures and algorithms, as they\nunfold in the context of 12 captivating hardware and software development\nprojects.\n\n> Nand to Tetris courses are now taught at 200+ universities and high schools\naround the world. The students who take them range from high school students to\nPh.D. students to Google engineers.\nTask: Earn $500 in BTC\nComplete all 12 projects and submit a link to the Github project repository\n 1.  Boolean Logic\n     [https://drive.google.com/file/d/1MY1buFHo_Wx5DPrKhCNSA2cm5ltwFJzM/view]\n 2.  Boolean Arithmetic\n     [https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_2e6113c60ec34ed0bc2035c9d1313066.pdf]\n 3.  Sequential Logic\n     [https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_e458602dcb0c4af9aaeb7fdaa34bb2b4.pdf]\n 4.  Machine Language\n     [https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_12f488fe481344328506857e6a799f79.pdf]\n 5.  Computer Architecture\n     [https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_96cbb9c6b8b84760a04c369453b62908.pdf]\n 6.  Assembler\n     [https://b1391bd6-da3d-477d-8c01-38cdf774495a.filesusr.com/ugd/56440f_65a2d8eef0ed4e0ea2471030206269b5.pdf]\n 7.  Virtual Machine I: Stack Arithmetic\n     [https://drive.google.com/file/d/19fe1PeGnggDHymu4LlVY08KmDdhMVRpm/view]\n 8.  Virtual Machine II: Program Control\n     [https://drive.google.com/file/d/1lBsaO5XKLkUgrGY6g6vLMsiZo6rWxlYJ/view]\n 9.  High Level Language\n     [https://drive.google.com/file/d/1rbHGZV8AK4UalmdJyivgt0fpPiD1Q6Vk/view]\n 10. Compiler I: Syntax Analysis\n     [https://drive.google.com/file/d/1ujgcS7GoI-zu56FxhfkTAvEgZ6JT7Dxl/view]\n 11. Compiler II: Code Generation\n     [https://drive.google.com/file/d/1DfGKr0fuJcCvlIPABNSg7fsLfFFqRLex/view]\n 12. Operating System\n     [https://drive.google.com/file/d/137PiYjt4CAZ3ROWiD0DJ8XMUbMM0_VHR/view]\n 13. Tetris\n\nDuring these 12 projects you will build your own Assembler, Virtual Machine,\nJava-like High Level Language, Compiler and Operating System. In the optional\n13th project you can tie all these things together to write an implementation of\nTetris or any other game of your choice using all the components you previously\nbuilt.\n\nThere is a guided Coursera course with two\n[https://www.coursera.org/learn/build-a-computer] parts\n[https://www.coursera.org/learn/nand2tetris2] but just using the links above or\nthe book\n[https://www.amazon.com/Elements-Computing-Systems-Building-Principles/dp/0262640686/ref=ed_oe_p] \nworks perfectly fine. Check out the introduction video here\n[https://www.youtube.com/watch?v=wTl5wRDT0CU]. Some inspirational projects can\nbe found here [https://www.nand2tetris.org/copy-of-talks].\n\nLoading…","feature_image":null,"featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2021-02-28 19:52:36","created_by":"1","updated_at":"2021-04-25 14:07:03","updated_by":"1","published_at":"2021-03-30 22:12:56","published_by":"1","custom_excerpt":"Nand to Tetris was created by two CS professors, Noam Nisan and Shimon Schocken. In a nutshell, you'll build your own computer in a bottom-up fashion all the way up from NAND gates. ","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"6085751174348916f1b089a8","uuid":"b5656406-aae1-4257-b8cf-ee86bd8b9a29","title":"Setting up Virtual Flow on AWS using Parallelcluster and Slurm","slug":"setting-up-virtual-flow-on-aws","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"mkdir parallel_cluster\\ncd parallel_cluster\\npoetry init\\npoetry add awscli aws-parallelcluster\"}],[\"code\",{\"code\":\" $ poetry run pcluster configure                  \\nAllowed values for AWS Region ID:\\n1. ap-northeast-1\\n2. ap-northeast-2\\n3. ap-south-1\\n4. ap-southeast-1\\n5. ap-southeast-2\\n6. ca-central-1\\n7. eu-central-1\\n8. eu-north-1\\n9. eu-west-1\\n10. eu-west-2\\n11. eu-west-3\\n12. sa-east-1\\n13. us-east-1\\n14. us-east-2\\n15. us-west-1\\n16. us-west-2\\nAWS Region ID [us-west-2]: 16\\nAllowed values for EC2 Key Pair Name:\\n1. parallelcluster\\nEC2 Key Pair Name [parallelcluster]: 1\\nAllowed values for Scheduler:\\n1. sge\\n2. torque\\n3. slurm\\n4. awsbatch\\nScheduler [slurm]: 3\\nAllowed values for Operating System:\\n1. alinux\\n2. alinux2\\n3. centos7\\n4. centos8\\n5. ubuntu1604\\n6. ubuntu1804\\nOperating System [alinux2]: 2\\nMinimum cluster size (instances) [0]: 1\\nMaximum cluster size (instances) [10]: \\nHead node instance type [t2.micro]: c4.large\\nCompute instance type [t2.micro]: c4.xlarge\\nAutomate VPC creation? (y/n) [n]: y\"}],[\"code\",{\"code\":\"$ cat ~/.parallelcluster/config \\n[aws]\\naws_region_name = us-west-2\\n\\n[aliases]\\nssh = ssh {CFN_USER}@{MASTER_IP} {ARGS}\\n\\n[global]\\ncluster_template = default\\nupdate_check = true\\nsanity_check = true\\n\\n[vpc default]\\nvpc_id = vpc-*****************\\nmaster_subnet_id = subnet-*****************\\n\\n[cluster default]\\nkey_name = parallelcluster\\nscheduler = slurm\\nmaster_instance_type = c4.large\\nbase_os = alinux2\\nvpc_settings = default\\nqueue_settings = compute\\n\\n[queue compute]\\nenable_efa = false\\nenable_efa_gdr = false\\ncompute_resource_settings = default\\n\\n[compute_resource default]\\ninstance_type = c4.xlarge\\nmin_count = 1\"}],[\"code\",{\"code\":\"$ poetry run pcluster create test-cluster\\nBeginning cluster creation for cluster: test-cluster\\nCreating stack named: parallelcluster-test-cluster\\n...\"}],[\"code\",{\"code\":\"poetry run pcluster ssh test-cluster -i ~/.ssh/<key_name>\"}],[\"code\",{\"code\":\"$ wget https://virtual-flow.org/sites/virtual-flow.org/files/tutorials/VFVS_GK.tar\\n$ tar -xvf VFVS_GK.tar\\n$ cd VFVS_GK/tools\\n\"}],[\"code\",{\"code\":\"# tools/templates/all.ctrl\\n...\\nbatchsystem=SLURM\\n# Possible values: SLURM, TOQRUE, PBS, LSF, SGE\\n# Settable via range control files: No\\n...\\npartition=compute\\n# Partitions are also called queues in some batchsystems\\n# Settable via range control files: Yes\"}],[\"code\",{\"code\":\"$ sinfo\\nPARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST \\ncompute*     up   infinite      5  idle~ compute-dy-c4xlarge-[5-9] \\ncompute*     up   infinite      5  alloc compute-dy-c4xlarge-[1-4],compute-st-c4xlarge-1 \"}],[\"code\",{\"code\":\"srun: error: Unable to create step for job 874794: Memory required by task is not available\"}],[\"code\",{\"code\":\"# Slurm Settings\\n###############################################################################\\n\\n#SBATCH --job-name=h-1.1\\n##SBATCH --mail-user=To be completed if uncommented\\n#SBATCH --mail-type=fail\\n#SBATCH --time=00-12:00:00\\n##SBATCH --mem-per-cpu=1024M\\n#SBATCH --nodes=1\\n#SBATCH --cpus-per-task=1\\n#SBATCH --partition=main\\n#SBATCH --output=../workflow/output-files/jobs/job-1.1_%j.out           # File to which standard out will be written\\n#SBATCH --error=../workflow/output-files/jobs/job-1.1_%j.out            # File to which standard err will be written\\n#SBATCH --signal=10@300\"}],[\"code\",{\"code\":\"./vf_prepare_folders.sh\"}],[\"code\",{\"code\":\"./vf_start_jobline.sh 1 12 templates/template1.slurm.sh submit 1\"}],[\"code\",{\"code\":\"# ../input-files/smina_rigid_receptor1/config.txt\\nreceptor = ../input-files/receptor/<protein>.pdbqt\\ncenter_x = 28.614\\ncenter_y = 15.838\\ncenter_z = -2.045\\nsize_x = 36.0\\nsize_y = 32.0\\nsize_z = 36.0\\nexhaustiveness = 4\\nscoring = vinardo\\ncpu = 1\"}]],\"markups\":[[\"a\",[\"href\",\"https://aws.amazon.com/hpc/parallelcluster/\"]],[\"a\",[\"href\",\"https://virtual-flow.org/\"]],[\"a\",[\"href\",\"https://aws.amazon.com/blogs/opensource/aws-parallelcluster/\"]],[\"a\",[\"href\",\"https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#KeyPairs\"]],[\"a\",[\"href\",\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/introduction\"]],[\"a\",[\"href\",\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/setting-up-the-workflow\"]],[\"a\",[\"href\",\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/starting-the-workflow\"]],[\"a\",[\"href\",\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/monitoring-the-workflow\"]],[\"a\",[\"href\",\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/the-completed-workflow\"]],[\"a\",[\"href\",\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/tutorial-2-vfvs-scratch/setting-up-the-workflow#preparing-the-input-files-folder\"]],[\"a\",[\"href\",\"http://vina.scripps.edu/download.html\"]],[\"a\",[\"href\",\"http://mgltools.scripps.edu/downloads\"]],[\"a\",[\"href\",\"http://vina.scripps.edu/tutorial.html\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"This is a short tutorial on how to set up AWS \"],[0,[0],1,\"Parallelcluster\"],[0,[],0,\" with Slurm to run \"],[0,[1],1,\"VirtualFlow\"],[0,[],0,\". \"]]],[1,\"blockquote\",[[0,[],0,\"VirtualFlow is a versatile, parallel workflow platform for carrying out virtual screening related tasks on Linux-based computer clusters of any type and size which are managed by a batchsystem (such as SLURM).\"]]],[1,\"h2\",[[0,[],0,\"AWS Parallelcluster with Slurm\"]]],[1,\"h3\",[[0,[],0,\"Creating our working environment\"]]],[1,\"p\",[[0,[],0,\"First, we'll create our working directory and set up a virtual environment using poetry. We need to add the awscli package as well as the aws-parallelcluster package.\"]]],[10,0],[1,\"h3\",[[0,[],0,\"Setting up the cluster config\"]]],[1,\"p\",[[0,[],0,\"To set up the AWS Parallelcluster I mainly followed \"],[0,[2],1,\"this post\"],[0,[],0,\". We start by creating the config for our cluster. Make sure to create an \"],[0,[3],1,\"EC2 key pair\"],[0,[],0,\" beforehand.\"]]],[10,1],[1,\"p\",[[0,[],0,\"We should now have a config file similar to this:\"]]],[10,2],[1,\"h3\",[[0,[],0,\"Creating the cluster\"]]],[1,\"p\",[[0,[],0,\"After the config file is set, we can create our cluster using the following commands. AWS will then spin up our CloudFormation stack which will take a couple of minutes.\"]]],[10,3],[1,\"p\",[[0,[],0,\"In order to access our head node we can run the following:\"]]],[10,4],[1,\"h2\",[[0,[],0,\"VirtualFlow\"]]],[1,\"p\",[[0,[],0,\"To get started with VirtualFlow I recommend running through the \"],[0,[4],1,\"first tutorial\"],[0,[],0,\" to make sure the cluster has been set up correctly. I'm only going through the changes that need to be made and list the other steps solely for completeness. The tutorial does a good job at explaining each individual step.\"]]],[1,\"h3\",[[0,[],0,\"Setting up VirtualFlow\"]]],[1,\"p\",[[0,[],0,\"First, we download the tutorial files and unzip them.\"]]],[10,5],[1,\"h3\",[[0,[],0,\"Preparing the config files\"]]],[1,\"p\",[[0,[],0,\"There are two files in which we need to make changes. We want to make sure our batchsystem is set to 'SLURM' and change the partition to 'compute' which is the default name when we use AWS Parallelcluster. \"]]],[10,6],[1,\"p\",[[0,[],0,\"If 'compute' doesn't work, try running the following command to retrieve the correct partition name: \"]]],[10,7],[1,\"p\",[[0,[],0,\"The second config file we need to adjust is the Slurm job template script. Usually we should be able to leave all the default values but I ran into this error:\"]]],[10,8],[1,\"p\",[[0,[],0,\"In order to solve it, we simply comment out the line with the --mem-per-cpu parameter.\"]]],[10,9],[1,\"p\",[[0,[],0,\"As a last preparation step we simply go back to the /tools subfolder and run this command:\"]]],[10,10],[1,\"p\",[[0,[],0,\"More details here: \"],[0,[5],1,\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/setting-up-the-workflow\"],[0,[],0,\".\"]]],[1,\"h3\",[[0,[],0,\"Starting the jobs\"]]],[1,\"p\",[[0,[],0,\"To spin up our nodes, we simply run this command:\"]]],[10,11],[1,\"p\",[[0,[],0,\"More details can be found here: \"],[0,[6],1,\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/starting-the-workflow\"],[0,[],0,\".\"]]],[1,\"h3\",[[0,[],0,\"Monitoring and Wrapping Up\"]]],[1,\"p\",[[0,[],0,\"In order to monitor the jobs and view the files after completion, I recommend the respective sections of the tutorial: \"]]],[1,\"p\",[[0,[7],1,\"Monitoring\"]]],[1,\"p\",[[0,[8],1,\"Completed Workflow\"]]],[1,\"h2\",[[0,[],0,\"Using our own files\"]]],[1,\"p\",[[0,[],0,\"Running the same workflow with our own files is pretty straightforward. After we downloaded the template files in the 'Setting up VirtualFlow' step we need to replace the ligand library as well as our target protein. \"]]],[1,\"h3\",[[0,[],0,\"Replacing the ligand library\"]]],[1,\"p\",[[0,[],0,\"The second tutorial in the VirtualFlow documentation has \"],[0,[9],1,\"a section dedicated\"],[0,[],0,\" to this.\"]]],[1,\"h3\",[[0,[],0,\"Using a different Protein\"]]],[1,\"p\",[[0,[],0,\"Here, I downloaded \"],[0,[10],1,\"AutoDock Vina\"],[0,[],0,\" together with \"],[0,[11],1,\"MGLTools\"],[0,[],0,\" and followed the \"],[0,[12],1,\"tutorial\"],[0,[],0,\" on \"],[0,[12],1,\"http://vina.scripps.edu\"],[0,[],0,\" which looks outdated but still works fine. We can use AutoDock Vina to convert our protein from .pbd to .pdbqt and use the 'GridBox' tool to get the necessary parameters for respective receptor config file. \"]]],[10,12],[1,\"p\",[[0,[],0,\"We add our protein to the folder and change both the smina (/input-files/smina_rigid_receptor1) and qvina receptor (/input-files/qvina02_rigid_receptor1) config files. \"]]],[1,\"p\",[[0,[],0,\"That's it. Now we can follow the rest of the steps outlined in the 'VirtualFlow' section above.\"]]]],\"ghostVersion\":\"3.0\"}","html":"<p>This is a short tutorial on how to set up AWS <a href=\"https://aws.amazon.com/hpc/parallelcluster/\">Parallelcluster</a> with Slurm to run <a href=\"https://virtual-flow.org/\">VirtualFlow</a>. </p><blockquote>VirtualFlow is a versatile, parallel workflow platform for carrying out virtual screening related tasks on Linux-based computer clusters of any type and size which are managed by a batchsystem (such as SLURM).</blockquote><h2 id=\"aws-parallelcluster-with-slurm\">AWS Parallelcluster with Slurm</h2><h3 id=\"creating-our-working-environment\">Creating our working environment</h3><p>First, we'll create our working directory and set up a virtual environment using poetry. We need to add the awscli package as well as the aws-parallelcluster package.</p><pre><code>mkdir parallel_cluster\ncd parallel_cluster\npoetry init\npoetry add awscli aws-parallelcluster</code></pre><h3 id=\"setting-up-the-cluster-config\">Setting up the cluster config</h3><p>To set up the AWS Parallelcluster I mainly followed <a href=\"https://aws.amazon.com/blogs/opensource/aws-parallelcluster/\">this post</a>. We start by creating the config for our cluster. Make sure to create an <a href=\"https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#KeyPairs\">EC2 key pair</a> beforehand.</p><pre><code> $ poetry run pcluster configure                  \nAllowed values for AWS Region ID:\n1. ap-northeast-1\n2. ap-northeast-2\n3. ap-south-1\n4. ap-southeast-1\n5. ap-southeast-2\n6. ca-central-1\n7. eu-central-1\n8. eu-north-1\n9. eu-west-1\n10. eu-west-2\n11. eu-west-3\n12. sa-east-1\n13. us-east-1\n14. us-east-2\n15. us-west-1\n16. us-west-2\nAWS Region ID [us-west-2]: 16\nAllowed values for EC2 Key Pair Name:\n1. parallelcluster\nEC2 Key Pair Name [parallelcluster]: 1\nAllowed values for Scheduler:\n1. sge\n2. torque\n3. slurm\n4. awsbatch\nScheduler [slurm]: 3\nAllowed values for Operating System:\n1. alinux\n2. alinux2\n3. centos7\n4. centos8\n5. ubuntu1604\n6. ubuntu1804\nOperating System [alinux2]: 2\nMinimum cluster size (instances) [0]: 1\nMaximum cluster size (instances) [10]: \nHead node instance type [t2.micro]: c4.large\nCompute instance type [t2.micro]: c4.xlarge\nAutomate VPC creation? (y/n) [n]: y</code></pre><p>We should now have a config file similar to this:</p><pre><code>$ cat ~/.parallelcluster/config \n[aws]\naws_region_name = us-west-2\n\n[aliases]\nssh = ssh {CFN_USER}@{MASTER_IP} {ARGS}\n\n[global]\ncluster_template = default\nupdate_check = true\nsanity_check = true\n\n[vpc default]\nvpc_id = vpc-*****************\nmaster_subnet_id = subnet-*****************\n\n[cluster default]\nkey_name = parallelcluster\nscheduler = slurm\nmaster_instance_type = c4.large\nbase_os = alinux2\nvpc_settings = default\nqueue_settings = compute\n\n[queue compute]\nenable_efa = false\nenable_efa_gdr = false\ncompute_resource_settings = default\n\n[compute_resource default]\ninstance_type = c4.xlarge\nmin_count = 1</code></pre><h3 id=\"creating-the-cluster\">Creating the cluster</h3><p>After the config file is set, we can create our cluster using the following commands. AWS will then spin up our CloudFormation stack which will take a couple of minutes.</p><pre><code>$ poetry run pcluster create test-cluster\nBeginning cluster creation for cluster: test-cluster\nCreating stack named: parallelcluster-test-cluster\n...</code></pre><p>In order to access our head node we can run the following:</p><pre><code>poetry run pcluster ssh test-cluster -i ~/.ssh/&lt;key_name&gt;</code></pre><h2 id=\"virtualflow\">VirtualFlow</h2><p>To get started with VirtualFlow I recommend running through the <a href=\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/introduction\">first tutorial</a> to make sure the cluster has been set up correctly. I'm only going through the changes that need to be made and list the other steps solely for completeness. The tutorial does a good job at explaining each individual step.</p><h3 id=\"setting-up-virtualflow\">Setting up VirtualFlow</h3><p>First, we download the tutorial files and unzip them.</p><pre><code>$ wget https://virtual-flow.org/sites/virtual-flow.org/files/tutorials/VFVS_GK.tar\n$ tar -xvf VFVS_GK.tar\n$ cd VFVS_GK/tools\n</code></pre><h3 id=\"preparing-the-config-files\">Preparing the config files</h3><p>There are two files in which we need to make changes. We want to make sure our batchsystem is set to 'SLURM' and change the partition to 'compute' which is the default name when we use AWS Parallelcluster. </p><pre><code># tools/templates/all.ctrl\n...\nbatchsystem=SLURM\n# Possible values: SLURM, TOQRUE, PBS, LSF, SGE\n# Settable via range control files: No\n...\npartition=compute\n# Partitions are also called queues in some batchsystems\n# Settable via range control files: Yes</code></pre><p>If 'compute' doesn't work, try running the following command to retrieve the correct partition name: </p><pre><code>$ sinfo\nPARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST \ncompute*     up   infinite      5  idle~ compute-dy-c4xlarge-[5-9] \ncompute*     up   infinite      5  alloc compute-dy-c4xlarge-[1-4],compute-st-c4xlarge-1 </code></pre><p>The second config file we need to adjust is the Slurm job template script. Usually we should be able to leave all the default values but I ran into this error:</p><pre><code>srun: error: Unable to create step for job 874794: Memory required by task is not available</code></pre><p>In order to solve it, we simply comment out the line with the --mem-per-cpu parameter.</p><pre><code># Slurm Settings\n###############################################################################\n\n#SBATCH --job-name=h-1.1\n##SBATCH --mail-user=To be completed if uncommented\n#SBATCH --mail-type=fail\n#SBATCH --time=00-12:00:00\n##SBATCH --mem-per-cpu=1024M\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1\n#SBATCH --partition=main\n#SBATCH --output=../workflow/output-files/jobs/job-1.1_%j.out           # File to which standard out will be written\n#SBATCH --error=../workflow/output-files/jobs/job-1.1_%j.out            # File to which standard err will be written\n#SBATCH --signal=10@300</code></pre><p>As a last preparation step we simply go back to the /tools subfolder and run this command:</p><pre><code>./vf_prepare_folders.sh</code></pre><p>More details here: <a href=\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/setting-up-the-workflow\">https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/setting-up-the-workflow</a>.</p><h3 id=\"starting-the-jobs\">Starting the jobs</h3><p>To spin up our nodes, we simply run this command:</p><pre><code>./vf_start_jobline.sh 1 12 templates/template1.slurm.sh submit 1</code></pre><p>More details can be found here: <a href=\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/starting-the-workflow\">https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/starting-the-workflow</a>.</p><h3 id=\"monitoring-and-wrapping-up\">Monitoring and Wrapping Up</h3><p>In order to monitor the jobs and view the files after completion, I recommend the respective sections of the tutorial: </p><p><a href=\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/monitoring-the-workflow\">Monitoring</a></p><p><a href=\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/the-completed-workflow\">Completed Workflow</a></p><h2 id=\"using-our-own-files\">Using our own files</h2><p>Running the same workflow with our own files is pretty straightforward. After we downloaded the template files in the 'Setting up VirtualFlow' step we need to replace the ligand library as well as our target protein. </p><h3 id=\"replacing-the-ligand-library\">Replacing the ligand library</h3><p>The second tutorial in the VirtualFlow documentation has <a href=\"https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/tutorial-2-vfvs-scratch/setting-up-the-workflow#preparing-the-input-files-folder\">a section dedicated</a> to this.</p><h3 id=\"using-a-different-protein\">Using a different Protein</h3><p>Here, I downloaded <a href=\"http://vina.scripps.edu/download.html\">AutoDock Vina</a> together with <a href=\"http://mgltools.scripps.edu/downloads\">MGLTools</a> and followed the <a href=\"http://vina.scripps.edu/tutorial.html\">tutorial</a> on <a href=\"http://vina.scripps.edu/tutorial.html\">http://vina.scripps.edu</a> which looks outdated but still works fine. We can use AutoDock Vina to convert our protein from .pbd to .pdbqt and use the 'GridBox' tool to get the necessary parameters for respective receptor config file. </p><pre><code># ../input-files/smina_rigid_receptor1/config.txt\nreceptor = ../input-files/receptor/&lt;protein&gt;.pdbqt\ncenter_x = 28.614\ncenter_y = 15.838\ncenter_z = -2.045\nsize_x = 36.0\nsize_y = 32.0\nsize_z = 36.0\nexhaustiveness = 4\nscoring = vinardo\ncpu = 1</code></pre><p>We add our protein to the folder and change both the smina (/input-files/smina_rigid_receptor1) and qvina receptor (/input-files/qvina02_rigid_receptor1) config files. </p><p>That's it. Now we can follow the rest of the steps outlined in the 'VirtualFlow' section above.</p>","comment_id":"607d4af6064f9e780b0d83ba","plaintext":"This is a short tutorial on how to set up AWS Parallelcluster\n[https://aws.amazon.com/hpc/parallelcluster/] with Slurm to run VirtualFlow\n[https://virtual-flow.org/]. \n\n> VirtualFlow is a versatile, parallel workflow platform for carrying out virtual\nscreening related tasks on Linux-based computer clusters of any type and size\nwhich are managed by a batchsystem (such as SLURM).\nAWS Parallelcluster with Slurm\nCreating our working environment\nFirst, we'll create our working directory and set up a virtual environment using\npoetry. We need to add the awscli package as well as the aws-parallelcluster\npackage.\n\nmkdir parallel_cluster\ncd parallel_cluster\npoetry init\npoetry add awscli aws-parallelcluster\n\nSetting up the cluster config\nTo set up the AWS Parallelcluster I mainly followed this post\n[https://aws.amazon.com/blogs/opensource/aws-parallelcluster/]. We start by\ncreating the config for our cluster. Make sure to create an EC2 key pair\n[https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#KeyPairs] \nbeforehand.\n\n $ poetry run pcluster configure                  \nAllowed values for AWS Region ID:\n1. ap-northeast-1\n2. ap-northeast-2\n3. ap-south-1\n4. ap-southeast-1\n5. ap-southeast-2\n6. ca-central-1\n7. eu-central-1\n8. eu-north-1\n9. eu-west-1\n10. eu-west-2\n11. eu-west-3\n12. sa-east-1\n13. us-east-1\n14. us-east-2\n15. us-west-1\n16. us-west-2\nAWS Region ID [us-west-2]: 16\nAllowed values for EC2 Key Pair Name:\n1. parallelcluster\nEC2 Key Pair Name [parallelcluster]: 1\nAllowed values for Scheduler:\n1. sge\n2. torque\n3. slurm\n4. awsbatch\nScheduler [slurm]: 3\nAllowed values for Operating System:\n1. alinux\n2. alinux2\n3. centos7\n4. centos8\n5. ubuntu1604\n6. ubuntu1804\nOperating System [alinux2]: 2\nMinimum cluster size (instances) [0]: 1\nMaximum cluster size (instances) [10]: \nHead node instance type [t2.micro]: c4.large\nCompute instance type [t2.micro]: c4.xlarge\nAutomate VPC creation? (y/n) [n]: y\n\nWe should now have a config file similar to this:\n\n$ cat ~/.parallelcluster/config \n[aws]\naws_region_name = us-west-2\n\n[aliases]\nssh = ssh {CFN_USER}@{MASTER_IP} {ARGS}\n\n[global]\ncluster_template = default\nupdate_check = true\nsanity_check = true\n\n[vpc default]\nvpc_id = vpc-*****************\nmaster_subnet_id = subnet-*****************\n\n[cluster default]\nkey_name = parallelcluster\nscheduler = slurm\nmaster_instance_type = c4.large\nbase_os = alinux2\nvpc_settings = default\nqueue_settings = compute\n\n[queue compute]\nenable_efa = false\nenable_efa_gdr = false\ncompute_resource_settings = default\n\n[compute_resource default]\ninstance_type = c4.xlarge\nmin_count = 1\n\nCreating the cluster\nAfter the config file is set, we can create our cluster using the following\ncommands. AWS will then spin up our CloudFormation stack which will take a\ncouple of minutes.\n\n$ poetry run pcluster create test-cluster\nBeginning cluster creation for cluster: test-cluster\nCreating stack named: parallelcluster-test-cluster\n...\n\nIn order to access our head node we can run the following:\n\npoetry run pcluster ssh test-cluster -i ~/.ssh/<key_name>\n\nVirtualFlow\nTo get started with VirtualFlow I recommend running through the first tutorial\n[https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/introduction] \nto make sure the cluster has been set up correctly. I'm only going through the\nchanges that need to be made and list the other steps solely for completeness.\nThe tutorial does a good job at explaining each individual step.\n\nSetting up VirtualFlow\nFirst, we download the tutorial files and unzip them.\n\n$ wget https://virtual-flow.org/sites/virtual-flow.org/files/tutorials/VFVS_GK.tar\n$ tar -xvf VFVS_GK.tar\n$ cd VFVS_GK/tools\n\n\nPreparing the config files\nThere are two files in which we need to make changes. We want to make sure our\nbatchsystem is set to 'SLURM' and change the partition to 'compute' which is the\ndefault name when we use AWS Parallelcluster. \n\n# tools/templates/all.ctrl\n...\nbatchsystem=SLURM\n# Possible values: SLURM, TOQRUE, PBS, LSF, SGE\n# Settable via range control files: No\n...\npartition=compute\n# Partitions are also called queues in some batchsystems\n# Settable via range control files: Yes\n\nIf 'compute' doesn't work, try running the following command to retrieve the\ncorrect partition name: \n\n$ sinfo\nPARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST \ncompute*     up   infinite      5  idle~ compute-dy-c4xlarge-[5-9] \ncompute*     up   infinite      5  alloc compute-dy-c4xlarge-[1-4],compute-st-c4xlarge-1 \n\nThe second config file we need to adjust is the Slurm job template script.\nUsually we should be able to leave all the default values but I ran into this\nerror:\n\nsrun: error: Unable to create step for job 874794: Memory required by task is not available\n\nIn order to solve it, we simply comment out the line with the --mem-per-cpu\nparameter.\n\n# Slurm Settings\n###############################################################################\n\n#SBATCH --job-name=h-1.1\n##SBATCH --mail-user=To be completed if uncommented\n#SBATCH --mail-type=fail\n#SBATCH --time=00-12:00:00\n##SBATCH --mem-per-cpu=1024M\n#SBATCH --nodes=1\n#SBATCH --cpus-per-task=1\n#SBATCH --partition=main\n#SBATCH --output=../workflow/output-files/jobs/job-1.1_%j.out           # File to which standard out will be written\n#SBATCH --error=../workflow/output-files/jobs/job-1.1_%j.out            # File to which standard err will be written\n#SBATCH --signal=10@300\n\nAs a last preparation step we simply go back to the /tools subfolder and run\nthis command:\n\n./vf_prepare_folders.sh\n\nMore details here: \nhttps://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/setting-up-the-workflow\n.\n\nStarting the jobs\nTo spin up our nodes, we simply run this command:\n\n./vf_start_jobline.sh 1 12 templates/template1.slurm.sh submit 1\n\nMore details can be found here: \nhttps://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/starting-the-workflow\n.\n\nMonitoring and Wrapping Up\nIn order to monitor the jobs and view the files after completion, I recommend\nthe respective sections of the tutorial: \n\nMonitoring\n[https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/monitoring-the-workflow]\n\nCompleted Workflow\n[https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/vfvs-tutorial-1/the-completed-workflow]\n\nUsing our own files\nRunning the same workflow with our own files is pretty straightforward. After we\ndownloaded the template files in the 'Setting up VirtualFlow' step we need to\nreplace the ligand library as well as our target protein. \n\nReplacing the ligand library\nThe second tutorial in the VirtualFlow documentation has a section dedicated\n[https://docs.virtual-flow.org/tutorials/-LdE94b2AVfBFT72zK-v/tutorial-2-vfvs-scratch/setting-up-the-workflow#preparing-the-input-files-folder] \nto this.\n\nUsing a different Protein\nHere, I downloaded AutoDock Vina [http://vina.scripps.edu/download.html] \ntogether with MGLTools [http://mgltools.scripps.edu/downloads] and followed the \ntutorial [http://vina.scripps.edu/tutorial.html] on http://vina.scripps.edu\n[http://vina.scripps.edu/tutorial.html] which looks outdated but still works\nfine. We can use AutoDock Vina to convert our protein from .pbd to .pdbqt and\nuse the 'GridBox' tool to get the necessary parameters for respective receptor\nconfig file. \n\n# ../input-files/smina_rigid_receptor1/config.txt\nreceptor = ../input-files/receptor/<protein>.pdbqt\ncenter_x = 28.614\ncenter_y = 15.838\ncenter_z = -2.045\nsize_x = 36.0\nsize_y = 32.0\nsize_z = 36.0\nexhaustiveness = 4\nscoring = vinardo\ncpu = 1\n\nWe add our protein to the folder and change both the smina\n(/input-files/smina_rigid_receptor1) and qvina receptor\n(/input-files/qvina02_rigid_receptor1) config files. \n\nThat's it. Now we can follow the rest of the steps outlined in the 'VirtualFlow'\nsection above.","feature_image":null,"featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2021-04-19 09:18:46","created_by":"1","updated_at":"2021-04-25 14:06:35","updated_by":"1","published_at":"2021-04-19 10:27:48","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"6085751174348916f1b089a9","uuid":"3481e6f2-8c81-44d3-bc5d-a09488e93d23","title":"My Emacs + Org-Roam + Logseq Setup","slug":"my-emacs-org-roam-logseq-setup","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"(use-package org-roam\\n  :ensure t\\n  :hook\\n  (after-init . org-roam-mode)\\n  :custom\\n  (org-roam-directory \\\"~/org-roam/\\\"\\n   org-roam-db-location \\\"~/org-roam/org-roam.db\\\")\\n  :bind (:map org-roam-mode-map\\n              ((\\\"C-c n l\\\" . org-roam)\\n               (\\\"C-c n f\\\" . org-roam-find-file)\\n               (\\\"C-c n g\\\" . org-roam-graph)\\n               (\\\"C-c n t\\\" . org-roam-dailies-find-today)\\n               (\\\"C-c n c\\\" . org-roam-dailies-capture-today))\\n         :map org-mode-map\\n              ((\\\"C-c n i\\\" . org-roam-insert))\\n              ((\\\"C-c n I\\\" . org-roam-insert-immediate))))\\n(setq org-roam-dailies-directory \\\"journals/\\\")\\n(setq org-roam-dailies-capture-templates\\n      '((\\\"d\\\" \\\"default\\\" entry\\n         #'org-roam-capture--get-point\\n         \\\"* %?\\\"\\n         :file-name \\\"journals/%<%Y-%m-%d>\\\"\\n         :head \\\"#+title: %<%Y-%m-%d>\\\\n\\\\n\\\")))\\n\"}],[\"code\",{\"code\":\"# Sync with git\\n./git-sync\\n\\n# Sync with local db\\nif [ \\\"` ls -t | head -1`\\\" != \\\"org-roam.db\\\" ]; then\\n  emacsclient -e '(org-roam-db-build-cache)'\\nfi\"}],[\"code\",{\"code\":\"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\\nMAILTO=\\\"\\\"\\n\\n*/1 * * * *  cd ~/org-roam && ./sync-git-and-db.sh\"}],[\"code\",{\"code\":\"{:journal-basis \\\"daily\\\" \\n :project {\\n           ;; Selected public notes can be published to https://logseq.com/your-project-or-your-username.\\n           :name \\\"\\\"\\n           :alias \\\"\\\"\\n           ;; your twitter handle\\n           :twitter \\\"\\\"\\n           ;; description supports both hiccup and html\\n           :description \\\"\\\"}\\n:org-mode/insert-file-link? true ;; add this, file continues below\"}]],\"markups\":[[\"a\",[\"href\",\"https://github.com/org-roam/org-roam\"]],[\"a\",[\"href\",\"https://www.orgroam.com/manual.html\"]],[\"a\",[\"href\",\"https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh\"]],[\"a\",[\"href\",\"https://org-roam.discourse.group/t/org-roam-db-across-multiple-machines/332/2\"]],[\"a\",[\"href\",\"https://github.com/simonthum/git-sync\"]],[\"code\"],[\"a\",[\"href\",\"https://github.com/logseq/logseq#how-can-i-use-it\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"First installed org-roam using the instructions on their github (\"],[0,[0],1,\"https://github.com/org-roam/org-roam\"],[0,[],0,\") and manual (\"],[0,[1],1,\"https://www.orgroam.com/manual.html\"],[0,[],0,\")\"]]],[1,\"p\",[[0,[],0,\"This is the config I used in my init.el\"]]],[10,0],[1,\"p\",[[0,[],0,\"Two important changes to the defaults:\"]]],[3,\"ul\",[[[0,[],0,\"Set up the org-roam.db in the same folder\"]],[[0,[],0,\"Logseq uses /journals folder instead of /daily\"]]]],[1,\"p\",[[0,[],0,\"In order to sync it with logseq\"]]],[3,\"ul\",[[[0,[],0,\"First initialized a github repo\"]],[[0,[],0,\"connecting with ssh will make it easier for the crontab to sync with github, find out how to do that here: \"],[0,[2],1,\"https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh\"]],[[0,[],0,\"According to this (\"],[0,[3],1,\"https://org-roam.discourse.group/t/org-roam-db-across-multiple-machines/332/2\"],[0,[],0,\") comment in the forum, used git-sync (\"],[0,[4],1,\"https://github.com/simonthum/git-sync\"],[0,[],0,\")\"]],[[0,[],0,\"Created my own script which is ran by crontab \"]]]],[10,1],[3,\"ul\",[[[0,[],0,\"Then set up crontab using \"],[0,[5],1,\"crontab -e\"],[0,[],0,\" , set the path to include the emacsclient, disabled \"],[0,[5],1,\"MAILTO\"],[0,[],0,\" though I would remove the line during setup for easier debugging, set the job to run every minute\"]]]],[10,2],[3,\"ul\",[[[0,[],0,\"Then went to \"],[0,[6],1,\"https://github.com/logseq/logseq#how-can-i-use-it\"],[0,[],0,\" and connected the website with my github repo\"]],[[0,[],0,\"Lastly went to /logseq/config.edn and added the following in order to keep org mode and logseq page linking in sync\"]]]],[10,3],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}","html":"<p>First installed org-roam using the instructions on their github (<a href=\"https://github.com/org-roam/org-roam\">https://github.com/org-roam/org-roam</a>) and manual (<a href=\"https://www.orgroam.com/manual.html\">https://www.orgroam.com/manual.html</a>)</p><p>This is the config I used in my init.el</p><pre><code>(use-package org-roam\n  :ensure t\n  :hook\n  (after-init . org-roam-mode)\n  :custom\n  (org-roam-directory \"~/org-roam/\"\n   org-roam-db-location \"~/org-roam/org-roam.db\")\n  :bind (:map org-roam-mode-map\n              ((\"C-c n l\" . org-roam)\n               (\"C-c n f\" . org-roam-find-file)\n               (\"C-c n g\" . org-roam-graph)\n               (\"C-c n t\" . org-roam-dailies-find-today)\n               (\"C-c n c\" . org-roam-dailies-capture-today))\n         :map org-mode-map\n              ((\"C-c n i\" . org-roam-insert))\n              ((\"C-c n I\" . org-roam-insert-immediate))))\n(setq org-roam-dailies-directory \"journals/\")\n(setq org-roam-dailies-capture-templates\n      '((\"d\" \"default\" entry\n         #'org-roam-capture--get-point\n         \"* %?\"\n         :file-name \"journals/%&lt;%Y-%m-%d&gt;\"\n         :head \"#+title: %&lt;%Y-%m-%d&gt;\\n\\n\")))\n</code></pre><p>Two important changes to the defaults:</p><ul><li>Set up the org-roam.db in the same folder</li><li>Logseq uses /journals folder instead of /daily</li></ul><p>In order to sync it with logseq</p><ul><li>First initialized a github repo</li><li>connecting with ssh will make it easier for the crontab to sync with github, find out how to do that here: <a href=\"https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh\">https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh</a></li><li>According to this (<a href=\"https://org-roam.discourse.group/t/org-roam-db-across-multiple-machines/332/2\">https://org-roam.discourse.group/t/org-roam-db-across-multiple-machines/332/2</a>) comment in the forum, used git-sync (<a href=\"https://github.com/simonthum/git-sync\">https://github.com/simonthum/git-sync</a>)</li><li>Created my own script which is ran by crontab </li></ul><pre><code># Sync with git\n./git-sync\n\n# Sync with local db\nif [ \"` ls -t | head -1`\" != \"org-roam.db\" ]; then\n  emacsclient -e '(org-roam-db-build-cache)'\nfi</code></pre><ul><li>Then set up crontab using <code>crontab -e</code> , set the path to include the emacsclient, disabled <code>MAILTO</code> though I would remove the line during setup for easier debugging, set the job to run every minute</li></ul><pre><code>PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nMAILTO=\"\"\n\n*/1 * * * *  cd ~/org-roam &amp;&amp; ./sync-git-and-db.sh</code></pre><ul><li>Then went to <a href=\"https://github.com/logseq/logseq#how-can-i-use-it\">https://github.com/logseq/logseq#how-can-i-use-it</a> and connected the website with my github repo</li><li>Lastly went to /logseq/config.edn and added the following in order to keep org mode and logseq page linking in sync</li></ul><pre><code>{:journal-basis \"daily\" \n :project {\n           ;; Selected public notes can be published to https://logseq.com/your-project-or-your-username.\n           :name \"\"\n           :alias \"\"\n           ;; your twitter handle\n           :twitter \"\"\n           ;; description supports both hiccup and html\n           :description \"\"}\n:org-mode/insert-file-link? true ;; add this, file continues below</code></pre>","comment_id":"60841f53064f9e780b0d8512","plaintext":"First installed org-roam using the instructions on their github (\nhttps://github.com/org-roam/org-roam) and manual (\nhttps://www.orgroam.com/manual.html)\n\nThis is the config I used in my init.el\n\n(use-package org-roam\n  :ensure t\n  :hook\n  (after-init . org-roam-mode)\n  :custom\n  (org-roam-directory \"~/org-roam/\"\n   org-roam-db-location \"~/org-roam/org-roam.db\")\n  :bind (:map org-roam-mode-map\n              ((\"C-c n l\" . org-roam)\n               (\"C-c n f\" . org-roam-find-file)\n               (\"C-c n g\" . org-roam-graph)\n               (\"C-c n t\" . org-roam-dailies-find-today)\n               (\"C-c n c\" . org-roam-dailies-capture-today))\n         :map org-mode-map\n              ((\"C-c n i\" . org-roam-insert))\n              ((\"C-c n I\" . org-roam-insert-immediate))))\n(setq org-roam-dailies-directory \"journals/\")\n(setq org-roam-dailies-capture-templates\n      '((\"d\" \"default\" entry\n         #'org-roam-capture--get-point\n         \"* %?\"\n         :file-name \"journals/%<%Y-%m-%d>\"\n         :head \"#+title: %<%Y-%m-%d>\\n\\n\")))\n\n\nTwo important changes to the defaults:\n\n * Set up the org-roam.db in the same folder\n * Logseq uses /journals folder instead of /daily\n\nIn order to sync it with logseq\n\n * First initialized a github repo\n * connecting with ssh will make it easier for the crontab to sync with github,\n   find out how to do that here: \n   https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh\n * According to this (\n   https://org-roam.discourse.group/t/org-roam-db-across-multiple-machines/332/2\n   ) comment in the forum, used git-sync (https://github.com/simonthum/git-sync)\n * Created my own script which is ran by crontab \n\n# Sync with git\n./git-sync\n\n# Sync with local db\nif [ \"` ls -t | head -1`\" != \"org-roam.db\" ]; then\n  emacsclient -e '(org-roam-db-build-cache)'\nfi\n\n * Then set up crontab using crontab -e , set the path to include the\n   emacsclient, disabled MAILTO though I would remove the line during setup for\n   easier debugging, set the job to run every minute\n\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nMAILTO=\"\"\n\n*/1 * * * *  cd ~/org-roam && ./sync-git-and-db.sh\n\n * Then went to https://github.com/logseq/logseq#how-can-i-use-it and connected\n   the website with my github repo\n * Lastly went to /logseq/config.edn and added the following in order to keep\n   org mode and logseq page linking in sync\n\n{:journal-basis \"daily\" \n :project {\n           ;; Selected public notes can be published to https://logseq.com/your-project-or-your-username.\n           :name \"\"\n           :alias \"\"\n           ;; your twitter handle\n           :twitter \"\"\n           ;; description supports both hiccup and html\n           :description \"\"}\n:org-mode/insert-file-link? true ;; add this, file continues below","feature_image":null,"featured":0,"type":"post","status":"draft","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2021-04-24 13:38:27","created_by":"1","updated_at":"2021-04-25 14:06:28","updated_by":"1","published_at":"2021-04-25 14:06:15","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"60857c71d3d3ed25945ea735","uuid":"1684d917-2100-4abc-b589-0d319421793c","title":"How to set up your own ENS domain name","slug":"how-to-set-up-ens-domain-name","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/1-launch-1.gif\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/2-search-name-1.gif\",\"width\":2000,\"height\":1100}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/3-connect-wallet.gif\",\"width\":2000,\"height\":1100}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/4-metamask-chrome.gif\",\"width\":2000,\"height\":1100}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/5-add-metamask-chrome.gif\",\"width\":2000,\"height\":1100}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/6-metamask-get-started.gif\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/7-create-password.gif\",\"width\":2000,\"height\":1100}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/8-backup-phrase.gif\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/9-account.png\",\"width\":3584,\"height\":2174}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/10-connect-wallet.gif\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/11-init-metamask.gif\",\"width\":2000,\"height\":1100}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/12-deposit-eth.gif\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/13-register-years.gif\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/14-three-steps.png\",\"width\":2934,\"height\":414}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/14-request-to-register.gif\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/15-wait-for-1-minute.png\",\"width\":3584,\"height\":2186}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/16-complete-registration.gif\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/17-my-account.png\",\"width\":3584,\"height\":2186}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/18-reverse-record.gif\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/19-record-success.png\",\"width\":3584,\"height\":2186}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/20-set-records.gif\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/21-confirm-transaction.gif\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2021/04/22-confirm.gif\"}],[\"hr\",{}]],\"markups\":[[\"strong\"],[\"a\",[\"href\",\"https://metamask.io/download.html\"]],[\"a\",[\"href\",\"https://app.ens.domains/name/rmeinl.eth\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"This is a short tutorial on how to set up your own ENS domain name using MetaMask and Google Chrome. Normally I'm using Brave but I thought doing the demos in Chrome would allow more people to access it.\"]]],[3,\"ol\",[[[0,[],0,\"Go to https://ens.domains/ and click \"],[0,[0],1,\"Launch App\"],[0,[],0,\".\"]]]],[10,0],[1,\"p\",[[0,[],0,\"2. Enter the name you are planning to register. It can end with .eth but doesn't have to.\"]]],[10,1],[1,\"p\",[[0,[],0,\"3. Now we have to connect ENS to an Ethereum account. Though they offer multiple ways to connect your wallet (as shown below) we are going to use MetaMask for this tutorial. If you already have a MetaMask account set up, you can jump straight to step 10.\"]]],[10,2],[1,\"p\",[[0,[],0,\"4. In order to download MetaMask, go to \"],[0,[1],1,\"https://metamask.io/download.html\"],[0,[],0,\" and press \"],[0,[0],1,\"Install MetaMask for Chrome\"],[0,[],0,\". You'll be redirected to the Chrome Web Store.\"]]],[10,3],[1,\"p\",[[0,[],0,\"5. Next, add MetaMask to Chrome by pressing \"],[0,[0],1,\"Add to Chrome\"],[0,[],0,\". After installation, you'll be redirected to the setup screen. \"]]],[10,4],[1,\"p\",[[0,[],0,\"6. Press \"],[0,[0],1,\"Get Started\"],[0,[],0,\" and \"],[0,[0],1,\"Create a Wallet\"],[0,[],0,\" unless you already have one. \"]]],[10,5],[1,\"p\",[[0,[],0,\"7. Create a password for your wallet.\"]]],[10,6],[1,\"p\",[[0,[],0,\"8. Store your \"],[0,[0],1,\"secret\"],[0,[],0,\" backup phrase in a safe place. It makes it easy to back up and restore your account. (The only reason I'm showing my phrase is because I'm using a throwaway account for this tutorial. You should never show it to anyone.)\"]]],[10,7],[1,\"p\",[[0,[],0,\"9. You're all set. You should now see a page with your MetaMask account like this.\"]]],[10,8],[1,\"p\",[[0,[],0,\"10. Now that MetaMask is all set up, switch back to the ENS tab and click \"],[0,[0],1,\"Connect \"],[0,[],0,\"to connect with your wallet. It'll open the same window as in step 3, but it should also include MetaMask now. You might have to refresh your browser.\"]]],[10,9],[1,\"p\",[[0,[],0,\"11. Click \"],[0,[0],1,\"MetaMask \"],[0,[],0,\"and select the account you want to authenticate with. Click \"],[0,[0],1,\"Next\"],[0,[],0,\" and finally \"],[0,[0],1,\"Connect\"],[0,[],0,\". On the left side next to the ENS domain name you should now see that your account is connected to the mainnet.\"]]],[10,10],[1,\"p\",[[0,[],0,\"12. In order to pay for the domain name you need to add some Ether to your account. The fastest way to do that is a direct deposit as shown below. Go to \"],[0,[0],1,\"Buy\"],[0,[],0,\" > \"],[0,[0],1,\"Directly Deposit Ether \"],[0,[],0,\" > \"],[0,[0],1,\"View Account \"],[0,[],0,\"to get your MetaMask Ether address. Use the wallet of your choice to send Ether to this account. It could take up to 10 minutes for your funds to arrive.\"]]],[10,11],[1,\"p\",[[0,[],0,\"13. Click on the domain name you want to register and select the number of years you want to reserve it for (2+ years are recommended, given the gas fees). There are three steps in total as listed on the website.\"]]],[10,12],[10,13],[1,\"p\",[[0,[],0,\"14. \"],[0,[0],1,\"Request to register\"],[0,[],0,\": Your wallet will open and you will be asked to confirm the first of two transactions required for registration.\"]]],[10,14],[1,\"p\",[[0,[],0,\"15. \"],[0,[0],1,\"Wait for 1 minute\"],[0,[],0,\": The waiting period is required to ensure another person hasn’t tried to register the same name and protect you after your request. Afterward, your screen should look like this.\"]]],[10,15],[1,\"p\",[[0,[],0,\"16. \"],[0,[0],1,\"Complete Registration\"],[0,[],0,\": Click \"],[0,[0],1,\"Register\"],[0,[],0,\" and your wallet will re-open. Only after the 2nd transaction is confirmed you'll know if you got the name. This could take up to 10 minutes. As you can see, this transaction cost me about $50 in total but the gas fees are variable so it might be more or less depending on when you submit yours.\"]]],[10,16],[1,\"p\",[[0,[],0,\"17. After the registration is completed, you should see the name show up under \"],[0,[0],1,\"My Account\"],[0,[],0,\".\"]]],[10,17],[1,\"p\",[[0,[],0,\"18. Click \"],[0,[0],1,\"Reverse record: not set\"],[0,[],0,\". Select your ENS name then click \"],[0,[0],1,\"Save\"],[0,[],0,\", and submit the transaction to save it on the blockchain.\"]]],[10,18],[1,\"p\",[[0,[],0,\"19. After about 10 minutes you should see that your reverse record has been set up successfully.\"]]],[10,19],[1,\"p\",[[0,[],0,\"20. In order to add some records, click on your name in the list below. You should see that it already points to your Ethereum address. Click on \"],[0,[0],1,\"Add/Edit Record\"],[0,[],0,\". I'm going to add my BTC address, my website and twitter as well as github handle.\"]]],[10,20],[1,\"p\",[[0,[],0,\"21. Finally, confirm the transaction and submit it to the blockchain via MetaMask. This should take another 10 minutes.\"]]],[10,21],[1,\"p\",[[0,[],0,\"22. That's it! You can now use a browser like Opera or Brave to check whether everything worked out. I'm using Brave here, which will initially ask for confirmation to redirect via ENS. You should then see your record. If you neither have Brave or Opera, just go to \"],[0,[2],1,\"https://app.ens.domains/name/<your_domain>.eth\"]]],[10,22],[10,23],[1,\"p\",[[0,[],0,\"We just walked through how to set up your own ENS domain name using MetaMask and Chrome. To give you a rough idea about the costs, the whole process cost me $97.86. Here's the breakdown: \"]]],[3,\"ul\",[[[0,[],0,\"$6.17 for step 14 (initial request)\"]],[[0,[],0,\"$46.26 for step 16 (paying for the name)\"]],[[0,[],0,\"$21.48 for step 18 (setting up the reverse record)\"]],[[0,[],0,\"$23.95 for step 21 (adding custom records)\"]]]],[1,\"p\",[[0,[],0,\"Obviously the majority of these costs are gas fees, you only pay ENS for step 16 so it will vary for you depending on when you set up yours.\"]]],[1,\"p\",[[0,[],0,\"Hope this was helpful!\"]]]],\"ghostVersion\":\"4.0\"}","html":"<p>This is a short tutorial on how to set up your own ENS domain name using MetaMask and Google Chrome. Normally I'm using Brave but I thought doing the demos in Chrome would allow more people to access it.</p><ol><li>Go to https://ens.domains/ and click <strong>Launch App</strong>.</li></ol><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/1-launch-1.gif\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>2. Enter the name you are planning to register. It can end with .eth but doesn't have to.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/2-search-name-1.gif\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1100\"></figure><p>3. Now we have to connect ENS to an Ethereum account. Though they offer multiple ways to connect your wallet (as shown below) we are going to use MetaMask for this tutorial. If you already have a MetaMask account set up, you can jump straight to step 10.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/3-connect-wallet.gif\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1100\"></figure><p>4. In order to download MetaMask, go to <a href=\"https://metamask.io/download.html\">https://metamask.io/download.html</a> and press <strong>Install MetaMask for Chrome</strong>. You'll be redirected to the Chrome Web Store.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/4-metamask-chrome.gif\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1100\"></figure><p>5. Next, add MetaMask to Chrome by pressing <strong>Add to Chrome</strong>. After installation, you'll be redirected to the setup screen. </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/5-add-metamask-chrome.gif\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1100\"></figure><p>6. Press <strong>Get Started</strong> and <strong>Create a Wallet</strong> unless you already have one. </p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/6-metamask-get-started.gif\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>7. Create a password for your wallet.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/7-create-password.gif\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1100\"></figure><p>8. Store your <strong>secret</strong> backup phrase in a safe place. It makes it easy to back up and restore your account. (The only reason I'm showing my phrase is because I'm using a throwaway account for this tutorial. You should never show it to anyone.)</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/8-backup-phrase.gif\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>9. You're all set. You should now see a page with your MetaMask account like this.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/9-account.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1213\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/9-account.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/9-account.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/04/9-account.png 1600w, __GHOST_URL__/content/images/size/w2400/2021/04/9-account.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>10. Now that MetaMask is all set up, switch back to the ENS tab and click <strong>Connect </strong>to connect with your wallet. It'll open the same window as in step 3, but it should also include MetaMask now. You might have to refresh your browser.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/10-connect-wallet.gif\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>11. Click <strong>MetaMask </strong>and select the account you want to authenticate with. Click <strong>Next</strong> and finally <strong>Connect</strong>. On the left side next to the ENS domain name you should now see that your account is connected to the mainnet.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/11-init-metamask.gif\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1100\"></figure><p>12. In order to pay for the domain name you need to add some Ether to your account. The fastest way to do that is a direct deposit as shown below. Go to <strong>Buy</strong> &gt; <strong>Directly Deposit Ether </strong> &gt; <strong>View Account </strong>to get your MetaMask Ether address. Use the wallet of your choice to send Ether to this account. It could take up to 10 minutes for your funds to arrive.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/12-deposit-eth.gif\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>13. Click on the domain name you want to register and select the number of years you want to reserve it for (2+ years are recommended, given the gas fees). There are three steps in total as listed on the website.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/13-register-years.gif\" class=\"kg-image\" alt loading=\"lazy\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/14-three-steps.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"282\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/14-three-steps.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/14-three-steps.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/04/14-three-steps.png 1600w, __GHOST_URL__/content/images/size/w2400/2021/04/14-three-steps.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>14. <strong>Request to register</strong>: Your wallet will open and you will be asked to confirm the first of two transactions required for registration.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/14-request-to-register.gif\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>15. <strong>Wait for 1 minute</strong>: The waiting period is required to ensure another person hasn’t tried to register the same name and protect you after your request. Afterward, your screen should look like this.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/15-wait-for-1-minute.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1220\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/15-wait-for-1-minute.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/15-wait-for-1-minute.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/04/15-wait-for-1-minute.png 1600w, __GHOST_URL__/content/images/size/w2400/2021/04/15-wait-for-1-minute.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>16. <strong>Complete Registration</strong>: Click <strong>Register</strong> and your wallet will re-open. Only after the 2nd transaction is confirmed you'll know if you got the name. This could take up to 10 minutes. As you can see, this transaction cost me about $50 in total but the gas fees are variable so it might be more or less depending on when you submit yours.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/16-complete-registration.gif\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>17. After the registration is completed, you should see the name show up under <strong>My Account</strong>.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/17-my-account.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1220\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/17-my-account.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/17-my-account.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/04/17-my-account.png 1600w, __GHOST_URL__/content/images/size/w2400/2021/04/17-my-account.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>18. Click <strong>Reverse record: not set</strong>. Select your ENS name then click <strong>Save</strong>, and submit the transaction to save it on the blockchain.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/18-reverse-record.gif\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>19. After about 10 minutes you should see that your reverse record has been set up successfully.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/19-record-success.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"2000\" height=\"1220\" srcset=\"__GHOST_URL__/content/images/size/w600/2021/04/19-record-success.png 600w, __GHOST_URL__/content/images/size/w1000/2021/04/19-record-success.png 1000w, __GHOST_URL__/content/images/size/w1600/2021/04/19-record-success.png 1600w, __GHOST_URL__/content/images/size/w2400/2021/04/19-record-success.png 2400w\" sizes=\"(min-width: 720px) 720px\"></figure><p>20. In order to add some records, click on your name in the list below. You should see that it already points to your Ethereum address. Click on <strong>Add/Edit Record</strong>. I'm going to add my BTC address, my website and twitter as well as github handle.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/20-set-records.gif\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>21. Finally, confirm the transaction and submit it to the blockchain via MetaMask. This should take another 10 minutes.</p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/21-confirm-transaction.gif\" class=\"kg-image\" alt loading=\"lazy\"></figure><p>22. That's it! You can now use a browser like Opera or Brave to check whether everything worked out. I'm using Brave here, which will initially ask for confirmation to redirect via ENS. You should then see your record. If you neither have Brave or Opera, just go to <a href=\"https://app.ens.domains/name/rmeinl.eth\">https://app.ens.domains/name/&lt;your_domain&gt;.eth</a></p><figure class=\"kg-card kg-image-card\"><img src=\"__GHOST_URL__/content/images/2021/04/22-confirm.gif\" class=\"kg-image\" alt loading=\"lazy\"></figure><hr><p>We just walked through how to set up your own ENS domain name using MetaMask and Chrome. To give you a rough idea about the costs, the whole process cost me $97.86. Here's the breakdown: </p><ul><li>$6.17 for step 14 (initial request)</li><li>$46.26 for step 16 (paying for the name)</li><li>$21.48 for step 18 (setting up the reverse record)</li><li>$23.95 for step 21 (adding custom records)</li></ul><p>Obviously the majority of these costs are gas fees, you only pay ENS for step 16 so it will vary for you depending on when you set up yours.</p><p>Hope this was helpful!</p>","comment_id":"60857c71d3d3ed25945ea735","plaintext":"This is a short tutorial on how to set up your own ENS domain name using\nMetaMask and Google Chrome. Normally I'm using Brave but I thought doing the\ndemos in Chrome would allow more people to access it.\n\n 1. Go to https://ens.domains/ and click Launch App.\n\n2. Enter the name you are planning to register. It can end with .eth but doesn't\nhave to.\n\n3. Now we have to connect ENS to an Ethereum account. Though they offer multiple\nways to connect your wallet (as shown below) we are going to use MetaMask for\nthis tutorial. If you already have a MetaMask account set up, you can jump\nstraight to step 10.\n\n4. In order to download MetaMask, go to https://metamask.io/download.html and\npress Install MetaMask for Chrome. You'll be redirected to the Chrome Web Store.\n\n5. Next, add MetaMask to Chrome by pressing Add to Chrome. After installation,\nyou'll be redirected to the setup screen. \n\n6. Press Get Started and Create a Wallet unless you already have one. \n\n7. Create a password for your wallet.\n\n8. Store your secret backup phrase in a safe place. It makes it easy to back up\nand restore your account. (The only reason I'm showing my phrase is because I'm\nusing a throwaway account for this tutorial. You should never show it to\nanyone.)\n\n9. You're all set. You should now see a page with your MetaMask account like\nthis.\n\n10. Now that MetaMask is all set up, switch back to the ENS tab and click \nConnect to connect with your wallet. It'll open the same window as in step 3,\nbut it should also include MetaMask now. You might have to refresh your browser.\n\n11. Click MetaMask and select the account you want to authenticate with. Click \nNext and finally Connect. On the left side next to the ENS domain name you\nshould now see that your account is connected to the mainnet.\n\n12. In order to pay for the domain name you need to add some Ether to your\naccount. The fastest way to do that is a direct deposit as shown below. Go to \nBuy > Directly Deposit Ether > View Account to get your MetaMask Ether address.\nUse the wallet of your choice to send Ether to this account. It could take up to\n10 minutes for your funds to arrive.\n\n13. Click on the domain name you want to register and select the number of years\nyou want to reserve it for (2+ years are recommended, given the gas fees). There\nare three steps in total as listed on the website.\n\n14. Request to register: Your wallet will open and you will be asked to confirm\nthe first of two transactions required for registration.\n\n15. Wait for 1 minute: The waiting period is required to ensure another person\nhasn’t tried to register the same name and protect you after your request.\nAfterward, your screen should look like this.\n\n16. Complete Registration: Click Register and your wallet will re-open. Only\nafter the 2nd transaction is confirmed you'll know if you got the name. This\ncould take up to 10 minutes. As you can see, this transaction cost me about $50\nin total but the gas fees are variable so it might be more or less depending on\nwhen you submit yours.\n\n17. After the registration is completed, you should see the name show up under \nMy Account.\n\n18. Click Reverse record: not set. Select your ENS name then click Save, and\nsubmit the transaction to save it on the blockchain.\n\n19. After about 10 minutes you should see that your reverse record has been set\nup successfully.\n\n20. In order to add some records, click on your name in the list below. You\nshould see that it already points to your Ethereum address. Click on Add/Edit\nRecord. I'm going to add my BTC address, my website and twitter as well as\ngithub handle.\n\n21. Finally, confirm the transaction and submit it to the blockchain via\nMetaMask. This should take another 10 minutes.\n\n22. That's it! You can now use a browser like Opera or Brave to check whether\neverything worked out. I'm using Brave here, which will initially ask for\nconfirmation to redirect via ENS. You should then see your record. If you\nneither have Brave or Opera, just go to \nhttps://app.ens.domains/name/<your_domain>.eth\n[https://app.ens.domains/name/rmeinl.eth]\n\n\n--------------------------------------------------------------------------------\n\nWe just walked through how to set up your own ENS domain name using MetaMask and\nChrome. To give you a rough idea about the costs, the whole process cost me\n$97.86. Here's the breakdown: \n\n * $6.17 for step 14 (initial request)\n * $46.26 for step 16 (paying for the name)\n * $21.48 for step 18 (setting up the reverse record)\n * $23.95 for step 21 (adding custom records)\n\nObviously the majority of these costs are gas fees, you only pay ENS for step 16\nso it will vary for you depending on when you set up yours.\n\nHope this was helpful!","feature_image":null,"featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2021-04-25 14:28:01","created_by":"1","updated_at":"2021-04-25 16:35:49","updated_by":"1","published_at":"2021-04-25 16:11:36","published_by":"1","custom_excerpt":"This is a short tutorial on how to set up your own ENS domain name using MetaMask and Google Chrome.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"6085b705d3d3ed25945ea898","uuid":"ca6bcb60-de1b-496d-9f78-8f8ce45e0665","title":"Projects","slug":"projects","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[[\"a\",[\"href\",\"https://github.com/fabioberger/curated_spaces\"]],[\"a\",[\"href\",\"https://curated-spaces-fabioberger.vercel.app/\"]],[\"a\",[\"href\",\"https://github.com/rmeinl/podcast_search\"]],[\"a\",[\"href\",\"https://share.streamlit.io/rmeinl/podcast_search/app.py\"]],[\"a\",[\"href\",\"https://chrome.google.com/webstore/detail/scify/kedfefpmgjcfidhnabfodadhnlabpili\"]],[\"a\",[\"href\",\"https://github.com/rmeinlsainsburys/instacart2vec\"]],[\"a\",[\"href\",\"https://github.com/rmeinl/capsule_networks\"]],[\"a\",[\"href\",\"https://github.com/rmeinl/MLND_Capstone\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Curated Spaces,  a community for NFT token holders (On Deck Global Build Weekend \"],[0,[0],1,\"Github\"],[0,[],0,\" \"],[0,[1],1,\"Demo\"]]],[1,\"p\",[[0,[],0,\"Semantic Podcast Search (using Lex Fridman's AI podcast) - \"],[0,[2],1,\"Github\"],[0,[],0,\" \"],[0,[3],1,\"Demo\"]]],[1,\"p\",[[0,[],0,\"Import Twitter Threads into Roam Research (Chrome Extension) - \"],[0,[4],1,\"Link\"]]],[1,\"p\",[[0,[],0,\"Word2Vec for Grocery Recommendations (Bachelor Thesis) - \"],[0,[5],1,\"Github\"]]],[1,\"p\",[[0,[],0,\"Survey of Capsule Networks (Paper) - \"],[0,[6],1,\"Github\"]]],[1,\"p\",[[0,[],0,\"Traffic Light Detection with YOLOv2 - \"],[0,[7],1,\"Github\"]]]],\"ghostVersion\":\"4.0\"}","html":"<p>Curated Spaces,  a community for NFT token holders (On Deck Global Build Weekend <a href=\"https://github.com/fabioberger/curated_spaces\">Github</a> <a href=\"https://curated-spaces-fabioberger.vercel.app/\">Demo</a></p><p>Semantic Podcast Search (using Lex Fridman's AI podcast) - <a href=\"https://github.com/rmeinl/podcast_search\">Github</a> <a href=\"https://share.streamlit.io/rmeinl/podcast_search/app.py\">Demo</a></p><p>Import Twitter Threads into Roam Research (Chrome Extension) - <a href=\"https://chrome.google.com/webstore/detail/scify/kedfefpmgjcfidhnabfodadhnlabpili\">Link</a></p><p>Word2Vec for Grocery Recommendations (Bachelor Thesis) - <a href=\"https://github.com/rmeinlsainsburys/instacart2vec\">Github</a></p><p>Survey of Capsule Networks (Paper) - <a href=\"https://github.com/rmeinl/capsule_networks\">Github</a></p><p>Traffic Light Detection with YOLOv2 - <a href=\"https://github.com/rmeinl/MLND_Capstone\">Github</a></p>","comment_id":"6085b705d3d3ed25945ea898","plaintext":"Curated Spaces,  a community for NFT token holders (On Deck Global Build Weekend \nGithub [https://github.com/fabioberger/curated_spaces] Demo\n[https://curated-spaces-fabioberger.vercel.app/]\n\nSemantic Podcast Search (using Lex Fridman's AI podcast) - Github\n[https://github.com/rmeinl/podcast_search] Demo\n[https://share.streamlit.io/rmeinl/podcast_search/app.py]\n\nImport Twitter Threads into Roam Research (Chrome Extension) - Link\n[https://chrome.google.com/webstore/detail/scify/kedfefpmgjcfidhnabfodadhnlabpili]\n\nWord2Vec for Grocery Recommendations (Bachelor Thesis) - Github\n[https://github.com/rmeinlsainsburys/instacart2vec]\n\nSurvey of Capsule Networks (Paper) - Github\n[https://github.com/rmeinl/capsule_networks]\n\nTraffic Light Detection with YOLOv2 - Github\n[https://github.com/rmeinl/MLND_Capstone]","feature_image":null,"featured":0,"type":"page","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2021-04-25 18:37:57","created_by":"1","updated_at":"2021-04-25 18:38:26","updated_by":"1","published_at":"2021-04-25 18:38:26","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"6085b75ad3d3ed25945ea89e","uuid":"c790c060-4dca-4dbe-bcc6-e92234b07d34","title":"Recommended","slug":"recommended","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[[\"a\",[\"href\",\"https://www.amazon.co.uk/Fooled-Randomness-Hidden-Chance-Markets/dp/0141031484\"]],[\"a\",[\"href\",\"https://www.amazon.co.uk/Black-Swan-Impact-Highly-Improbable/dp/0141034599\"]],[\"a\",[\"href\",\"https://www.amazon.co.uk/Skin-Game-Hidden-Asymmetries-Daily/dp/0141982659/\"]],[\"a\",[\"href\",\"https://www.amazon.co.uk/Stories-Your-Life-Others-Chiang/dp/1447289234\"]],[\"a\",[\"href\",\"https://www.amazon.co.uk/Golden-Compass-His-Dark-Materials/dp/1101934662\"]],[\"a\",[\"href\",\"https://www.amazon.co.uk/Zero-One-Notes-Start-Future/dp/0753555204\"]],[\"a\",[\"href\",\"https://www.nand2tetris.org/\"]],[\"a\",[\"href\",\"https://cryptozombies.io/\"]],[\"a\",[\"href\",\"https://github.com/jimmysong/programmingbitcoin\"]],[\"a\",[\"href\",\"https://mitpress.mit.edu/books/little-schemer-fourth-edition\"]],[\"a\",[\"href\",\"https://mitpress.mit.edu/books/reasoned-schemer\"]],[\"a\",[\"href\",\"https://rustwasm.github.io/book/introduction.html\"]],[\"a\",[\"href\",\"https://www.edx.org/course/introduction-to-biology-the-secret-of-life\"]],[\"a\",[\"href\",\"https://www.coursera.org/learn/machine-learning\"]],[\"a\",[\"href\",\"https://www.coursera.org/specializations/probabilistic-graphical-models\"]],[\"a\",[\"href\",\"https://meltingasphalt.com/crony-beliefs/\"]],[\"a\",[\"href\",\"http://www.paulgraham.com/lesson.html\"]],[\"a\",[\"href\",\"http://www.paulgraham.com/relres.html\"]],[\"a\",[\"href\",\"https://apenwarr.ca/log/20201227\"]],[\"a\",[\"href\",\"https://dreamsongs.com/WorseIsBetter.html\"]],[\"a\",[\"href\",\"https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/\"]],[\"a\",[\"href\",\"https://www.listennotes.com/listen/listened-KX-5xzMF_W6/?display=episode\"]],[\"a\",[\"href\",\"https://ericweinstein.org/\"]],[\"a\",[\"href\",\"https://open.spotify.com/episode/2CUxZLRujETtjxaVDvl0xv?si=BD5T9RgDSh6qi--QhSRiQg\"]],[\"a\",[\"href\",\"https://open.spotify.com/episode/732wSQDBZnIqZ0J63nYFsk?si=o0WxXFwhRDyzrz5guxPhYQ\"]],[\"a\",[\"href\",\"https://lexfridman.com/podcast/\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=krB0enBeSiE\"]],[\"a\",[\"href\",\"https://www.youtube.com/watch?v=ifX_JnBfxTY\"]],[\"a\",[\"href\",\"https://hiddenforces.io/\"]],[\"a\",[\"href\",\"https://open.spotify.com/episode/27ENHoo3ZNJAUTamDrBuWr?si=eef71803a8964905\"]]],\"sections\":[[1,\"h3\",[[0,[],0,\"Books\"]]],[1,\"p\",[[0,[0],1,\"Fooled by Randomness\"]]],[1,\"p\",[[0,[1],1,\"Black Swan\"]]],[1,\"p\",[[0,[2],1,\"Skin in the Game\"]]],[1,\"p\",[[0,[3],1,\"Ted Chiang - Stories of Your Life and others\"]]],[1,\"p\",[[0,[4],1,\"Philipp Pullman - The Golden Compass\"]]],[1,\"p\",[[0,[5],1,\"Zero to One\"]]],[1,\"p\",[]],[1,\"h3\",[[0,[],0,\"Programming\"]]],[1,\"p\",[[0,[6],1,\"NAND2Tetris\"],[0,[],0,\" - building a computer all the way up from NAND gates. Hands down one of the best tutorials to understand how computers work and trumps a lot of what university teaches you in CS classes\"]]],[1,\"p\",[[0,[7],1,\"Crypto Zombies\"],[0,[],0,\" - easy and fun intro to Ethereum, Solidity and Smart Contracts\"]]],[1,\"p\",[[0,[8],1,\"Programming Bitcoin\"]]],[1,\"p\",[[0,[9],1,\"The Little Schemer\"]]],[1,\"p\",[[0,[10],1,\"The Reasoned Schemer\"]]],[1,\"p\",[[0,[11],1,\"Rust and WebAssembly (building the Game of Life)\"]]],[1,\"p\",[]],[1,\"h3\",[[0,[],0,\"Courses\"]]],[1,\"p\",[[0,[12],1,\"Introduction to Biology - The Secret of Life\"]]],[1,\"p\",[[0,[13],1,\"Andrew Ng - Machine Learning\"]]],[1,\"p\",[[0,[14],1,\"Probabilistic Graphical Models\"]]],[1,\"p\",[]],[1,\"h3\",[[0,[],0,\"Essays\"]]],[1,\"p\",[[0,[15],1,\"Crony Beliefs\"]]],[1,\"p\",[[0,[16],1,\"PG - The Lesson to unlearn\"]]],[1,\"p\",[[0,[17],1,\"PG - Relentlessly Resourceful\"]]],[1,\"p\",[[0,[18],1,\"Systems design explains the world\"]]],[1,\"p\",[[0,[19],1,\"Worse is better\"]]],[1,\"p\",[[0,[20],1,\"Things you should never do\"],[0,[],0,\" (rewrite code from scratch)\"]]],[1,\"p\",[]],[1,\"h3\",[[0,[],0,\"Podcasts\"]]],[1,\"p\",[[0,[21],1,\"Episodes I listened to\"]]],[1,\"p\",[[0,[22],1,\"Eric Weinstein - The Portal\"],[0,[],0,\" (Episodes with \"],[0,[23],1,\"Balaji\"],[0,[],0,\", \"],[0,[24],1,\"Peter Thiel\"],[0,[],0,\")\"]]],[1,\"p\",[[0,[25],1,\"Lex Fridman Podcast\"],[0,[],0,\" (Episodes with \"],[0,[26],1,\"Brendan Eich\"],[0,[],0,\", \"],[0,[27],1,\"Eric Weinstein\"],[0,[],0,\")\"]]],[1,\"p\",[[0,[28],1,\"Hidden Forces\"],[0,[],0,\" (Episode with \"],[0,[29],1,\"Balaji\"],[0,[],0,\")\"]]]],\"ghostVersion\":\"4.0\"}","html":"<h3 id=\"books\">Books</h3><p><a href=\"https://www.amazon.co.uk/Fooled-Randomness-Hidden-Chance-Markets/dp/0141031484\">Fooled by Randomness</a></p><p><a href=\"https://www.amazon.co.uk/Black-Swan-Impact-Highly-Improbable/dp/0141034599\">Black Swan</a></p><p><a href=\"https://www.amazon.co.uk/Skin-Game-Hidden-Asymmetries-Daily/dp/0141982659/\">Skin in the Game</a></p><p><a href=\"https://www.amazon.co.uk/Stories-Your-Life-Others-Chiang/dp/1447289234\">Ted Chiang - Stories of Your Life and others</a></p><p><a href=\"https://www.amazon.co.uk/Golden-Compass-His-Dark-Materials/dp/1101934662\">Philipp Pullman - The Golden Compass</a></p><p><a href=\"https://www.amazon.co.uk/Zero-One-Notes-Start-Future/dp/0753555204\">Zero to One</a></p><p></p><h3 id=\"programming\">Programming</h3><p><a href=\"https://www.nand2tetris.org/\">NAND2Tetris</a> - building a computer all the way up from NAND gates. Hands down one of the best tutorials to understand how computers work and trumps a lot of what university teaches you in CS classes</p><p><a href=\"https://cryptozombies.io/\">Crypto Zombies</a> - easy and fun intro to Ethereum, Solidity and Smart Contracts</p><p><a href=\"https://github.com/jimmysong/programmingbitcoin\">Programming Bitcoin</a></p><p><a href=\"https://mitpress.mit.edu/books/little-schemer-fourth-edition\">The Little Schemer</a></p><p><a href=\"https://mitpress.mit.edu/books/reasoned-schemer\">The Reasoned Schemer</a></p><p><a href=\"https://rustwasm.github.io/book/introduction.html\">Rust and WebAssembly (building the Game of Life)</a></p><p></p><h3 id=\"courses\">Courses</h3><p><a href=\"https://www.edx.org/course/introduction-to-biology-the-secret-of-life\">Introduction to Biology - The Secret of Life</a></p><p><a href=\"https://www.coursera.org/learn/machine-learning\">Andrew Ng - Machine Learning</a></p><p><a href=\"https://www.coursera.org/specializations/probabilistic-graphical-models\">Probabilistic Graphical Models</a></p><p></p><h3 id=\"essays\">Essays</h3><p><a href=\"https://meltingasphalt.com/crony-beliefs/\">Crony Beliefs</a></p><p><a href=\"http://www.paulgraham.com/lesson.html\">PG - The Lesson to unlearn</a></p><p><a href=\"http://www.paulgraham.com/relres.html\">PG - Relentlessly Resourceful</a></p><p><a href=\"https://apenwarr.ca/log/20201227\">Systems design explains the world</a></p><p><a href=\"https://dreamsongs.com/WorseIsBetter.html\">Worse is better</a></p><p><a href=\"https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/\">Things you should never do</a> (rewrite code from scratch)</p><p></p><h3 id=\"podcasts\">Podcasts</h3><p><a href=\"https://www.listennotes.com/listen/listened-KX-5xzMF_W6/?display=episode\">Episodes I listened to</a></p><p><a href=\"https://ericweinstein.org/\">Eric Weinstein - The Portal</a> (Episodes with <a href=\"https://open.spotify.com/episode/2CUxZLRujETtjxaVDvl0xv?si=BD5T9RgDSh6qi--QhSRiQg\">Balaji</a>, <a href=\"https://open.spotify.com/episode/732wSQDBZnIqZ0J63nYFsk?si=o0WxXFwhRDyzrz5guxPhYQ\">Peter Thiel</a>)</p><p><a href=\"https://lexfridman.com/podcast/\">Lex Fridman Podcast</a> (Episodes with <a href=\"https://www.youtube.com/watch?v=krB0enBeSiE\">Brendan Eich</a>, <a href=\"https://www.youtube.com/watch?v=ifX_JnBfxTY\">Eric Weinstein</a>)</p><p><a href=\"https://hiddenforces.io/\">Hidden Forces</a> (Episode with <a href=\"https://open.spotify.com/episode/27ENHoo3ZNJAUTamDrBuWr?si=eef71803a8964905\">Balaji</a>)</p>","comment_id":"6085b75ad3d3ed25945ea89e","plaintext":"Books\nFooled by Randomness\n[https://www.amazon.co.uk/Fooled-Randomness-Hidden-Chance-Markets/dp/0141031484]\n\nBlack Swan\n[https://www.amazon.co.uk/Black-Swan-Impact-Highly-Improbable/dp/0141034599]\n\nSkin in the Game\n[https://www.amazon.co.uk/Skin-Game-Hidden-Asymmetries-Daily/dp/0141982659/]\n\nTed Chiang - Stories of Your Life and others\n[https://www.amazon.co.uk/Stories-Your-Life-Others-Chiang/dp/1447289234]\n\nPhilipp Pullman - The Golden Compass\n[https://www.amazon.co.uk/Golden-Compass-His-Dark-Materials/dp/1101934662]\n\nZero to One [https://www.amazon.co.uk/Zero-One-Notes-Start-Future/dp/0753555204]\n\n\n\nProgramming\nNAND2Tetris [https://www.nand2tetris.org/] - building a computer all the way up\nfrom NAND gates. Hands down one of the best tutorials to understand how\ncomputers work and trumps a lot of what university teaches you in CS classes\n\nCrypto Zombies [https://cryptozombies.io/] - easy and fun intro to Ethereum,\nSolidity and Smart Contracts\n\nProgramming Bitcoin [https://github.com/jimmysong/programmingbitcoin]\n\nThe Little Schemer\n[https://mitpress.mit.edu/books/little-schemer-fourth-edition]\n\nThe Reasoned Schemer [https://mitpress.mit.edu/books/reasoned-schemer]\n\nRust and WebAssembly (building the Game of Life)\n[https://rustwasm.github.io/book/introduction.html]\n\n\n\nCourses\nIntroduction to Biology - The Secret of Life\n[https://www.edx.org/course/introduction-to-biology-the-secret-of-life]\n\nAndrew Ng - Machine Learning [https://www.coursera.org/learn/machine-learning]\n\nProbabilistic Graphical Models\n[https://www.coursera.org/specializations/probabilistic-graphical-models]\n\n\n\nEssays\nCrony Beliefs [https://meltingasphalt.com/crony-beliefs/]\n\nPG - The Lesson to unlearn [http://www.paulgraham.com/lesson.html]\n\nPG - Relentlessly Resourceful [http://www.paulgraham.com/relres.html]\n\nSystems design explains the world [https://apenwarr.ca/log/20201227]\n\nWorse is better [https://dreamsongs.com/WorseIsBetter.html]\n\nThings you should never do\n[https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/] \n(rewrite code from scratch)\n\n\n\nPodcasts\nEpisodes I listened to\n[https://www.listennotes.com/listen/listened-KX-5xzMF_W6/?display=episode]\n\nEric Weinstein - The Portal [https://ericweinstein.org/] (Episodes with Balaji\n[https://open.spotify.com/episode/2CUxZLRujETtjxaVDvl0xv?si=BD5T9RgDSh6qi--QhSRiQg]\n, Peter Thiel\n[https://open.spotify.com/episode/732wSQDBZnIqZ0J63nYFsk?si=o0WxXFwhRDyzrz5guxPhYQ]\n)\n\nLex Fridman Podcast [https://lexfridman.com/podcast/] (Episodes with Brendan\nEich [https://www.youtube.com/watch?v=krB0enBeSiE], Eric Weinstein\n[https://www.youtube.com/watch?v=ifX_JnBfxTY])\n\nHidden Forces [https://hiddenforces.io/] (Episode with Balaji\n[https://open.spotify.com/episode/27ENHoo3ZNJAUTamDrBuWr?si=eef71803a8964905])","feature_image":null,"featured":0,"type":"page","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2021-04-25 18:39:22","created_by":"1","updated_at":"2021-04-25 18:39:31","updated_by":"1","published_at":"2021-04-25 18:39:31","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"6085b774d3d3ed25945ea8a5","uuid":"bf6ca38e-8e0e-4f28-a69e-2237672967e0","title":"About me","slug":"about-me","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[[\"hr\",{}]],\"markups\":[[\"a\",[\"href\",\"https://ricomeinl.com/the-world-doesnt-care-lessons-from-startup-failure/\"]],[\"a\",[\"href\",\"https://joinef.com/\"]],[\"a\",[\"href\",\"https://share.streamlit.io/rmeinl/podcast_search/app.py\"]],[\"a\",[\"href\",\"https://chrome.google.com/webstore/detail/scify/kedfefpmgjcfidhnabfodadhnlabpili\"]],[\"a\",[\"href\",\"https://ricomeinl.com/recommender-systems-the-most-valuable-application-of-machine-learning-part-1/\"]],[\"a\",[\"href\",\"https://ricomeinl.com/machine-learning-system-design/\"]],[\"a\",[\"href\",\"https://www.meetup.com/meetupai-hamburg/\"]],[\"a\",[\"href\",\"https://www.meetup.com/meetupai-Berlin/\"]],[\"a\",[\"href\",\"https://ricomeinl.com/books/\"]],[\"a\",[\"href\",\"https://twitter.com/rmeinl\"]],[\"a\",[\"href\",\"https://github.com/rmeinl\"]],[\"a\",[\"href\",\"https://www.linkedin.com/in/ricomeinl/\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"I have a Computer Science background, specialised in Machine Learning and Computer Vision. \"]]],[1,\"p\",[[0,[],0,\"I previously co-founded a fashion-tech startup (Dresswell) where we built a phone body measurement system (1.5-3mm inaccuracy) using ML and Computer Vision \"],[0,[0],1,\"(lessons learned here)\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"Most recently I participated in the \"],[0,[1],1,\"Entrepreneur First\"],[0,[],0,\" cohort in London where I worked on scientific search, semantic \"],[0,[2],1,\"podcast search\"],[0,[],0,\", and a \"],[0,[3],1,\"small chrome extension\"],[0,[],0,\". \"]]],[1,\"p\",[[0,[],0,\"I’ve been \"],[0,[4],1,\"active\"],[0,[],0,\" \"],[0,[5],1,\"in\"],[0,[],0,\" the ML community for the past 3 years and founded Meetup.ai in \"],[0,[6],1,\"Hamburg\"],[0,[],0,\" and \"],[0,[7],1,\"Berlin\"],[0,[],0,\" which I grew into two of Germany’s biggest AI Meetups with over 2000 and 3000 members respectively.\"]]],[1,\"p\",[[0,[],0,\"Some books I liked: \"],[0,[8],1,\"https://ricomeinl.com/books/\"]]],[1,\"p\",[[0,[],0,\"Some of my better writings:\"]]],[3,\"ul\",[[[0,[4],1,\"Recommender Systems: The Most Valuable Application of Machine Learning (Part 1)\"]],[[0,[5],1,\"Machine Learning System Design\"]],[[0,[0],1,\"The World Doesn't Care - Lessons From Startup Failure\"]]]],[10,0],[1,\"p\",[[0,[],0,\"Twitter: \"],[0,[9],1,\"@rmeinl\"],[1,[],0,0],[0,[],0,\"Github: \"],[0,[10],1,\"@rmeinl\"],[1,[],0,1],[0,[],0,\"LinkedIn: \"],[0,[11],1,\"linkedin.com/in/ricomeinl\"],[1,[],0,2],[0,[],0,\"Chess.com and Lichess: @rmeinl\"]]]],\"ghostVersion\":\"4.0\"}","html":"<p>I have a Computer Science background, specialised in Machine Learning and Computer Vision. </p><p>I previously co-founded a fashion-tech startup (Dresswell) where we built a phone body measurement system (1.5-3mm inaccuracy) using ML and Computer Vision <a href=\"https://ricomeinl.com/the-world-doesnt-care-lessons-from-startup-failure/\">(lessons learned here)</a>. </p><p>Most recently I participated in the <a href=\"https://joinef.com/\">Entrepreneur First</a> cohort in London where I worked on scientific search, semantic <a href=\"https://share.streamlit.io/rmeinl/podcast_search/app.py\">podcast search</a>, and a <a href=\"https://chrome.google.com/webstore/detail/scify/kedfefpmgjcfidhnabfodadhnlabpili\">small chrome extension</a>. </p><p>I’ve been <a href=\"https://ricomeinl.com/recommender-systems-the-most-valuable-application-of-machine-learning-part-1/\">active</a> <a href=\"https://ricomeinl.com/machine-learning-system-design/\">in</a> the ML community for the past 3 years and founded Meetup.ai in <a href=\"https://www.meetup.com/meetupai-hamburg/\">Hamburg</a> and <a href=\"https://www.meetup.com/meetupai-Berlin/\">Berlin</a> which I grew into two of Germany’s biggest AI Meetups with over 2000 and 3000 members respectively.</p><p>Some books I liked: <a href=\"https://ricomeinl.com/books/\">https://ricomeinl.com/books/</a></p><p>Some of my better writings:</p><ul><li><a href=\"https://ricomeinl.com/recommender-systems-the-most-valuable-application-of-machine-learning-part-1/\">Recommender Systems: The Most Valuable Application of Machine Learning (Part 1)</a></li><li><a href=\"https://ricomeinl.com/machine-learning-system-design/\">Machine Learning System Design</a></li><li><a href=\"https://ricomeinl.com/the-world-doesnt-care-lessons-from-startup-failure/\">The World Doesn't Care - Lessons From Startup Failure</a></li></ul><hr><p>Twitter: <a href=\"https://twitter.com/rmeinl\">@rmeinl</a><br>Github: <a href=\"https://github.com/rmeinl\">@rmeinl</a><br>LinkedIn: <a href=\"https://www.linkedin.com/in/ricomeinl/\">linkedin.com/in/ricomeinl</a><br>Chess.com and Lichess: @rmeinl</p>","comment_id":"6085b774d3d3ed25945ea8a5","plaintext":"I have a Computer Science background, specialised in Machine Learning and\nComputer Vision. \n\nI previously co-founded a fashion-tech startup (Dresswell) where we built a\nphone body measurement system (1.5-3mm inaccuracy) using ML and Computer Vision \n(lessons learned here)\n[https://ricomeinl.com/the-world-doesnt-care-lessons-from-startup-failure/]. \n\nMost recently I participated in the Entrepreneur First [https://joinef.com/] \ncohort in London where I worked on scientific search, semantic podcast search\n[https://share.streamlit.io/rmeinl/podcast_search/app.py], and a small chrome\nextension\n[https://chrome.google.com/webstore/detail/scify/kedfefpmgjcfidhnabfodadhnlabpili]\n. \n\nI’ve been active\n[https://ricomeinl.com/recommender-systems-the-most-valuable-application-of-machine-learning-part-1/] \n in [https://ricomeinl.com/machine-learning-system-design/] the ML community for\nthe past 3 years and founded Meetup.ai in Hamburg\n[https://www.meetup.com/meetupai-hamburg/] and Berlin\n[https://www.meetup.com/meetupai-Berlin/] which I grew into two of Germany’s\nbiggest AI Meetups with over 2000 and 3000 members respectively.\n\nSome books I liked: https://ricomeinl.com/books/\n\nSome of my better writings:\n\n * Recommender Systems: The Most Valuable Application of Machine Learning (Part\n   1)\n   [https://ricomeinl.com/recommender-systems-the-most-valuable-application-of-machine-learning-part-1/]\n * Machine Learning System Design\n   [https://ricomeinl.com/machine-learning-system-design/]\n * The World Doesn't Care - Lessons From Startup Failure\n   [https://ricomeinl.com/the-world-doesnt-care-lessons-from-startup-failure/]\n\n\n--------------------------------------------------------------------------------\n\nTwitter: @rmeinl [https://twitter.com/rmeinl]\nGithub: @rmeinl [https://github.com/rmeinl]\nLinkedIn: linkedin.com/in/ricomeinl [https://www.linkedin.com/in/ricomeinl/]\nChess.com and Lichess: @rmeinl","feature_image":null,"featured":0,"type":"page","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2021-04-25 18:39:48","created_by":"1","updated_at":"2021-04-25 18:40:11","updated_by":"1","published_at":"2021-04-25 18:40:11","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"60dccf53c0c8a524b4391a1f","uuid":"6b192555-d796-4020-87f4-420b6f133c2c","title":"Awesome Open-Source Bio/Cheminformatics","slug":"open-source-bio-chem-informatics","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}],[\"soft-return\",\"\",{}]],\"cards\":[],\"markups\":[[\"a\",[\"href\",\"http://vina.scripps.edu/\"]],[\"a\",[\"href\",\"http://en.wikipedia.org/wiki/Docking_(molecular)\"]],[\"a\",[\"href\",\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041641/\"]],[\"a\",[\"href\",\"https://github.com/mwojcikowski/smina\"]],[\"a\",[\"href\",\"https://qvina.github.io/\"]],[\"a\",[\"href\",\"https://github.com/gnina/gnina\"]],[\"a\",[\"href\",\"https://github.com/ccsb-scripps/AutoDock-GPU\"]],[\"a\",[\"href\",\"https://doi.org/10.1021/acs.jctc.0c01006\",\"rel\",\"nofollow\"]],[\"a\",[\"href\",\"https://virtual-flow.org/\"]],[\"a\",[\"href\",\"https://github.com/VirtualFlow/VFVS\"]],[\"a\",[\"href\",\"https://doi.org/10.1038/s41586-020-2117-z\"]],[\"a\",[\"href\",\"https://durrantlab.pitt.edu/gypsum-dl/\"]],[\"a\",[\"href\",\"https://git.durrantlab.pitt.edu/jdurrant/gypsum_dl\"]],[\"a\",[\"href\",\"https://doi.org/10.1186/s13321-019-0358-3\"]],[\"a\",[\"href\",\"http://drugdesign.unistra.fr/LIT-PCBA/\"]],[\"a\",[\"href\",\"http://drugdesign.unistra.fr/LIT-PCBA/Files/LIT-PCBA_bioactivities.xlsx\"]],[\"a\",[\"href\",\"https://doi.org/10.1021/acs.jcim.0c00155\"]],[\"a\",[\"href\",\"https://apricot-select.readthedocs.io/en/latest/index.html\"]],[\"a\",[\"href\",\"https://apricot-select.readthedocs.io/en/latest/index.html\",\"rel\",\"nofollow\"]],[\"a\",[\"href\",\"https://github.com/jmschrei/apricot\"]],[\"a\",[\"href\",\"https://jmlr.org/papers/volume21/19-467/19-467.pdf\"]],[\"a\",[\"href\",\"https://github.com/coleygroup/molpal\"]],[\"a\",[\"href\",\"https://arxiv.org/abs/2012.07127\"]],[\"a\",[\"href\",\"https://github.com/coleygroup/pyscreener\"]],[\"strong\"],[\"a\",[\"href\",\"https://doi.org/10.1093/bib/bbv037\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"A (growing) list of open-source Bio/Cheminformatics tools that I found useful in my work. If you know other tools in this realm that I should check out, please reach out.\"]]],[1,\"h3\",[[0,[0],1,\"Autodock Vina\"]]],[1,\"p\",[[0,[],0,\"#molecular-docking\"]]],[3,\"ul\",[[[0,[],0,\"Open-source program for doing \"],[0,[1],1,\"molecular docking\"],[0,[],0,\".\"]]]],[1,\"p\",[[0,[],0,\"Publication: \"],[0,[2],1,\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041641/\"]]],[1,\"p\",[[0,[],0,\"Forks:\"]]],[3,\"ul\",[[[0,[3],1,\"smina\"],[0,[],0,\" is a fork of AutoDock Vina that focuses on improving scoring and minimization\"]],[[0,[4],1,\"QuickVina\"],[0,[],0,\" - fast and accurate molecular docking tool, attained at accurately accelerating AutoDock Vina\"]],[[0,[5],1,\"Gnina\"],[0,[],0,\" - molecular docking program with integrated support for scoring and optimizing ligands using convolutional neural networks. It is a fork of smina, which is a fork of AutoDock Vina\"]]]],[1,\"h3\",[[0,[6],1,\"Autodock GPU\"]]],[1,\"p\",[[0,[],0,\"#molecular-docking\"]]],[3,\"ul\",[[[0,[],0,\"OpenCL and Cuda accelerated version of AutoDock4.2.6. It leverages its embarrasingly parallelizable LGA by processing ligand-receptor poses in parallel over multiple compute units.\"]]]],[1,\"p\",[[0,[],0,\"Github: \"],[0,[6],1,\"https://github.com/ccsb-scripps/AutoDock-GPU\"],[1,[],0,0],[0,[],0,\"Publication: Accelerating AutoDock4 with GPUs and Gradient-Based Local Search, \"],[0,[7],1,\"J. Chem. Theory Comput. 2021, 10.1021/acs.jctc.0c01006\"]]],[1,\"h3\",[[0,[8],1,\"VirtualFlow\"]]],[1,\"p\",[[0,[],0,\"#virtual-screening\"]]],[3,\"ul\",[[[0,[],0,\"VirtualFlow is a versatile, parallel workflow platform for carrying out virtual screening related tasks on Linux-based computer clusters of any type and size which are managed by a batchsystem (such as SLURM).\"]]]],[1,\"p\",[[0,[],0,\"Github: \"],[0,[9],1,\"https://github.com/VirtualFlow/VFVS\"],[1,[],0,1],[0,[],0,\"Publication: An open-source drug discovery platform enables ultra-large virtual screens. Nature 580, 663–668 (2020). \"],[0,[10],1,\"https://doi.org/10.1038/s41586-020-2117-z\"]]],[1,\"h3\",[[0,[11],1,\"Gypsum-DL\"]]],[1,\"p\",[[0,[],0,\"#ligand-preparation\"]]],[3,\"ul\",[[[0,[],0,\"Gypsum-DL is a free, open-source program for preparing 3D small-molecule models. Beyond simply assigning atomic coordinates, Gypsum-DL accounts for alternate ionization, tautomeric, chiral, cis/trans isomeric, and ring-conformational forms.\"]]]],[1,\"p\",[[0,[],0,\"Gitlab: \"],[0,[12],1,\"https://git.durrantlab.pitt.edu/jdurrant/gypsum_dl\"],[1,[],0,2],[0,[],0,\"Publication: \\\"Gypsum-DL: An Open-source Program for Preparing Small-molecule Libraries for Structure-based Virtual Screening.\\\" Journal of Cheminformatics 11:1. \"],[0,[13],1,\"doi:10.1186/s13321-019-0358-3\"]]],[1,\"h3\",[[0,[14],1,\"LIT-PCBA\"]]],[1,\"p\",[[0,[],0,\"#dataset\"]]],[3,\"ul\",[[[0,[],0,\"15 target sets, 9780 actives and 407839 unique inactives selected from high-confidence \"],[0,[15],1,\"PubChem Bioassay data\"]]]],[1,\"p\",[[0,[],0,\"Data: \"],[0,[14],1,\"http://drugdesign.unistra.fr/LIT-PCBA/\"],[1,[],0,3],[0,[],0,\"Publication: LIT-PCBA: An Unbiased Data Set for Machine Learning and Virtual Screening. \"],[0,[16],1,\"https://doi.org/10.1021/acs.jcim.0c00155\"]]],[1,\"h3\",[[0,[17],1,\"Apricot\"]]],[1,\"p\",[[0,[],0,\"#submodular-optimization\"]]],[3,\"ul\",[[[0,[],0,\"apricot implements submodular optimization for the purpose of selecting subsets of massive data sets to train machine learning models quickly. See the documentation page: \"],[0,[18],1,\"https://apricot-select.readthedocs.io/en/latest/index.html\"]]]],[1,\"p\",[[0,[],0,\"Github: \"],[0,[19],1,\"https://github.com/jmschrei/apricot\"],[1,[],0,4],[0,[],0,\"Publication: \"],[0,[20],1,\"https://jmlr.org/papers/volume21/19-467/19-467.pdf\"]]],[1,\"h3\",[[0,[21],1,\"MolPal\"]]],[1,\"p\",[[0,[],0,\"#active-learning\"]]],[3,\"ul\",[[[0,[],0,\"Accelerating high-throughput virtual screening through molecular pool-based active learning.\"]]]],[1,\"p\",[[0,[],0,\"Github: \"],[0,[21],1,\"https://github.com/coleygroup/molpal\"],[1,[],0,5],[0,[],0,\"Publication: \"],[0,[22],1,\"https://arxiv.org/abs/2012.07127\"]]],[1,\"h3\",[[0,[23],1,\"PyScreener\"]]],[1,\"p\",[[0,[],0,\"#virtual-screening\"]]],[3,\"ul\",[[[0,[],0,\"A pythonic interface to high-throughput virtual screening software.\"]]]],[1,\"p\",[[0,[],0,\"Github: \"],[0,[23],1,\"https://github.com/coleygroup/pyscreener\"]]],[1,\"h3\",[[0,[],0,\"Other Resources\"]]],[3,\"ul\",[[[0,[],0,\"Building a virtual ligand screening pipeline using free software: a survey.\"],[0,[24],1,\" \"],[0,[25],1,\"https://doi.org/10.1093/bib/bbv037\"]]]]],\"ghostVersion\":\"4.0\"}","html":"<p>A (growing) list of open-source Bio/Cheminformatics tools that I found useful in my work. If you know other tools in this realm that I should check out, please reach out.</p><h3 id=\"autodock-vina\"><a href=\"http://vina.scripps.edu/\">Autodock Vina</a></h3><p>#molecular-docking</p><ul><li>Open-source program for doing <a href=\"http://en.wikipedia.org/wiki/Docking_(molecular)\">molecular docking</a>.</li></ul><p>Publication: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041641/\">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041641/</a></p><p>Forks:</p><ul><li><a href=\"https://github.com/mwojcikowski/smina\">smina</a> is a fork of AutoDock Vina that focuses on improving scoring and minimization</li><li><a href=\"https://qvina.github.io/\">QuickVina</a> - fast and accurate molecular docking tool, attained at accurately accelerating AutoDock Vina</li><li><a href=\"https://github.com/gnina/gnina\">Gnina</a> - molecular docking program with integrated support for scoring and optimizing ligands using convolutional neural networks. It is a fork of smina, which is a fork of AutoDock Vina</li></ul><h3 id=\"autodock-gpu\"><a href=\"https://github.com/ccsb-scripps/AutoDock-GPU\">Autodock GPU</a></h3><p>#molecular-docking</p><ul><li>OpenCL and Cuda accelerated version of AutoDock4.2.6. It leverages its embarrasingly parallelizable LGA by processing ligand-receptor poses in parallel over multiple compute units.</li></ul><p>Github: <a href=\"https://github.com/ccsb-scripps/AutoDock-GPU\">https://github.com/ccsb-scripps/AutoDock-GPU</a><br>Publication: Accelerating AutoDock4 with GPUs and Gradient-Based Local Search, <a href=\"https://doi.org/10.1021/acs.jctc.0c01006\" rel=\"nofollow\">J. Chem. Theory Comput. 2021, 10.1021/acs.jctc.0c01006</a></p><h3 id=\"virtualflow\"><a href=\"https://virtual-flow.org/\">VirtualFlow</a></h3><p>#virtual-screening</p><ul><li>VirtualFlow is a versatile, parallel workflow platform for carrying out virtual screening related tasks on Linux-based computer clusters of any type and size which are managed by a batchsystem (such as SLURM).</li></ul><p>Github: <a href=\"https://github.com/VirtualFlow/VFVS\">https://github.com/VirtualFlow/VFVS</a><br>Publication: An open-source drug discovery platform enables ultra-large virtual screens. Nature 580, 663–668 (2020). <a href=\"https://doi.org/10.1038/s41586-020-2117-z\">https://doi.org/10.1038/s41586-020-2117-z</a></p><h3 id=\"gypsum-dl\"><a href=\"https://durrantlab.pitt.edu/gypsum-dl/\">Gypsum-DL</a></h3><p>#ligand-preparation</p><ul><li>Gypsum-DL is a free, open-source program for preparing 3D small-molecule models. Beyond simply assigning atomic coordinates, Gypsum-DL accounts for alternate ionization, tautomeric, chiral, cis/trans isomeric, and ring-conformational forms.</li></ul><p>Gitlab: <a href=\"https://git.durrantlab.pitt.edu/jdurrant/gypsum_dl\">https://git.durrantlab.pitt.edu/jdurrant/gypsum_dl</a><br>Publication: \"Gypsum-DL: An Open-source Program for Preparing Small-molecule Libraries for Structure-based Virtual Screening.\" Journal of Cheminformatics 11:1. <a href=\"https://doi.org/10.1186/s13321-019-0358-3\">doi:10.1186/s13321-019-0358-3</a></p><h3 id=\"lit-pcba\"><a href=\"http://drugdesign.unistra.fr/LIT-PCBA/\">LIT-PCBA</a></h3><p>#dataset</p><ul><li>15 target sets, 9780 actives and 407839 unique inactives selected from high-confidence <a href=\"http://drugdesign.unistra.fr/LIT-PCBA/Files/LIT-PCBA_bioactivities.xlsx\">PubChem Bioassay data</a></li></ul><p>Data: <a href=\"http://drugdesign.unistra.fr/LIT-PCBA/\">http://drugdesign.unistra.fr/LIT-PCBA/</a><br>Publication: LIT-PCBA: An Unbiased Data Set for Machine Learning and Virtual Screening. <a href=\"https://doi.org/10.1021/acs.jcim.0c00155\">https://doi.org/10.1021/acs.jcim.0c00155</a></p><h3 id=\"apricot\"><a href=\"https://apricot-select.readthedocs.io/en/latest/index.html\">Apricot</a></h3><p>#submodular-optimization</p><ul><li>apricot implements submodular optimization for the purpose of selecting subsets of massive data sets to train machine learning models quickly. See the documentation page: <a href=\"https://apricot-select.readthedocs.io/en/latest/index.html\" rel=\"nofollow\">https://apricot-select.readthedocs.io/en/latest/index.html</a></li></ul><p>Github: <a href=\"https://github.com/jmschrei/apricot\">https://github.com/jmschrei/apricot</a><br>Publication: <a href=\"https://jmlr.org/papers/volume21/19-467/19-467.pdf\">https://jmlr.org/papers/volume21/19-467/19-467.pdf</a></p><h3 id=\"molpal\"><a href=\"https://github.com/coleygroup/molpal\">MolPal</a></h3><p>#active-learning</p><ul><li>Accelerating high-throughput virtual screening through molecular pool-based active learning.</li></ul><p>Github: <a href=\"https://github.com/coleygroup/molpal\">https://github.com/coleygroup/molpal</a><br>Publication: <a href=\"https://arxiv.org/abs/2012.07127\">https://arxiv.org/abs/2012.07127</a></p><h3 id=\"pyscreener\"><a href=\"https://github.com/coleygroup/pyscreener\">PyScreener</a></h3><p>#virtual-screening</p><ul><li>A pythonic interface to high-throughput virtual screening software.</li></ul><p>Github: <a href=\"https://github.com/coleygroup/pyscreener\">https://github.com/coleygroup/pyscreener</a></p><h3 id=\"other-resources\">Other Resources</h3><ul><li>Building a virtual ligand screening pipeline using free software: a survey.<strong> </strong><a href=\"https://doi.org/10.1093/bib/bbv037\">https://doi.org/10.1093/bib/bbv037</a></li></ul>","comment_id":"60dccf53c0c8a524b4391a1f","plaintext":"A (growing) list of open-source Bio/Cheminformatics tools that I found useful in\nmy work. If you know other tools in this realm that I should check out, please\nreach out.\n\nAutodock Vina [http://vina.scripps.edu/]\n#molecular-docking\n\n * Open-source program for doing molecular docking\n   [http://en.wikipedia.org/wiki/Docking_(molecular)].\n\nPublication: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3041641/\n\nForks:\n\n * smina [https://github.com/mwojcikowski/smina] is a fork of AutoDock Vina that\n   focuses on improving scoring and minimization\n * QuickVina [https://qvina.github.io/] - fast and accurate molecular docking\n   tool, attained at accurately accelerating AutoDock Vina\n * Gnina [https://github.com/gnina/gnina] - molecular docking program with\n   integrated support for scoring and optimizing ligands using convolutional\n   neural networks. It is a fork of smina, which is a fork of AutoDock Vina\n\nAutodock GPU [https://github.com/ccsb-scripps/AutoDock-GPU]\n#molecular-docking\n\n * OpenCL and Cuda accelerated version of AutoDock4.2.6. It leverages its\n   embarrasingly parallelizable LGA by processing ligand-receptor poses in\n   parallel over multiple compute units.\n\nGithub: https://github.com/ccsb-scripps/AutoDock-GPU\nPublication: Accelerating AutoDock4 with GPUs and Gradient-Based Local Search, \nJ. Chem. Theory Comput. 2021, 10.1021/acs.jctc.0c01006\n[https://doi.org/10.1021/acs.jctc.0c01006]\n\nVirtualFlow [https://virtual-flow.org/]\n#virtual-screening\n\n * VirtualFlow is a versatile, parallel workflow platform for carrying out\n   virtual screening related tasks on Linux-based computer clusters of any type\n   and size which are managed by a batchsystem (such as SLURM).\n\nGithub: https://github.com/VirtualFlow/VFVS\nPublication: An open-source drug discovery platform enables ultra-large virtual\nscreens. Nature 580, 663–668 (2020). https://doi.org/10.1038/s41586-020-2117-z\n\nGypsum-DL [https://durrantlab.pitt.edu/gypsum-dl/]\n#ligand-preparation\n\n * Gypsum-DL is a free, open-source program for preparing 3D small-molecule\n   models. Beyond simply assigning atomic coordinates, Gypsum-DL accounts for\n   alternate ionization, tautomeric, chiral, cis/trans isomeric, and\n   ring-conformational forms.\n\nGitlab: https://git.durrantlab.pitt.edu/jdurrant/gypsum_dl\nPublication: \"Gypsum-DL: An Open-source Program for Preparing Small-molecule\nLibraries for Structure-based Virtual Screening.\" Journal of Cheminformatics\n11:1. doi:10.1186/s13321-019-0358-3 [https://doi.org/10.1186/s13321-019-0358-3]\n\nLIT-PCBA [http://drugdesign.unistra.fr/LIT-PCBA/]\n#dataset\n\n * 15 target sets, 9780 actives and 407839 unique inactives selected from\n   high-confidence PubChem Bioassay data\n   [http://drugdesign.unistra.fr/LIT-PCBA/Files/LIT-PCBA_bioactivities.xlsx]\n\nData: http://drugdesign.unistra.fr/LIT-PCBA/\nPublication: LIT-PCBA: An Unbiased Data Set for Machine Learning and Virtual\nScreening. https://doi.org/10.1021/acs.jcim.0c00155\n\nApricot [https://apricot-select.readthedocs.io/en/latest/index.html]\n#submodular-optimization\n\n * apricot implements submodular optimization for the purpose of selecting\n   subsets of massive data sets to train machine learning models quickly. See\n   the documentation page: \n   https://apricot-select.readthedocs.io/en/latest/index.html\n\nGithub: https://github.com/jmschrei/apricot\nPublication: https://jmlr.org/papers/volume21/19-467/19-467.pdf\n\nMolPal [https://github.com/coleygroup/molpal]\n#active-learning\n\n * Accelerating high-throughput virtual screening through molecular pool-based\n   active learning.\n\nGithub: https://github.com/coleygroup/molpal\nPublication: https://arxiv.org/abs/2012.07127\n\nPyScreener [https://github.com/coleygroup/pyscreener]\n#virtual-screening\n\n * A pythonic interface to high-throughput virtual screening software.\n\nGithub: https://github.com/coleygroup/pyscreener\n\nOther Resources\n * Building a virtual ligand screening pipeline using free software: a survey. \n   https://doi.org/10.1093/bib/bbv037","feature_image":null,"featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2021-06-30 20:08:51","created_by":"1","updated_at":"2021-06-30 20:38:46","updated_by":"1","published_at":"2021-06-30 20:38:46","published_by":"1","custom_excerpt":"A (growing) list of open-source Bio/Cheminformatics tools that I found useful in my work. If you know other tools in this realm that I should check out, please reach out.","codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null},{"id":"61787503aeea2b2777d0cef5","uuid":"81d13597-adf6-48ae-bc2d-62205341bf6c","title":"Bioelectricity Resources","slug":"bioelectricity-resources","mobiledoc":"{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"hr\",{}],[\"hr\",{}],[\"hr\",{}]],\"markups\":[[\"a\",[\"href\",\"http://www.drmichaellevin.org/\"]],[\"a\",[\"href\",\"https://learning.edx.org/course/course-v1:HarvardX+MCB80.1x+2T2021/home\"]],[\"a\",[\"href\",\"https://www.ece.tufts.edu/ee/123/\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Bioelectricity\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Some bioelectricity resources I found useful while studying it:\"]]],[1,\"p\",[[0,[],0,\"The Levin Lab - \"],[0,[0],1,\"http://www.drmichaellevin.org/\"]]],[10,0],[1,\"p\",[[0,[],0,\"Fundamentals of Neuroscience Part 1: The Electrical Properties of the Neuron - \"],[0,[1],1,\"https://learning.edx.org/course/course-v1:HarvardX+MCB80.1x+2T2021/home\"]]],[3,\"ul\",[[[0,[],0,\"the more specific version of bioelectricity but super helpful to understand things like diffusion and drift as well as ion channels, nernst and membrane potentials and the GHK equation\"]]]],[10,1],[1,\"p\",[[0,[],0,\"EE123 Bioelectricity Course (Tufts) - \"],[0,[2],1,\"https://www.ece.tufts.edu/ee/123/\"]]],[3,\"ul\",[[[0,[],0,\"In depth course about bioelectricity from Tufts University with programming assignments\"]]]],[10,2],[1,\"p\",[[0,[],0,\"Bioelectricity Wikipedia Entry - \"],[0,[3],1,\"https://en.wikipedia.org/wiki/Bioelectricity\"]]],[3,\"ul\",[[[0,[],0,\"Great entry point for history, methods and applications\"]]]],[1,\"p\",[]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}","html":"<p>Some bioelectricity resources I found useful while studying it:</p><p>The Levin Lab - <a href=\"http://www.drmichaellevin.org/\">http://www.drmichaellevin.org/</a></p><hr><p>Fundamentals of Neuroscience Part 1: The Electrical Properties of the Neuron - <a href=\"https://learning.edx.org/course/course-v1:HarvardX+MCB80.1x+2T2021/home\">https://learning.edx.org/course/course-v1:HarvardX+MCB80.1x+2T2021/home</a></p><ul><li>the more specific version of bioelectricity but super helpful to understand things like diffusion and drift as well as ion channels, nernst and membrane potentials and the GHK equation</li></ul><hr><p>EE123 Bioelectricity Course (Tufts) - <a href=\"https://www.ece.tufts.edu/ee/123/\">https://www.ece.tufts.edu/ee/123/</a></p><ul><li>In depth course about bioelectricity from Tufts University with programming assignments</li></ul><hr><p>Bioelectricity Wikipedia Entry - <a href=\"https://en.wikipedia.org/wiki/Bioelectricity\">https://en.wikipedia.org/wiki/Bioelectricity</a></p><ul><li>Great entry point for history, methods and applications</li></ul><p></p>","comment_id":"61787503aeea2b2777d0cef5","plaintext":"Some bioelectricity resources I found useful while studying it:\n\nThe Levin Lab - http://www.drmichaellevin.org/\n\n\n--------------------------------------------------------------------------------\n\nFundamentals of Neuroscience Part 1: The Electrical Properties of the Neuron - \nhttps://learning.edx.org/course/course-v1:HarvardX+MCB80.1x+2T2021/home\n\n * the more specific version of bioelectricity but super helpful to understand\n   things like diffusion and drift as well as ion channels, nernst and membrane\n   potentials and the GHK equation\n\n\n--------------------------------------------------------------------------------\n\nEE123 Bioelectricity Course (Tufts) - https://www.ece.tufts.edu/ee/123/\n\n * In depth course about bioelectricity from Tufts University with programming\n   assignments\n\n\n--------------------------------------------------------------------------------\n\nBioelectricity Wikipedia Entry - https://en.wikipedia.org/wiki/Bioelectricity\n\n * Great entry point for history, methods and applications","feature_image":null,"featured":0,"type":"post","status":"published","locale":null,"visibility":"public","email_recipient_filter":"none","author_id":"1","created_at":"2021-10-26 21:37:07","created_by":"1","updated_at":"2021-10-26 21:42:16","updated_by":"1","published_at":"2021-10-26 21:42:16","published_by":"1","custom_excerpt":null,"codeinjection_head":null,"codeinjection_foot":null,"custom_template":null,"canonical_url":null}],"posts_meta":[],"users":[{"id":"1","name":"Rico Meinl","slug":"rico","password":"$2a$10$YzmqMcBlTgKy8xbMwoE6AemTi6evekVRNc0w6Xb5bBg9Nc/XeofKi","email":"dev@rmeinl.com","profile_image":null,"cover_image":null,"bio":"--- This website is a work in progress. ---\n\nTwitter: @rmeinl\nLinkedIn: https://www.linkedin.com/in/ricomeinl/\nMedium: https://medium.com/@ricomeinl ","website":"https://rmeinl.com","location":null,"facebook":null,"twitter":"@rmeinl","accessibility":null,"status":"active","locale":null,"visibility":"public","meta_title":null,"meta_description":null,"tour":null,"last_seen":"2021-10-26 21:36:42","created_at":"2021-04-25 13:54:30","created_by":"1","updated_at":"2021-10-26 21:36:42","updated_by":"1"}],"posts_authors":[{"id":"608577531830b521b5118fdb","post_id":"6085751174348916f1b089a9","author_id":"1","sort_order":0},{"id":"6085776a1830b521b5118fe0","post_id":"6085751174348916f1b089a8","author_id":"1","sort_order":0},{"id":"608577761830b521b5118fe3","post_id":"6085751174348916f1b089a7","author_id":"1","sort_order":0},{"id":"608577951830b521b5118fed","post_id":"6085751174348916f1b0899c","author_id":"1","sort_order":0},{"id":"6085779d1830b521b5118ff0","post_id":"6085751174348916f1b0899b","author_id":"1","sort_order":0},{"id":"608577a71830b521b5118ff6","post_id":"6085751174348916f1b0899d","author_id":"1","sort_order":0},{"id":"608577b41830b521b5118ff9","post_id":"6085751174348916f1b0899e","author_id":"1","sort_order":0},{"id":"608577bc1830b521b5118ffc","post_id":"6085751174348916f1b089a0","author_id":"1","sort_order":0},{"id":"608577ca1830b521b5119002","post_id":"6085751174348916f1b089a1","author_id":"1","sort_order":0},{"id":"608577d21830b521b5119005","post_id":"6085751174348916f1b089a2","author_id":"1","sort_order":0},{"id":"608577f21830b521b5119009","post_id":"6085751174348916f1b089a3","author_id":"1","sort_order":0},{"id":"60857c71d3d3ed25945ea736","post_id":"60857c71d3d3ed25945ea735","author_id":"1","sort_order":0},{"id":"6085b705d3d3ed25945ea899","post_id":"6085b705d3d3ed25945ea898","author_id":"1","sort_order":0},{"id":"6085b75ad3d3ed25945ea89f","post_id":"6085b75ad3d3ed25945ea89e","author_id":"1","sort_order":0},{"id":"6085b775d3d3ed25945ea8a6","post_id":"6085b774d3d3ed25945ea8a5","author_id":"1","sort_order":0},{"id":"60dccf53c0c8a524b4391a20","post_id":"60dccf53c0c8a524b4391a1f","author_id":"1","sort_order":0},{"id":"61787503aeea2b2777d0cef6","post_id":"61787503aeea2b2777d0cef5","author_id":"1","sort_order":0}],"roles":[{"id":"6085749674348916f1b087c7","name":"Administrator","description":"Administrators","created_at":"2021-04-25 13:54:30","created_by":"1","updated_at":"2021-04-25 13:54:30","updated_by":"1"},{"id":"6085749674348916f1b087c8","name":"Editor","description":"Editors","created_at":"2021-04-25 13:54:30","created_by":"1","updated_at":"2021-04-25 13:54:30","updated_by":"1"},{"id":"6085749674348916f1b087c9","name":"Author","description":"Authors","created_at":"2021-04-25 13:54:30","created_by":"1","updated_at":"2021-04-25 13:54:30","updated_by":"1"},{"id":"6085749674348916f1b087ca","name":"Contributor","description":"Contributors","created_at":"2021-04-25 13:54:30","created_by":"1","updated_at":"2021-04-25 13:54:30","updated_by":"1"},{"id":"6085749674348916f1b087cb","name":"Owner","description":"Blog Owner","created_at":"2021-04-25 13:54:30","created_by":"1","updated_at":"2021-04-25 13:54:30","updated_by":"1"},{"id":"6085749674348916f1b087cc","name":"Admin Integration","description":"External Apps","created_at":"2021-04-25 13:54:30","created_by":"1","updated_at":"2021-04-25 13:54:30","updated_by":"1"},{"id":"6085749674348916f1b087cd","name":"DB Backup Integration","description":"Internal DB Backup Client","created_at":"2021-04-25 13:54:30","created_by":"1","updated_at":"2021-04-25 13:54:30","updated_by":"1"},{"id":"6085749674348916f1b087ce","name":"Scheduler Integration","description":"Internal Scheduler Client","created_at":"2021-04-25 13:54:30","created_by":"1","updated_at":"2021-04-25 13:54:30","updated_by":"1"}],"roles_users":[{"id":"6085749774348916f1b0892c","role_id":"6085749674348916f1b087cb","user_id":"1"}],"settings":[{"id":"6085749774348916f1b0892d","group":"core","key":"db_hash","value":"22b03108-138e-463f-90b9-63020b0179a0","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749774348916f1b0892e","group":"core","key":"routes_hash","value":"0341d64ce65c175c75cbf1a121955434","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:33","updated_by":"1"},{"id":"6085749774348916f1b0892f","group":"core","key":"next_update_check","value":"1635370597","type":"number","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-10-26 21:36:37","updated_by":"1"},{"id":"6085749774348916f1b08930","group":"core","key":"notifications","value":"{\"isFulfilled\":false,\"isRejected\":true,\"rejectionReason\":{\"statusCode\":403,\"errorType\":\"NoPermissionError\",\"level\":\"normal\",\"message\":\"You do not have permission to dismiss this notification.\",\"id\":\"178c57e0-d9df-11eb-8475-e17e747e1091\",\"name\":\"NoPermissionError\",\"code\":null,\"property\":null,\"redirect\":null}}","type":"array","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-06-30 20:09:36","updated_by":"1"},{"id":"6085749774348916f1b08931","group":"core","key":"session_secret","value":"c90fe2d9eadd567320e1ed9bac85e83c753d015ae09837b864d6d5fb06cc2827","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749774348916f1b08932","group":"core","key":"theme_session_secret","value":"3fa4f48b4abe520ab4dcd5d5a5c09da991456e317769e6a0910760bd93644540","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749774348916f1b08933","group":"core","key":"ghost_public_key","value":"-----BEGIN RSA PUBLIC KEY-----\nMIGJAoGBALLGbRyrofnZ6z6NrzXPPkPpWXBbYUA/p/Px0zN8MUkTBtQSXbtyOqQt8QPD25na\ncLjPfUJ2wBpYMguIHwTdnAKh6hG2GhtUjmVPDLLaZadhXh3qJ42mM8vMlV41b/UHNVjNDjB3\nHVM3YmCDSrCO7wdiAdKHjeUMF0XNcjeKELnZAgMBAAE=\n-----END RSA PUBLIC KEY-----\n","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749774348916f1b08934","group":"core","key":"ghost_private_key","value":"-----BEGIN RSA PRIVATE KEY-----\nMIICXwIBAAKBgQCyxm0cq6H52es+ja81zz5D6VlwW2FAP6fz8dMzfDFJEwbUEl27cjqkLfED\nw9uZ2nC4z31CdsAaWDILiB8E3ZwCoeoRthobVI5lTwyy2mWnYV4d6ieNpjPLzJVeNW/1BzVY\nzQ4wdx1TN2Jgg0qwju8HYgHSh43lDBdFzXI3ihC52QIDAQABAoGBAJlu8cCUkaz1WhBS29hr\n6P2yLZ/f3aSdvZEBsIlUgpw75zVmGepBzJCSGXNoynXOY8ZJ1jCP6KnznegFyNGNPVIWg8js\n2KEioM4dAeIT7v9c9mhWzGugsBPFSFLqepbJ3VkNg5qfaaUL+w3HUxOgceAlyCt/Of452NdR\n1LNdXdoBAkEA9M4gB9i/z/zoSCE9uAyzsBLEkyIiFlTEsRlm4BSey2IoLo1/xR6Dq2HVRzGL\nyjaHTVGzIIN+n2l+uTEToqwmQQJBALrzTZL+pfxliYH4XWP9xfcc9vrMVcwDnloNIEmTWWGT\n7AM+cdPOX4WFQgZGSeoKHfbbYcu8soPJJhOTgn+4nZkCQQDZXXilXviZpdddzF4v4N9ftJpk\nhkc8CtKG6aYly0lgD2zcQPm1Pi3ta7XjPAQCbb5fke56LSeuRg6mQwRLSY3BAkEAiPbjqIPj\n+4wwOAZL9Yvg03BnCctWOEeWZgcj1oObgj+rM502K6UQmnPMsWghktOirE6B0ZAHgUGHIeR6\nQTRyUQJBAMwnMBlppx9/aqAc4knFzevGWP1k/dHllaj1rHTj2pZ3SQdMTg67avNAXzBb9JWE\nFRX+6SlWvZYFdq7659ImPrM=\n-----END RSA PRIVATE KEY-----\n","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b08935","group":"core","key":"members_public_key","value":"-----BEGIN RSA PUBLIC KEY-----\nMIGJAoGBAM2cRv1So/LToAqrkdY50rO/uHCfglBACyO5jSVnPqtTq4+rsHm81/3Y3lYEVfnT\nOAYu231vRe5iUHohjhqmO9OMGcMmVR955/3WDn3wzFC3pm/zazukRC8PKU6EO4Bu/awFW1Th\nNLihlrU1oZqf3FZJUJLyISqfYRiNi1VorqT9AgMBAAE=\n-----END RSA PUBLIC KEY-----\n","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b08936","group":"core","key":"members_private_key","value":"-----BEGIN RSA PRIVATE KEY-----\nMIICWwIBAAKBgQDNnEb9UqPy06AKq5HWOdKzv7hwn4JQQAsjuY0lZz6rU6uPq7B5vNf92N5W\nBFX50zgGLtt9b0XuYlB6IY4apjvTjBnDJlUfeef91g598MxQt6Zv82s7pEQvDylOhDuAbv2s\nBVtU4TS4oZa1NaGan9xWSVCS8iEqn2EYjYtVaK6k/QIDAQABAoGAb7xQu9PQMuMcow/P5ipw\nPayfr9yPNctIAncQpFXyMar7nc0Az3d3rYTQdtBOZMCLPpjyQL1atIyLDYP0tLjH41nQvEsR\noFsPJrp1Ti7yRVXvWfwakE4bayENc3VolNlcosOe7fsBGaAe1/hMi4fIBbJ5euih5gskWnD5\nmlo7SSUCQQD2P5v3AEKuB6FW8ouqBbVVYVvshiBAYTF+Y/5cyWC63+/OkiAq/tWJSqI9w6Mt\nI9rXNqXKoqieNWNxCYaiRldrAkEA1cCxRHb5PdLoLRvBQKuBmV4zaAleD6NpPPRns/Lx7HlA\nb2Lm945NS7d0aFHAeNruRwA4KtD/29GyAs9I3TXXNwJAPGGgltKDhzTrxOw4fvpjWopDBh5l\nbiPnBPzz9ECU7X3XyalfJevS5JVebxK3wmvWT4tg3+0+t3yT47XYQ5ZH/QJAR57cBquykZOE\ndfDRzOBqeUAGC3rwCF9hmKnvwWzKwMhT3b6O0y3cGl2q5HVX/2aj5ihdqYMD59yYP7bCnFQ4\n+wJAMOxnBmg/2CRgifOolKZQl+aXyhdn4vBAelf1hQ1yW/7J8N6LZt4kyTHHZ3HYxHajw4G9\nsmsmzT/qiL6YSMtOpQ==\n-----END RSA PRIVATE KEY-----\n","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b08937","group":"core","key":"members_email_auth_secret","value":"95d9a7867723637a2ce4e6fa94b0183d377235c2e07fc960f322fa00922fe2cb1ae2ed3eb632ac3aaddb4de3fea7e1328e465f97b23239e7c69926b4344242a9","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b0893a","group":"site","key":"title","value":"Rico Meinl","type":"string","flags":"PUBLIC","created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 20:19:37","updated_by":"1"},{"id":"6085749874348916f1b0893b","group":"site","key":"description","value":"I'm interested in biotech, longevity, machine learning and the decentralized web","type":"string","flags":"PUBLIC","created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2021-04-08 11:27:08","updated_by":"1"},{"id":"6085749874348916f1b0893c","group":"site","key":"logo","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-09 17:34:05","updated_by":"1"},{"id":"6085749874348916f1b0893d","group":"site","key":"cover_image","value":"__GHOST_URL__/content/images/2021/01/compass_cover.png","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2021-01-31 17:58:41","updated_by":"1"},{"id":"6085749874348916f1b0893e","group":"site","key":"icon","value":"__GHOST_URL__/content/images/2021/01/compass_favicon.png","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2021-01-31 17:48:19","updated_by":"1"},{"id":"6085749874348916f1b0893f","group":"site","key":"accent_color","value":"#15171A","type":"string","flags":"PUBLIC","created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 20:20:14","updated_by":"1"},{"id":"6085749874348916f1b08940","group":"site","key":"lang","value":"en","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08941","group":"site","key":"timezone","value":"Europe/Dublin","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 20:27:14","updated_by":"1"},{"id":"6085749874348916f1b08942","group":"site","key":"codeinjection_head","value":"<!-- Global site tag (gtag.js) - Google Analytics -->\n<script async src=\"https://www.googletagmanager.com/gtag/js?id=G-73VB9DC17E\"></script>\n<script>\n  window.dataLayer = window.dataLayer || [];\n  function gtag(){dataLayer.push(arguments);}\n  gtag('js', new Date());\n\n  gtag('config', 'G-73VB9DC17E');\n</script>","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-23 18:31:46","updated_by":"1"},{"id":"6085749874348916f1b08943","group":"site","key":"codeinjection_foot","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08944","group":"site","key":"facebook","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 20:27:14","updated_by":"1"},{"id":"6085749874348916f1b08945","group":"site","key":"twitter","value":"@rmeinl","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 20:27:14","updated_by":"1"},{"id":"6085749874348916f1b08946","group":"site","key":"navigation","value":"[{\"label\":\"Home\",\"url\":\"/\"},{\"label\":\"About me\",\"url\":\"/about-me/\"},{\"label\":\"Recommended\",\"url\":\"/recommended/\"},{\"label\":\"Projects\",\"url\":\"/projects/\"}]","type":"array","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2021-03-09 21:54:22","updated_by":"1"},{"id":"6085749874348916f1b08947","group":"site","key":"secondary_navigation","value":"[]","type":"array","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 20:30:23","updated_by":"1"},{"id":"6085749874348916f1b08948","group":"site","key":"meta_title","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08949","group":"site","key":"meta_description","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b0894a","group":"site","key":"og_image","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b0894b","group":"site","key":"og_title","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b0894c","group":"site","key":"og_description","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b0894d","group":"site","key":"twitter_image","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b0894e","group":"site","key":"twitter_title","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b0894f","group":"site","key":"twitter_description","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08950","group":"theme","key":"active_theme","value":"undefined-ghost-theme-master--1-","type":"string","flags":"RO","created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:56:03","updated_by":"1"},{"id":"6085749874348916f1b08951","group":"private","key":"is_private","value":"false","type":"boolean","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b08952","group":"private","key":"password","value":"","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b08953","group":"private","key":"public_hash","value":"30da930f636d01764d482853c5c73f","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08954","group":"members","key":"default_content_visibility","value":"public","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08955","group":"members","key":"members_signup_access","value":"all","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08956","group":"members","key":"members_from_address","value":"noreply","type":"string","flags":"RO","created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b08957","group":"members","key":"members_support_address","value":"noreply","type":"string","flags":"PUBLIC,RO","created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b08958","group":"members","key":"members_reply_address","value":"newsletter","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08959","group":"members","key":"members_free_signup_redirect","value":"/","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b0895a","group":"members","key":"members_paid_signup_redirect","value":"/","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b0895b","group":"members","key":"stripe_product_name","value":"Ghost Subscription","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b0895e","group":"members","key":"stripe_plans","value":"[{\"name\":\"Monthly\",\"currency\":\"usd\",\"interval\":\"month\",\"amount\":500},{\"name\":\"Yearly\",\"currency\":\"usd\",\"interval\":\"year\",\"amount\":5000}]","type":"array","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08961","group":"members","key":"stripe_connect_livemode","value":null,"type":"boolean","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08962","group":"members","key":"stripe_connect_display_name","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08964","group":"portal","key":"portal_name","value":"true","type":"boolean","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08965","group":"portal","key":"portal_button","value":"true","type":"boolean","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08966","group":"portal","key":"portal_plans","value":"[\"free\",\"monthly\",\"yearly\"]","type":"array","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 20:20:14","updated_by":"1"},{"id":"6085749874348916f1b08967","group":"portal","key":"portal_button_style","value":"icon-and-text","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08968","group":"portal","key":"portal_button_icon","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08969","group":"portal","key":"portal_button_signup_text","value":"Subscribe","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b0896a","group":"email","key":"mailgun_domain","value":"mg.ricomeinl.com","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-05 09:12:01","updated_by":"1"},{"id":"6085749874348916f1b0896b","group":"email","key":"mailgun_api_key","value":"32bf920b49c2a1d2b5d9f828499e5882-0d2e38f7-1f0f8ed9","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-08 22:42:19","updated_by":"1"},{"id":"6085749874348916f1b0896c","group":"email","key":"mailgun_base_url","value":"https://api.eu.mailgun.net/v3","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-05 09:12:01","updated_by":"1"},{"id":"6085749874348916f1b0896d","group":"email","key":"email_track_opens","value":"true","type":"boolean","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b0896e","group":"amp","key":"amp","value":"true","type":"boolean","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b0896f","group":"amp","key":"amp_gtag_id","value":null,"type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 17:03:05","updated_by":"1"},{"id":"6085749874348916f1b08970","group":"firstpromoter","key":"firstpromoter","value":"false","type":"boolean","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b08971","group":"firstpromoter","key":"firstpromoter_id","value":null,"type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b08972","group":"slack","key":"slack_url","value":"","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b08973","group":"slack","key":"slack_username","value":"Ghost","type":"string","flags":null,"created_at":"2020-10-04 17:03:05","created_by":"1","updated_at":"2020-10-04 20:20:14","updated_by":"1"},{"id":"6085749874348916f1b08974","group":"unsplash","key":"unsplash","value":"true","type":"boolean","flags":null,"created_at":"2020-10-04 17:03:06","created_by":"1","updated_at":"2020-10-04 20:20:14","updated_by":"1"},{"id":"6085749874348916f1b08975","group":"views","key":"shared_views","value":"[]","type":"array","flags":null,"created_at":"2020-10-04 17:03:06","created_by":"1","updated_at":"2020-10-04 17:03:06","updated_by":"1"},{"id":"6085749874348916f1b08976","group":"newsletter","key":"newsletter_show_badge","value":"true","type":"boolean","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b08977","group":"newsletter","key":"newsletter_show_header","value":"true","type":"boolean","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b08978","group":"newsletter","key":"newsletter_body_font_category","value":"sans_serif","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"},{"id":"6085749874348916f1b08979","group":"newsletter","key":"newsletter_footer_content","value":"","type":"string","flags":null,"created_at":"2021-04-25 13:54:32","created_by":"1","updated_at":"2021-04-25 13:54:32","updated_by":"1"}],"tags":[{"id":"6085749674348916f1b087c6","name":"Getting Started","slug":"getting-started","description":null,"feature_image":null,"parent_id":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"created_at":"2021-04-25 13:54:30","created_by":"1","updated_at":"2021-04-25 13:54:30","updated_by":"1"},{"id":"6085751074348916f1b08996","name":"system design","slug":"system-design","description":null,"feature_image":null,"parent_id":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"created_at":"2020-10-04 20:41:09","created_by":"1","updated_at":"2020-10-04 20:41:09","updated_by":null},{"id":"6085751074348916f1b08998","name":"startup","slug":"startup","description":null,"feature_image":null,"parent_id":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"created_at":"2020-10-04 20:42:42","created_by":"1","updated_at":"2020-10-04 20:42:42","updated_by":null},{"id":"6085751074348916f1b08995","name":"machine learning","slug":"machine-learning","description":null,"feature_image":null,"parent_id":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"created_at":"2020-10-04 20:41:09","created_by":"1","updated_at":"2020-10-04 20:41:09","updated_by":null},{"id":"6085751074348916f1b08999","name":"entrepreneurship","slug":"entrepreneurship","description":null,"feature_image":null,"parent_id":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"created_at":"2020-10-04 20:42:42","created_by":"1","updated_at":"2020-10-04 20:42:42","updated_by":null},{"id":"6085751074348916f1b08997","name":"data science","slug":"data-science","description":null,"feature_image":null,"parent_id":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"created_at":"2020-10-04 20:41:09","created_by":"1","updated_at":"2020-10-04 20:41:09","updated_by":null},{"id":"6085751074348916f1b0899a","name":"recommender systems","slug":"recommender-systems","description":null,"feature_image":null,"parent_id":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"created_at":"2020-10-04 20:45:23","created_by":"1","updated_at":"2020-10-04 20:45:23","updated_by":null},{"id":"60dcd5bfc0c8a524b4391ab4","name":"bioinformatics","slug":"bioinformatics","description":null,"feature_image":null,"parent_id":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"created_at":"2021-06-30 20:36:15","created_by":"1","updated_at":"2021-06-30 20:36:15","updated_by":"1"},{"id":"60dcd5bfc0c8a524b4391ab5","name":"cheminformatics","slug":"cheminformatics","description":null,"feature_image":null,"parent_id":null,"visibility":"public","og_image":null,"og_title":null,"og_description":null,"twitter_image":null,"twitter_title":null,"twitter_description":null,"meta_title":null,"meta_description":null,"codeinjection_head":null,"codeinjection_foot":null,"canonical_url":null,"accent_color":null,"created_at":"2021-06-30 20:36:15","created_by":"1","updated_at":"2021-06-30 20:36:15","updated_by":"1"}],"posts_tags":[{"id":"6085751174348916f1b089aa","post_id":"6085751174348916f1b0899b","tag_id":"6085751074348916f1b08995","sort_order":0},{"id":"6085751174348916f1b089ab","post_id":"6085751174348916f1b0899b","tag_id":"6085751074348916f1b08996","sort_order":1},{"id":"6085751174348916f1b089ac","post_id":"6085751174348916f1b0899b","tag_id":"6085751074348916f1b08997","sort_order":2},{"id":"6085751174348916f1b089ae","post_id":"6085751174348916f1b0899c","tag_id":"6085751074348916f1b08998","sort_order":0},{"id":"6085751174348916f1b089af","post_id":"6085751174348916f1b0899c","tag_id":"6085751074348916f1b08999","sort_order":1},{"id":"6085751174348916f1b089b1","post_id":"6085751174348916f1b0899d","tag_id":"6085751074348916f1b0899a","sort_order":0},{"id":"6085751174348916f1b089b2","post_id":"6085751174348916f1b0899d","tag_id":"6085751074348916f1b08995","sort_order":1},{"id":"6085751174348916f1b089b3","post_id":"6085751174348916f1b0899d","tag_id":"6085751074348916f1b08997","sort_order":2},{"id":"6085751174348916f1b089b5","post_id":"6085751174348916f1b0899e","tag_id":"6085751074348916f1b0899a","sort_order":0},{"id":"6085751174348916f1b089b6","post_id":"6085751174348916f1b0899e","tag_id":"6085751074348916f1b08995","sort_order":1},{"id":"6085751174348916f1b089b7","post_id":"6085751174348916f1b0899e","tag_id":"6085751074348916f1b08997","sort_order":2},{"id":"60dcd5bfc0c8a524b4391ab6","post_id":"60dccf53c0c8a524b4391a1f","tag_id":"60dcd5bfc0c8a524b4391ab4","sort_order":0},{"id":"60dcd5bfc0c8a524b4391ab7","post_id":"60dccf53c0c8a524b4391a1f","tag_id":"60dcd5bfc0c8a524b4391ab5","sort_order":1}]}}